<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="de-DE" xml:lang="de-DE">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
  </style>
</head>
<body>
<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Vollkorn" />
<style>
html {
    margin:    0 auto;
    max-width: 50%;
    background-color: rgb(255,253,253);
    font-family: Vollkorn;
}

h1 {
    font-family: Vollkorn;
    font-size: 27px;
    font-style: normal;
    font-variant: normal;
    font-weight: 600;
    line-height: 23px;
    color: #266BBD;
}

h2 {
    font-family: Vollkorn;
    font-size: 19px;
    font-style: normal;
    font-variant: normal;
    font-weight: 500;
    line-height: 23px;
    color: #266BBD;
}

h3 {
    font-family: Vollkorn;
    font-size: 17px;
    font-style: normal;
    font-variant: normal;
    font-weight: 400;
    line-height: 23px;
    color: #266BBD;
}

p {
    font-family: Vollkorn;
    font-size: 15px;
    font-style: normal;
    font-variant: normal;
    font-weight: 400;
    line-height: 23px;
}

blockquote {
    font-family: Vollkorn;
    font-size: 17px;
    font-style: normal;
    font-variant: normal;
    font-weight: 400;
    line-height: 23px;
}

pre {
    font-family: Vollkorn;
    font-size: 11px;
    font-style: normal;
    font-variant: normal;
    font-weight: 400;
    line-height: 23px;
}

img {
    width: 100%; 
    height: auto;
    display: block;
    margin-left: auto;
    margin-right: auto
}

</style>
<div id="TOC">
<img src="title.png" />
</div>

<p> </p>
<h1 id="sec:motivation"><span class="header-section-number">1</span> Einleitung</h1>
<p>Einfache und sichere Dateisynchronisation ist trotz vieler Lösungsansätze im Jahre 2016 noch immer kein Standard. Versucht man beispielsweise eine Datei zwischen zwei Personen zu teilen (oder noch schwieriger: synchron zu halten), so kann man unter anderem zwischen den folgenden Möglichkeiten wählen:</p>
<ul>
<li>Übertragung mittels USB–Stick, Speicherkarte oder Ähnlichem.</li>
<li>Übertragung über einen zentralen Dienst im lokalen Netz (wie FTP oder <em>ownCloud</em><a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>).</li>
<li>Übertragung über das Internet mit zentralen Diensten wie Dropbox.</li>
<li>Direkte Übertragung im Netzwerk mittels Protokollen wie <code>ssh</code>.</li>
<li>…oder sehr häufig auch einfach via E–Mail.</li>
</ul>
<p>Jede dieser Ansätze funktioniert auf seine Weise, doch ergeben sich in der Praxis meist sehr unterschiedliche Probleme. Bei E–Mails kann oft nur eine maximale Dateigröße übermittelt werden, die Übertragung von Dateien mittels <code>ssh</code> ist für die meisten Nutzer zu kompliziert und zentrale Dienste rufen einerseits Sicherheitsbedenken hervor, andererseits sind sie meist nur bedingt kostenlos und können unvermittelt ausfallen oder mittels Zensurmaßnahmen blockiert werden. Wie in fig. 1 humoristisch gezeigt, muss also für jeden neuen Kontakt stets erst aufwendig der kleinste gemeinsame Nenner ausgehandelt werden.</p>
<a name="fig:xkcd-sync"></a>
<div class="figure">
<img src="images/1/xkcd-file-transfer.png" alt="Figure 1: Figure 1. Humorvolle Darstellung der Suche nach dem »kleinsten gemeinsamen Nenner«." id="fig:xkcd-sync" style="width:50.0%" />
<p class="caption">Figure 1: Figure 1. Humorvolle Darstellung der Suche nach dem »kleinsten gemeinsamen Nenner«.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
</div>
<h2 id="motivation"><span class="header-section-number">1.1</span> Motivation</h2>
<p>Zahlreiche Ansätze haben versucht, diese Probleme in der Praxis abzumildern oder zu lösen. Viele dieser Ansätze basieren nicht mehr auf einer zentralen Infrastruktur, sondern benutzen als Gegenentwurf einen dezentralen Ansatz. Dabei werden nicht alle Dateien an einem zentralen Punkt gespeichert, sondern können verteilt (ganz oder nur einzelne Blöcke einer Datei) im Netzwerk vorhanden sein. Dass dabei Dokumente auch durchaus doppelt oder öfters gespeichert werden dürfen, erhöht die Ausfallsicherheit und vermeidet den Flaschenhals zentraler Dienste, da der Ausfall einzelner Netzwerkknoten durch andere abgefangen werden kann. Anwender sind auch oft davon betroffen, dass viele Filehoster nur für einen bestimmten Zeitraum Dateien speichern. Ist dieser Zeitraum vorbei oder wird der Dienst eingestellt, entstehen vielfach tote Links. Hier könnte eine Lösung ansetzen, bei der die Dateien von jedem Interessenten gespiegelt werden und auch von diesen beziehbar sind. Dieser Gedanke entspricht dem <em>Permanent Web</em><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a>.</p>
<p>Abseits der Dateisynchronisation konnte sich in anderen Bereichen sichere Open–Source–Software erfolgreich etablieren. Ein gutes Beispiel hierfür ist die Messenger–Anwendung <em>Signal</em><a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>, welche sichere und einfache Kommunikation auf dem Smartphone ermöglicht. Vermutlich hat diese Software nicht nur durch seine hohen Sicherheitsversprechen eine gewisse Verbreitung<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> erfahren, sondern weil es genauso leicht benutzbar und zugänglich war, wie die unsichereren Alternativen (wie <em>SMS</em> oder frühere Versionen von <em>WhatsApp</em>). Letztendlich führte dies sogar dazu, dass die von <em>Signal</em> genutzte Technik im deutlich populäreren <em>WhatsApp</em>–Messenger eingesetzt wurde. Gleichzeitig muss fairerweise gesagt werden, dass die gute Usability durch einige Vereinfachungen im Sicherheitsmodell erreicht wurde<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>.</p>
<p>Erwähnenswert ist <em>Signal</em>, da auch viele Dateisynchronisationsdienste in der Praxis entweder an der Usability oder an den Sicherheitsanforderungen kranken, die insbesondere Unternehmen an eine solche Lösung stellen. Die vorliegende Arbeit stellt einen dezentralen Ansatz zur Dateisynchronisation vor, der eine <em>Balance zwischen Sicherheit, Usability und Effizienz</em> herstellt. Die hier vorgestellte und quelloffene Lösung trägt den Namen »<code>brig</code>«. Der aktuelle Quelltext findet sich auf der Hosting–Plattform <em>GitHub</em><a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>.</p>
<h2 id="projektziel"><span class="header-section-number">1.2</span> Projektziel</h2>
<p>Ziel des Projektes ist die Entwicklung einer sicheren, verteilten und versionierten Alternative zu Cloud–Storage Lösungen wie Dropbox, die sowohl für Unternehmen, als auch für Heimanwender nutzbar ist. Trotz der Prämisse, einfache Nutzbarkeit zu gewährleisten, wird auf Sicherheit sehr großen Wert gelegt.</p>
<p>Nutzbar soll das resultierende Produkt, neben dem Standardanwendungsfall der Dateisynchronisation, auch als Backup- bzw. Archivierungs–Lösung sein. Weiterhin kann es auch als verschlüsselter Daten–Safe oder als »Werkzeugkasten« für andere, verteilte Anwendungen dienen — wie beispielsweise aus dem Industrie–4.0–Umfeld.</p>
<p>Als weiteres Abgrenzungsmerkmal setzt <code>brig</code> nicht auf möglichst hohe Effizienz (wie es typischerweise verteilte Dateisysteme tun) sondern versucht möglichst generell anwendbar zu sein und über Netzwerkgrenzen hinweg zu funktionieren. Dadurch soll es zu einer Art »Standard« werden, auf den sich möglichst viele Anwender einigen können.</p>
<h2 id="der-name"><span class="header-section-number">1.3</span> Der Name</h2>
<p>Eine »Brigg« (englisch »brig«) ist ein kleines und wendiges Zweimaster–Segelschiff aus dem 18. Jahrhundert. Passend erschien den Autoren der Name einerseits, weil die Software flexibel »Güter« (in Form von Dateien) in der ganzen Welt verteilt, andererseits weil <code>brig</code> auf (Datei-)Strömen operiert.</p>
<p>Dass der Name ähnlich klingt und kurz ist wie <code>git</code><a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>, ist kein Zufall. Das Versionsverwaltungssystem hat durch seine sehr flexible und dezentrale Arbeitsweise bestehende zentrale Alternativen wie <code>svn</code><a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> oder <code>cvs</code><a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a> fast vollständig abgelöst. Zusätzlich ist der Gesamteinsatz von Versionsverwaltungssystemen durch die verhältnismäßig einfache Anwendung gestiegen. Die Autoren hoffen mit <code>brig</code> eine ähnlich flexible Lösung für »große« Dateien etablieren zu können.</p>
<h2 id="lizenz"><span class="header-section-number">1.4</span> Lizenz</h2>
<p>Eine sicherheitskritische Lösung sollte den Nutzern die Möglichkeit geben zu validieren, wie die Sicherheitskonzepte implementiert sind. Aus diesem Grund und um eine freie Weiterentwicklung zu gewährleisten, wird die entwickelte Software unter die <code>AGPLv3</code> (<em>Affero General Public License, Version 3</em><a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a>) gestellt. Diese stellt sicher, dass Verbesserungen am Projekt auch wieder in dieses zurückfließen müssen. Das Open–Source–Modell bietet aus unserer Sicht hierbei einige grundlegende Vorteile:</p>
<ul>
<li>Schnellere Verbreitung durch fehlende Kostenbarriere auf Nutzerseite.</li>
<li>Kann von Nutzern und Unternehmen auf ihre Bedürfnissen angepasst werden.</li>
<li>Transparenz in puncto Sicherheit (keine offensichtlichen Backdoors möglich).</li>
<li>Fehlerkorrekturen und Weiterentwicklung durch die Community gewährleistet.</li>
</ul>
<h2 id="gliederung-der-arbeit"><span class="header-section-number">1.5</span> Gliederung der Arbeit</h2>
<p>Diese Arbeit wird einen Überblick über die aktuelle Implementierung sowie die Techniken und Designentscheidungen dahinter geben, um sie anschließend kritisch zu reflektieren. Sicherheitsaspekte werden in dieser Arbeit nur oberflächlich angeschnitten, da Herr Piechula in seiner Arbeit »<em>Sicherheitskonzepte und Evaluation dezentraler Dateisynchronisationssysteme am Beispiel brig</em>«<span class="citation">[27]</span> die Sicherheitskonzepte der Software im Detail beleuchtet.</p>
<p>Die vorliegende Arbeit ist in drei größere logische Blöcke gegliedert:</p>
<ul>
<li>sec. 1 – sec. 4 (Einleitung, Stand der Technik, Anforderungen, Grundlagen): Eine Hinführung zum Thema Dateisynchronisation wird gegeben. Neben einer Analyse der Wettbewerber und Einsatzmöglichkeiten wird auch das nötige Grundlagenwissen vermittelt, um die nächsten Kapitel zu verstehen.</li>
<li>sec. 5 – sec. 7 (Architektur, Implementierung, Usability): In diesen drei Kapiteln wird das technische Design des Prototypen erläutert und Begründungen zu den Designentscheidungen gegeben. Zuletzt wird noch ein Konzept für eine grafische Benutzeroberfläche vorgestellt.</li>
<li>sec. 8 – sec. 9 (Evaluation, Fazit): Der aktuelle Prototyp wird auf Schwächen untersucht und mögliche Lösungen werden diskutiert. Zudem werden Möglichkeiten zur weiteren Entwicklung aufgezeigt.</li>
</ul>
<p>Im sec. 10 findet sich zudem ein Benutzerhandbuch, das losgekoppelt vom Rest gelesen werden kann und dazu dienen soll, einen praktischen Eindruck von der Implementierung zu bekommen. Es wird daher empfohlen, das Benutzerhandbuch frühzeitig zu lesen.</p>
<h2 id="über-die-autoren-der-software"><span class="header-section-number">1.6</span> Über die Autoren der Software</h2>
<p>Die Autoren sind zwei Master–Studenten an der Hochschule Augsburg, die von »Freier Software« begeistert sind. Momentan entwickeln wir <code>brig</code> im Rahmen unserer Masterarbeiten bei Prof. Dr.-Ing. Thorsten Schöler in der Distributed–Systems–Group<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a> und wollen auch nach unserem Abschluss weiter daran arbeiten. Beide Autoren haben Erfahrung und Spaß daran, Open–Source–Software zu entwickeln und zu betreuen, was neben dem Eigennutzen einen großen Teil der Motivation ausmacht.</p>
<h2 id="konventionen"><span class="header-section-number">1.7</span> Konventionen</h2>
<p>Es werden einige wenige typografische Konventionen im Textsatz vereinbart:</p>
<ul>
<li>Programmnamen werden <code>monospaced</code> geschrieben.</li>
<li>Wichtige Aussagen werden <em>hervorgehoben</em>.</li>
<li>Spezielle Ausdrücke und Eigennamen werden in »Chevrons« gesetzt.</li>
</ul>
<p>Zudem werden die Namen <em>Alice</em>, <em>Bob</em> und manchmal <em>Charlie</em> verwendet, um Testnutzer zu kennzeichnen. Sofern nicht anders angegeben, kann angenommen werden, dass Abläufe aus Sicht von <em>Alice</em> geschildert werden. Die Grafiken in dieser Arbeit sind in englischer Sprache gehalten, da diese auch für die offizielle Dokumentation genutzt werden sollen.</p>
<h1 id="sec:stand-der-technik"><span class="header-section-number">2</span> Stand der Technik</h1>
<p>In diesem Kapitel wird ein kurze Einführung zum Thema Peer–to–Peer–Netzwerke gegeben. Danach wird eine Einordnung der Arbeit zu den bisher existierenden Arbeiten zum Thema Dateisynchronisation gegeben. Im Anschluss wird <code>brig</code> zudem in Relation zu einigen auf dem Markt verfügbaren Produkten gesetzt. Darauf aufbauend wird von verschiedenen Perspektiven aus überlegt, welche Eigenschaften <code>brig</code> übernehmen kann und von wem und in welchem Rahmen die Software eingesetzt werden kann.</p>
<h2 id="peertopeer-netzwerke"><span class="header-section-number">2.1</span> Peer–to–Peer Netzwerke</h2>
<p>Bilden viele Rechner ein dezentrales Netzwerk, bei dem jeder Rechner (ein »Peer«) die gleichen Rechte besitzt und die gleichen Aktionen ausführt wie jeder andere, so wird dieses Netz ein <em>Peer–to–Peer–Netzwerk</em> genannt (kurz <em>P2P–Netzwerk</em>, vgl. auch <span class="citation">[23]</span>, S. 4 ff.). Statt Verbindungen über einen Mittelsmann aufzubauen, kommunizieren die einzelnen Peers für gewöhnlich direkt miteinander. Jeder Knoten des Netzwerks kann Anfragen an andere Knoten richten, trägt aber selbst etwas bei indem er selbst Anfragen beantwortet. Im Client–Server–Modell entspricht ein Peer also sowohl Server als auch Client (siehe auch fig. 2).</p>
<a name="fig:central-distributed"></a>
<div class="figure">
<img src="images/2/central-distributed.png" id="fig:central-distributed" />
<p class="caption">Figure 2: Figure 2. Anschaulicher Unterschied zwischen zentralen und verteilten Systemen.</p>
</div>
<p>Im alltäglichen Gebrauch der meisten »Otto–Normal–Nutzer« scheinen P2P–Netzwerke derzeit eine eher untergeordnete Rolle zu spielen. Die bekanntesten und populärsten P2P–Netzwerke sind vermutlich das BitTorrent- und Skype–Protokoll (vgl. <span class="citation">[23]</span>, S. 232 ff. und S. 2). Darüber hinaus gibt es auch viele sehr große Filesharing–Netzwerke, wie Gnutella (vgl. auch <span class="citation">[23]</span>, S. 57 ff.). Gemeinsam ist allen, dass sie als sogenanntes <em>Overlay–Netzwerk</em><a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a> über das Internet gelegt werden und dessen existierende Infrastruktur wiederverwenden.</p>
<h3 id="zugrundeliegende-technik"><span class="header-section-number">2.1.1</span> Zugrundeliegende Technik</h3>
<p>Die meisten Dienste im Internet basieren hingegen auf dem Client–Server–Modell, bei dem viele anonyme Clients eine Anfrage an einen zentralen Server stellen. Dieser muss mit der steigenden Anzahl an Clients skalieren, indem er typischerweise mehr Prozessorleistung und Bandbreite zur Verfügung stellt. Dieses Modell passt auf viele heterogene Anwendungsfälle, wo Client und Server grundverschiedene Rollen zugeordnet sind (Beispiel: Dienstleiter und Kunde). Eine weitere Eigenschaft, ist dass das Client–Server–Modell kein Problem mit dem sogenannten <em>NAT–Traversal</em> hat.</p>
<p>NAT steht dabei für <em>Network Address Translation</em> (dt. Netzwerkadressübersetzung, siehe auch <span class="citation">[23]</span>, S. 47 ff.) und ist eine Technik, um zwischen einer öffentlichen und mehreren lokalen IP–Adressen zu vermitteln. Es wird aufgrund der Knappheit von IPv4 sehr häufig eingesetzt, um einem Heim- oder Unternehmensnetzwerk eine einzige IP-Adresse nach Außen zu geben, die über bestimmte Ports dann den Verkehr auf die jeweiligen lokalen Adressen übersetzt. Der Nachteil in Bezug auf P2P–Netzwerke ist dabei, dass die Rechner hinter einem <em>NAT</em> nicht direkt erreichbar sind. Client–Server–Anwendungen haben damit kein Problem, da der »anonyme« Client die Verbindung zum »wohlbekannten« Server selbstständig aufbaut. Bei einer P2P–Kommunikation hingegen, muss eine Verbindung in beide Richtungen möglich sein — und das möglicherweise sogar über mehrere <em>NATs</em> hinweg. Die Umgehung dieser Grenzen ist in der Literatur als <em>NAT Traversal</em> bekannt. Eine populäre Technik ist dabei das UDP–Hole–Punching<a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a>. Dabei wird, grob erklärt, ein beiden Parteien bekannter Mittelsmann herangezogen, über den die eigentliche, direkte Verbindung aufgebaut wird. Eine technische Notwendigkeit dabei ist die Verwendung von <em>UDP</em> anstatt <em>TCP</em>.</p>
<p>Typischerweise ist dieser Mittelsmann ein sogenannter <em>Bootstrap–Knoten</em>. Dieser ist innerhalb eines P2P–Netzwerks einer von mehreren wohlbekannten Knoten, zu dem sich neue Netzwerkteilnehmer verbinden, um von ihm an weitere Teilnehmer vermittelt zu werden. Der Boostrap–Knoten führt aber normalerweise das gleiche Programm aus, wie jeder andere, ist aber vertrauenswürdiger. Bemerkenswert ist, dass sich keine zentrale Instanz um die Koordination des Datenflusses im Netzwerk kümmern muss. Die Grundlage für die Koordination bildet dabei die <em>Distributed Hashtable (DHT, vgl. <span class="citation">[23]</span>, S. 63 ff.)</em> Diese Datenstruktur bildet sich durch den Zusammenschluss vieler Rechner und nutzt eine <em>Hashfunktion</em><a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a>, um für einen bestimmten Datensatz zu entscheiden, welche Knoten (mindestens aber einer) im Netzwerk für diesen Datensatz zuständig sind. Ist ein Teilnehmer an einem Datensatz interessiert, so muss er nur die Prüfsumme desselben kennen, um zu wissen von welchem Teilnehmer er den Datensatz beziehen kann. Jeder Knoten verwaltet dabei einen bestimmten Wertebereich der Prüfsummenfunktion und ist für diese Prüfsummen zuständig. Werden neue Knoten hinzugefügt oder andere verlassen das Netz, werden die Wertebereiche neu verteilt.</p>
<h3 id="dateisynchronisation-in-p2pnetzwerken"><span class="header-section-number">2.1.2</span> Dateisynchronisation in P2P–Netzwerken</h3>
<p>In diesem Kontext meint der Begriff »Synchronisation« das Zusammenführen der Dateistände mehrerer Netzwerkteilnehmer. Typischerweise nutzen viele Nutzer heutzutage dafür einen zentralen Dienst. Dieser hält einen Dateistand vor, der von allen Teilnehmern als Referenz angesehen wird. Ändert ein Teilnehmer seinen Stand, so wird die Änderung zum zentralen Server übertragen und erreicht so auch alle anderen Teilnehmer.</p>
<p>In vielen Fällen skalieren aber solche Client–Server Anwendungen bei weitem schlechter als verteilte Anwendungen. Man stelle sich einen Vorlesungssaal mit 50 Studenten vor, die ein Festplattenimage (Größe: 5 Gigabyte) aus dem Internet herunterladen sollen. Bei einer Client–Server Anwendung werden hier 50 Verbindungen zu einem zentralen Server (beispielsweise Dropbox) geöffnet. Der Server muss nun 50 Verbindungen gleichzeitig bearbeiten und muss eine entsprechende Bandbreite zur Verfügung stellen. Bei kleineren Diensten kann dies bereits der Flaschenhals sein, teilweise kann aber auch die Bandbreite auf Seiten des Empfängers limitiert sein. Fällt der zentrale Server aus (»Single–Point–of–Failure«), so kann kein neuer Nutzer mehr das Festplattenimage empfangen.</p>
<a name="fig:speedup"></a>
<div class="figure">
<img src="images/2/zentral-dezentral-speedup.png" id="fig:speedup" />
<p class="caption">Figure 3: Figure 3. Veranschaulichung der Netzwerklast bei zentralen und dezentralen Systemen.</p>
</div>
<p>Bilden die Rechner der Studenten ein verteiltes Netzwerk, so genügt es wenn nur ein Rechner einen Teil der Datei hat. Diesen Teil kann er im lokalen Netz anderen Teilnehmern wieder anbieten und sich Teile der Datei besorgen, die er selbst noch nicht hat. So muss in der Theorie die Datei nur maximal einmal vom zentralen Server übertragen werden. In diesem etwas konstruierten<a href="#fn16" class="footnoteRef" id="fnref16"><sup>16</sup></a> Beispiel würde im dezentralen Netzwerk die Datei also bis zu 50-mal schneller verteilt werden, als im zentralen Anwendungsfall. Fällt der zentrale Server aus nachdem die Datei bereits einmal komplett heruntergeladen wurde, so werden die bereits existierenden Teile von den jeweiligen Teilnehmern weiter angeboten. fig. 3 veranschaulicht diesen Zusammenhang noch einmal.</p>
<p>Dezentrale Netzwerke eignen sich sehr gut um Dateien auszutauschen, da ganze Dateien in kleine Blöcke unterteilt werden können. Diese können dann von interessierten Knoten vorgehalten und weitergegeben werden. Protokolle wie <em>BitTorrent</em> haben das Problem, dass ein Block nur solange verfügbar ist, solange es Teilnehmer gibt, die diesen Block anbieten. Prinzipiell hat auch <code>brig</code> dieses Problem, doch besteht ein <code>brig</code>–Netzwerk nur aus den Teilnehmern, die einen gemeinsamen Dateistand synchronisieren wollen. Daher kann angenommen werden, dass alle darin enthaltenen Dateien von mindestens einem Teilnehmer angeboten werden können.</p>
<h2 id="ähnliche-arbeiten"><span class="header-section-number">2.2</span> Ähnliche Arbeiten</h2>
<p>Es gibt viele unterschiedliche wissenschaftliche Arbeiten rund um das Thema der Dateiverteilung in P2P–Netzwerken. Die meisten Arbeiten scheinen sich mehr auf das Thema des Dateiaustausches an sich zu konzentrieren und weniger auf das Thema der Dateisynchronisation, wo eine Menge von Dateien auf dem selben Stand gehalten werden muss. Die dazu vorhandenen Arbeiten legen ihren Fokus dabei meist auf die Untersuchung und Implementierung verteilter Dateisysteme, die sehr ähnliche Probleme lösen müssen, aber mehr auf Effizienz als auf Einfachheit Wert legen.</p>
<p>Stellvertretend für eine solche Arbeit soll hier die Dissertation von Julien Quintard <em>»Towards a worldwide storage infrastructure«</em><span class="citation">[26]</span> genannt werden. In dieser wird die Implementierung und die Konzepte hinter dem verteilten Dateisystem <em>Infinit</em> vorgestellt. Obwohl der Fokus hier auf Effizienz liegt, hat <em>Infinit</em> einige auffällige Ähnlichkeiten mit den Zielen von <code>brig</code>:</p>
<ul>
<li>Weltumspannendes P2P-Netzwerk als Grundlage.</li>
<li>Nutzung von FUSE<a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a> als Frontend zum Nutzer.</li>
<li>Verschlüsselte Speicherung der Daten.</li>
<li>Eingebaute Deduplizierung.</li>
<li>Eine Versionierung der Dateien ist geplant.</li>
</ul>
<p>Der Hauptunterschied ist allerdings die Zielgruppe. Während das bei <code>brig</code> der »Otto–Normal–Nutzer« als kleinster Nenner ist, so ist <em>Infinit</em> auf Entwickler und Administratoren ausgelegt und leider nur teilweise quelloffen,<a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a> also keine »Free Open Source Software« <em>(FOSS)</em>.</p>
<p>Eine sehr detaillierte Gegenüberstellung vieler Produkte rund um das Thema Dateisynchronisation findet sich in der Dokumentation von <code>inifinit</code><a href="#fn19" class="footnoteRef" id="fnref19"><sup>19</sup></a>.</p>
<p>Es gibt eine Reihe nicht–kommerzieller Projekte, die teilweise eine ähnliche Ausrichtung wie <code>brig</code> haben und daher mindestens eine Erwähnung verdienen. Im Folgenden werden die Ähnlichkeiten zu <code>brig</code> genannt:</p>
<p><strong>bazil:</strong><a href="#fn20" class="footnoteRef" id="fnref20"><sup>20</sup></a> Ein Werkzeug um Dateien verschlüsselt und dezentral zu verteilen. In seinen Zielen ist es sehr ähnlich zu <code>brig</code>, besonders da es ebenfalls ein FUSE–Dateisystem implementiert<a href="#fn21" class="footnoteRef" id="fnref21"><sup>21</sup></a>. Es ist eher an technisch versierte Nutzer gerichtet und momentan noch nicht für den Produktivbetrieb geeignet. Zu diesem Zeitpunkt funktioniert es nur lokal auf einem System ohne mit anderen Knoten kommunizieren zu können.</p>
<p><strong>Tahoe-LAFS:</strong><a href="#fn22" class="footnoteRef" id="fnref22"><sup>22</sup></a> Ein verteiltes Dateisystem, welches Dateien auf eine Menge an Rechnern möglichst ausfallsicher verteilen kann, selbst wenn einzelne Rechner ausfallen. Es richtet sich tendenziell an Administratoren und technisch versierte Nutzer, die eine große Menge an Daten sicher lagern wollen. Ähnliche Produkte in diesem Bereich gibt es mit <em>XtreemFs</em><a href="#fn23" class="footnoteRef" id="fnref23"><sup>23</sup></a>, <em>LizardFs</em><a href="#fn24" class="footnoteRef" id="fnref24"><sup>24</sup></a> und <em>MooseFs</em><a href="#fn25" class="footnoteRef" id="fnref25"><sup>25</sup></a> mit jeweils unterschiedlichen Schwerpunkten.</p>
<p><strong>restic:</strong><a href="#fn26" class="footnoteRef" id="fnref26"><sup>26</sup></a> Ein in <em>Go</em> geschriebenes Backup–Programm. Es synchronisiert zwar keine Dateien über das Netzwerk, setzt aber eine Versionsverwaltung mittels <em>Snapshots</em> um. Zudem verschlüsselt es alle ihm bekannten Dateien in einem <em>Repository</em> und gewährleistet mittels eines speziellen Dateiformats deren Integrität. <code>brig</code> verwendet analog zu <code>restic</code> (und <code>git</code>) den Begriff <em>Repository</em> für den Ordner, in dem es seine Daten ablegt.</p>
<h2 id="wissenschaftliche-lücke"><span class="header-section-number">2.3</span> Wissenschaftliche Lücke</h2>
<a name="fig:science-hole"></a>
<div class="figure">
<img src="images/2/science-hole.png" id="fig:science-hole" style="width:66.0%" />
<p class="caption">Figure 4: Figure 4. Die Neuerung von <code>brig</code> liegt in der Zusammenführung vieler Teildisziplinen.</p>
</div>
<p>Die wissenschaftliche Neuerung der vorliegenden Arbeit ist die Zusammenführung vieler wissenschaftlicher Teildisziplinen, die es nach Wissen des Autors vorher noch nicht in dieser Kombination gab. Dabei werden viele bestehende Ideen und Konzepte genommen, um sie in einer Software zu vereinen, die ein versioniertes und verteiltes Dateisystem implementiert. Dieses soll nicht nur »sicher« (im weitesten Sinne, siehe <span class="citation">[27]</span> für eine Begriffseinordnung) sein, sondern auch für einen Großteil der Anwender benutzbar sein.</p>
<p>Im Konkreten besteht die Neuerung hauptsächlich aus der Kombination folgender Punkte:</p>
<ul>
<li>Eine Erweiterung des Datenmodells von <code>git</code>, welches Metadaten von den eigentlichen Daten trennt, leere Verzeichnisse sowie umbenannte Pfade nativ unterstützt und eine eigene Historie pro Datei verwaltet.</li>
<li>Die Möglichkeit nur die Metadaten zu synchronisieren und die eigentlichen Daten dynamisch nachzuladen und nach Anwendungsfall zu »pinnen«. Dateien mit einem <em>Pin</em> werden dabei auf dem lokalen Rechner gespeichert, Dateien ohne Pin dürfen falls nötig wieder gelöscht werden.</li>
<li>Ein Containerformat für Verschlüsselung (ähnlich dem Secretbox der freien NaCl<a href="#fn27" class="footnoteRef" id="fnref27"><sup>27</sup></a> Bibliothek), welches effizienten wahlfreien Zugriff erlaubt und eine Austauschbarkeit des Algorithmus gewährleistet.</li>
<li>Ein Containerformat zur Kompression, welches blockbasierten, wahlfreien Zugriff und den Einsatz verschiedener Algorithmen erlaubt.</li>
<li>Ein Konzept und Implementierung zur dezentralen Benutzerverwaltung, ohne dass ein Nutzer dabei explizit registriert werden muss.</li>
<li>Verschiedene Ansätze um die Usability zu verbessern ohne die Sicherheit einzuschränken (siehe sec. 7).</li>
</ul>
<h2 id="markt-und-wettbewerber"><span class="header-section-number">2.4</span> Markt und Wettbewerber</h2>
<p>Bereits ein Blick auf Wikipedia<a href="#fn28" class="footnoteRef" id="fnref28"><sup>28</sup></a> zeigt, dass der momentane Markt an Dateisynchronisationssoftware sehr unübersichtlich ist. Ein näherer Blick zeigt, dass die dortigen Softwareprojekte oft nur in Teilaspekten gut funktionieren und teilweise auch mit architektonischen Problemen behaftet sind.</p>
<p>Im Folgenden wird eine unvollständige Übersicht über bekannte Dateisynchronisationsprogramme gegeben. Davon stehen nicht alle in Konkurrenz zu <code>brig</code>, sind aber zumindest aus Anwendersicht ähnlich und sollten daher kurz aus dieser Perspektive verglichen werden.</p>
<h3 id="dropbox-boxcryptor"><span class="header-section-number">2.4.1</span> Dropbox + Boxcryptor</h3>
<a name="fig:scrn-dropbox"></a>
<div class="figure">
<img src="images/2/dropbox.png" alt="Figure 5: Figure 5. Screenshot eines Dropbox–Accounts." id="fig:scrn-dropbox" />
<p class="caption">Figure 5: Figure 5. Screenshot eines Dropbox–Accounts.</p>
</div>
<p>Dropbox (siehe fig. 5) ist der vermutlich bekannteste und am weitesten verbreitete zentrale Dienst zur Dateisynchronisation. Verschlüsselung kann man mit Tools wie dem freien <code>encfs</code><a href="#fn29" class="footnoteRef" id="fnref29"><sup>29</sup></a> oder dem etwas umfangreicheren, proprietären <code>boxcryptor</code> nachrüsten. Was das Backend genau tut ist leider das Geheimnis von Dropbox — es ist nicht Open–Source. Mehr Details liefert die Arbeit von Herrn Piechula<span class="citation">[27]</span>.</p>
<p>Die Server von Dropbox stehen in den Vereinigten Staaten von Amerika, was spätestens seit den Snowden–Enthüllungen Besorgnis um die Sicherheit der Daten weckt. Wie oben erwähnt, kann diese Problematik durch die Verschlüsselungssoftware <code>boxcryptor</code> abgemildert werden. Diese kostet aber zusätzlich und benötigt noch einen zusätzlichen zentralen Keyserver<a href="#fn30" class="footnoteRef" id="fnref30"><sup>30</sup></a>. Ein weiterer Nachteil ist hier die Abhängigkeit von der Verfügbarkeit des Dienstes.</p>
<p>Technisch nachteilhaft bei vielen zentralen Diensten ist, dass die Datei »über den Pazifik« hinweg synchronisiert werden muss, nur um möglicherweise auf dem Arbeitsrechner »nebenan« anzukommen. Dropbox hat hier nachgerüstet, indem es nach Möglichkeit direkt über LAN synchronisiert<a href="#fn31" class="footnoteRef" id="fnref31"><sup>31</sup></a>. Nichtsdestotrotz können Kunden nicht mehr synchronisieren, wenn der zentrale Dienst ausgefallen ist oder den Dienst eingestellt hat.</p>
<h3 id="owncloud-nextcloud"><span class="header-section-number">2.4.2</span> <code>ownCloud</code> / <code>Nextcloud</code></h3>
<a name="fig:scrn-owncloud"></a>
<div class="figure">
<img src="images/2/owncloud.png" alt="Figure 6: Figure 6. Screenshot der ownCloud–Weboberfläche." id="fig:scrn-owncloud" />
<p class="caption">Figure 6: Figure 6. Screenshot der ownCloud–Weboberfläche.</p>
</div>
<p>Eine Alternative zu einem von einem Unternehmen bereitgestellten zentralen Dienst, ist die Nutzung einer eigenen »Private Cloud« mithilfe der Open–Source Lösung <code>ownCloud</code> (siehe fig. 6, beziehungsweise dessen Fork <code>Nextcloud</code>). Nutzer installieren auf ihren Servern selbst eine <code>ownCloud</code>–Instanz und stellen ausreichend Speicherplatz bereit. Vorteilhaft ist also, dass die Daten auf den eigenen Servern liegen. Nachteilig hingegen, dass das zentrale Modell von Dropbox lediglich auf eigene Server übertragen wird. Einerseits ist <code>ownCloud</code> nicht so stark wie <code>brig</code> auf Sicherheit fokussiert, andererseits ist die Installation eines Serversystems für viele Nutzer eine große Hürde und somit zumindest für den Heimanwender nicht praktikabel.</p>
<h3 id="syncthing"><span class="header-section-number">2.4.3</span> <code>Syncthing</code></h3>
<a name="fig:scrn-syncthing"></a>
<div class="figure">
<img src="images/2/syncthing.png" alt="Figure 7: Figure 7. Screenshot der Syncthing–Weboberfläche." id="fig:scrn-syncthing" />
<p class="caption">Figure 7: Figure 7. Screenshot der Syncthing–Weboberfläche.</p>
</div>
<p>Das 2013 veröffentlichte quelloffene <code>syncthing</code> (siehe fig. 7) versucht diese zentrale Instanz zu vermeiden, indem die Daten jeweils von Teilnehmer zu Teilnehmer übertragen werden. Die Dateien werden in einem speziellen Ordner gelegt, der von <code>syncthing</code> überwacht wird. Nach der Installation wird eine einzigartige Client–ID generiert. Über eine Weboberfläche oder eine native Desktopanwendung kann konfiguriert werden, mit wem dieser Ordner geteilt werden soll, indem die Client–ID eines anderen Teilnehmers eingegeben wird.</p>
<p>Es ist allerdings kein vollständiges Peer–to–peer–Netzwerk: Geteilte Dateien liegen immer als vollständige Kopie bei allen Teilnehmern, welche die Datei haben. Alternativ ist nur die selektive Synchronisation bestimmter Dateien möglich. Zwischen den Teilnehmern wird ein Protokoll mit dem Namen <em>Block Exchange Protocol</em><span class="citation">[6]</span> etabliert. Dieses sorgt für eine sichere, differentielle und blockweise Übertragung.</p>
<p>Praktisch ist auch, dass <code>syncthing</code>–Instanzen mittels eines zentralen Discovery–Servers entdeckt werden. Nachteilig ist aber die fehlende Benutzerverwaltung: Man kann nicht festlegen von welchen Nutzern man Änderungen empfangen will und von welchen nicht. Eingesetzt wird <code>syncthing</code> zwar auch gerne von technisch versierten Nutzern, doch existiert auch für Neulinge ausreichend Dokumentation.</p>
<h3 id="resilio"><span class="header-section-number">2.4.4</span> <code>resilio</code></h3>
<a name="fig:scrn-resilio"></a>
<div class="figure">
<img src="images/2/resilio.png" alt="Figure 8: Figure 8. Screenshot der resilio–Weboberfläche." id="fig:scrn-resilio" />
<p class="caption">Figure 8: Figure 8. Screenshot der <code>resilio</code>–Weboberfläche.</p>
</div>
<p>Das kommerzielle und proprietäre <code>resilio</code> (früher <em>Bittorrent Sync</em>) nutzt eine Modifikation<a href="#fn32" class="footnoteRef" id="fnref32"><sup>32</sup></a> des bekannten und freien BitTorrent Protokoll zur Übertragung. Vom Feature–Umfang ist es in etwa vergleichbar mit <code>syncthing</code>. Das Anlegen von verschlüsselten Repositories ist möglich.</p>
<p>Genauere Aussagen über die verwendete Technik kann man aufgrund der geschlossenen Natur des Programms und der eher vagen Werbeprosa nicht treffen. Ähnlich zu <code>syncthing</code> ist allerdings, dass eine Versionsverwaltung nur mittels eines »Archivordners« vorhanden ist. Gelöschte Dateien werden in diesen Ordner verschoben und können von dort wiederhergestellt werden. Etwas mehr Details liefert der Vergleich des <em>Infinit</em>–Projekts.<a href="#fn33" class="footnoteRef" id="fnref33"><sup>33</sup></a></p>
<h3 id="git-annex"><span class="header-section-number">2.4.5</span> <code>git-annex</code></h3>
<a name="fig:scrn-git-annex"></a>
<div class="figure">
<img src="images/2/git-annex-assistant.png" alt="Figure 9: Figure 9. Screenshot des git-annex–Assistenten." id="fig:scrn-git-annex" />
<p class="caption">Figure 9: Figure 9. Screenshot des <code>git-annex</code>–Assistenten<a href="#fn34" class="footnoteRef" id="fnref34"><sup>34</sup></a>.</p>
</div>
<p>Das 2010 erstmals von Joey Hess veröffentlichte <code>git-annex</code><a href="#fn35" class="footnoteRef" id="fnref35"><sup>35</sup></a> geht in vielerlei Hinsicht einen anderen Weg als die oben genannten Werkzeuge. Einerseits ist es in der funktionalen Programmiersprache Haskell geschrieben, andererseits nutzt es intern das Versionsverwaltungssystem <code>git</code><span class="citation">[32]</span>, um die Metadaten zu den Dateien abzuspeichern, die es verwaltet. Auch werden Dateien standardmäßig nicht automatisch synchronisiert, hier ist die Grundidee die Dateien selbst zu »pushen«, beziehungsweise zu »pullen«.</p>
<p>Dieser »Do-it-yourself« Ansatz ist sehr nützlich, um <code>git-annex</code> als Teil der eigenen Anwendung einzusetzen. Für den alltäglichen Gebrauch scheint es aber selbst für erfahrene Anwender zu kompliziert, um es praktikabel einzusetzen.</p>
<p>Trotzdem sollen zwei interessante Features genannt werden, welche auch für <code>brig</code> interessant sind:</p>
<ul>
<li><em>Special Remotes:</em> »Datenablagen« bei denen <code>git-annex</code> nicht installiert sein muss. Damit können beliebige Cloud–Dienste als Speicher genutzt werden.</li>
<li><em>N-Copies:</em> Von wichtigen Dateien kann <code>git-annex</code> bis zu <code>N</code> Kopien speichern. Versucht man eine Kopie zu löschen, so verweigert <code>git-annex</code> dies.</li>
</ul>
<h3 id="weitere-alternativen"><span class="header-section-number">2.4.6</span> Weitere Alternativen</h3>
<p>Obwohl <code>brig</code> eine gewisse Ähnlichkeit mit verteilten Dateisystemen, wie <em>GlusterFS</em> hat, wurden diese in der Übersicht weggelassen — einerseits aus Gründen der Übersicht, andererseits weil diese andere Ziele verfolgen und von Heimanwendern kaum genutzt werden. Zudem ist der Vollständigkeit halber auch <em>OpenPGP</em><a href="#fn36" class="footnoteRef" id="fnref36"><sup>36</sup></a> zu nennen, was viele Nutzer zum Verschlüsseln von E-Mails benutzen. Aber auch hier ist der größte Nachteil die für den Otto–Normal–Nutzer schwierige Einrichtung und Benutzung. Auch das freie Projekt <code>librevault</code><a href="#fn37" class="footnoteRef" id="fnref37"><sup>37</sup></a> wurde im Vergleich ausgelassen, da es sich noch im Alpha–Stadium befindet und bei einem Test reproduzierbar abstürzte.</p>
<h3 id="zusammenfassung"><span class="header-section-number">2.4.7</span> Zusammenfassung</h3>
<p>In tbl. <strong>??</strong> und tbl. <strong>??</strong> findet sich zusammenfassend eine Übersicht, mit den wichtigsten Unterscheidungsmerkmalen. Die Bewertung ist in Punkten wie <em>»Einfach nutzbar«</em> subjektiver Natur.</p>
<a name="tbl:table-technical-overview"></a>
<table>
<caption>Table 1. Vergleich der Software aus technischer Sicht</caption>
<thead>
<tr class="header">
<th></th>
<th><strong>Dezentral</strong></th>
<th><strong>Verschlüsselung im Client</strong></th>
<th><strong>Versionierung</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>Dropbox/Boxcryptor</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><code>ownCloud</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><code>syncthing</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><code>resilio</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><code>git-annex</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><code>infinit</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><code>brig</code> <em>(Prototyp)</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><code>brig</code> <em>(Ziel)</em></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<a name="tbl:table-practical-overview"></a>
<table>
<caption>Table 2. Vergleich der Software aus Nutzersicht</caption>
<thead>
<tr class="header">
<th></th>
<th><strong>FOSS</strong></th>
<th><strong>Einfach nutzbar</strong></th>
<th><strong>Einfache Installation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>Dropbox/Boxcryptor</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><code>ownCloud</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><code>syncthing</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><code>resilio</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><code>infinit</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><code>git-annex</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><code>brig</code> <em>(Prototyp)</em></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><code>brig</code> <em>(Ziel)</em></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Abschließend kann man sagen, dass <code>syncthing</code> dem Gedanken hinter <code>brig</code> am nächsten kommt. Der Hauptunterschied ist, dass die Basis hinter <code>brig</code> ein volles P2P–Netzwerk namens <code>ipfs</code> ist (dazu später mehr). Wie in den nächsten Kapiteln ersichtlich ist, eröffnet dieser Unterbau eine Reihe von Möglichkeiten, die <code>syncthing</code> nicht bieten kann<a href="#fn38" class="footnoteRef" id="fnref38"><sup>38</sup></a>.</p>
<h2 id="zielgruppen"><span class="header-section-number">2.5</span> Zielgruppen</h2>
<p>Die primären Zielgruppen von <code>brig</code> sind Unternehmen und Heimanwender. Aufgrund der starken Ende-zu-Ende Verschlüsselung ist <code>brig</code> allerdings auch insbesondere für Berufsgruppen attraktiv, bei denen eine hohe Diskretion bezüglich Datenschutz gewahrt werden muss. Hier wären in erster Linie Journalisten, Anwälte, Ärzte mit Schweigepflicht und auch Aktivisten und politisch verfolgte Minderheiten zu nennen.</p>
<p><strong>Unternehmen:</strong> Unternehmen können <code>brig</code> nutzen, um ihre Daten und Dokumente intern zu verwalten und zwischen Mitarbeitern zu teilen. Besonders sicherheitskritische Dateien entgehen so der Lagerung in Cloud–Services oder der Gefahr von Kopien auf potenziell unsicheren Mitarbeiter–Endgeräten. Größere Unternehmen verwalten dabei oft ein Rechenzentrum in dem firmeninterne Dokumente gespeichert werden. Von den Nutzern werden diese dann meist mittels Diensten wie <em>ownCloud</em><a href="#fn39" class="footnoteRef" id="fnref39"><sup>39</sup></a> »händisch« heruntergeladen. In diesem Fall könnte man <code>brig</code> im Rechenzentrum und auf allen Endgeräten installieren. Das Rechenzentrum würde die Datei mit tiefer Versionierung vorhalten. Endanwender würden alle Daten sehen, aber auf ihrem Gerät nur die Daten tatsächlich speichern, die sie auch benötigen. Hat beispielsweise ein Kollege im selben Büro die Datei bereits vorliegen, kann <code>brig</code> diese dann direkt transparent vom Endgerät des Kollegen holen. Das »intelligente Routing« erlaubt den Einsatz von <code>brig</code> auf Smartphones, Tablets und anderen speicherplatzlimitierten Geräten. Nutzer, die eine physikalische Kopie der Datei auf ihrem Gerät haben wollen, können das entsprechende Dokument »pinnen«. Ist ein Außendienstmitarbeiter beispielsweise im Zug unterwegs, kann er vorher ein benötigtes Dokument pinnen, damit <code>brig</code> die Datei persistent verfügbar macht.</p>
<p><strong>Privatanwender:</strong> Privatanwender können <code>brig</code> für ihren Datenbestand aus Fotos, Filmen, Musik und sonstigen Dokumenten nutzen. Ein typischer Anwendungsfall wäre dabei ein Network–Attached-Storage–Server (NAS), der alle Dateien mit niedriger Versionierung speichert. Endgeräte, wie Laptops und Smartphones, würden dann ebenfalls <code>brig</code> nutzen, aber mit deutlich geringeren Speicherquotas (maximales Speicherlimit), so dass nur die aktuell benötigten Dateien physikalisch auf dem Gerät vorhanden sind. Die anderen Dateien lagern im Netz und können transparent von <code>brig</code> von anderen verfügbaren Knoten geholt werden.</p>
<p><strong>Plattform:</strong> Da <code>brig</code> auch komplett automatisiert und ohne Interaktion nutzbar ist, kann es auch als Plattform für andere Anwendungen genutzt werden, die Dateien sicher austauschen und synchronisieren müssen. Eine Anwendung in der Industrie 4.0 wäre beispielsweise die Synchronisierung von Konfigurationsdateien im gesamten Netzwerk.</p>
<p><strong>Einsatz im öffentlichen Bereich:</strong> Aufgrund der Ende-zu-Ende Verschlüsselung und einfachen Usability ist eine Nutzung an Schulen, Universitäten sowie auch in Behörden zum Dokumentenaustausch denkbar. Vorteilhaft wäre für die jeweiligen Institutionen hierbei vor allem, dass man sich aufgrund des Open–Source–Modells an keinen Hersteller bindet (Stichwort: <em>Vendor Lock–In</em>) und keine behördlichen Daten in der Cloud landen. Eine praktische Anwendung im universitärem Bereich wäre die Verteilung von Studienunterlagen an die Studenten. Mangels einer Standardlösung ist es heutzutage schwierig Dokumente sicher mit Behörden auszutauschen. <code>brig</code> könnte hier einen Standard etablieren und in Zukunft als eine Plattform dienen, um beispielsweise medizinische Unterlagen mit einem Krankenhaus auszutauschen.</p>
<h2 id="einsatzszenarien"><span class="header-section-number">2.6</span> Einsatzszenarien</h2>
<p>Basierend auf den vorgestellten Nutzergruppen lassen sich einige konkrete Einsatzszenarien ableiten:</p>
<p><strong>Synchronisationslösung:</strong> Spiegelung von zwei oder mehr Ordnern und das Teilen derselben zwischen ein oder mehreren Nutzern. Ein häufiger Anwendungsfall ist dabei die Synchronisation zwischen mehreren Geräten eines einzigen Nutzers. Eine selektive Synchronisation bestimmter Ordner ist vorerst nicht vorgesehen.</p>
<p><strong>Transferlösung:</strong> Veröffentlichen von Dateien nach Außen mittels eines <em>Gateway</em> über den Browser. Eine beliebige Anzahl an anonymen Teilnehmern können die Datei herunterladen.</p>
<p><strong>Versionsverwaltung:</strong> Alle Modifikationen an den bekannten Dateien werden aufgezeichnet. Bis zu einer bestimmten Tiefe können Dateien wiederhergestellt werden.</p>
<p><strong>Backup- und Archivierungslösung:</strong> Es ist möglich Knoten so zu konfigurieren, dass alle Dateien gepinned werden. Ein solcher Knoten kann dann anderen Teilnehmern automatisch als Archiv für alte Dateien dienen.</p>
<p><strong>Verschlüsselter Safe:</strong> Da alle Dateien verschlüsselt sind, müssen sie beim Zugriff der Software erst entschlüsselt werden. Da die entschlüsselten Daten nur im Hauptspeicher vorgehalten werden, ist nach Beenden der Software kein Zugriff mehr möglich.</p>
<p>Es gibt natürlich auch einige Einsatzzwecke, für die <code>brig</code> weniger geeignet ist. Diese werden in sec. 8 beleuchtet, da die dortige Argumentation teilweise ein Verständnis von der internen Architektur benötigt.</p>
<h2 id="sec:assumptions"><span class="header-section-number">2.7</span> Annahmen während der Konzeption</h2>
<p>Das Design von <code>brig</code> basiert auf einigen Annahmen, die im Voraus getroffen werden mussten:</p>
<p><strong>Durchschnittliche Netzwerkkonfiguration:</strong> Für den Prototypen wird ein normales Heimnetzwerk mit mehren Computern angenommen, welche typischerweise hinter einem NAT liegen. Diese sollen sich mit anderen Computern in anderen Heimnetzwerken über das Internet austauschen können.</p>
<p><strong>Durchschnittlicher Arbeitsrechner:</strong> Das Design wurde nicht auf leistungsschwache Hardware ausgerichtet. Ausgegangen wird von einem »normalen« Arbeitsrechner. Normal wird hier definiert durch Vorhandensein eines typischen Mehrkernprozessors aus dem Jahr 2008 oder später und mindestens 2 Gigabyte Arbeitsspeicher. Der Internetanschluss sollte ein Download von mindestens 4 Mbit/s<a href="#fn40" class="footnoteRef" id="fnref40"><sup>40</sup></a> besitzen und ein Upload von 1 Mbit/s.</p>
<p><strong>Stabilität von <code>ipfs:</code></strong> Es wird angenommen, dass <code>ipfs</code> stetig weiterentwickelt wird und im momentanen Zustand keine gravierenden Sicherheitsmängel enthält. Zudem wird angenommen, dass es für die Zwecke von <code>brig</code> ausreichend hohe Performanz bietet.</p>
<p><strong>Keine Kollision der Prüfsummen:</strong> <code>brig</code> kann (genau wie <code>ipfs</code>) Dateien nicht auseinanderhalten, die einen unterschiedlichen Inhalt besitzen, aber die selbe Prüfsumme erzeugen. Auch wenn dieser Fall in der Theorie eintreten kann, so ist dieser extrem schwer zu erreichen. Der von <code>ipfs</code> standardmäßig verwendete Algorithmus ist <em>sha256</em><a href="#fn41" class="footnoteRef" id="fnref41"><sup>41</sup></a>, welcher eine Prüfsumme von 256 Bit Länge liefert. Wie in eq. 1 gezeigt, müssten trotz des Geburtstagsparadoxons<span class="citation">[29]</span> unpraktikabel viele Prüfsummen erzeugt werden, um eine Kollisionswahrscheinlichkeit von <span class="math inline">0.1%</span> zu erreichen, selbst wenn man sehr optimistisch annimmt, dass die Berechnung einer einzigen Prüfsumme nur eine Pikosekunde dauert.</p>
<p><br /><span class="math display">$$(\frac{1}{1000} \times 2^{\frac{256}{2}}) \times 10^{-12}s \simeq 10^{35.5} \times 10^{-12}s \simeq 10^{15} \text{Jahre}\qquad(1)$$</span><br /></p>
<h1 id="sec:requirements"><span class="header-section-number">3</span> Anforderungen</h1>
<p>Im Folgenden wird auf die Anforderungen eingegangen, welche <code>brig</code> in Zukunft erfüllen soll. Diese sind weitreichender als der Umfang der aktuellen Implementierung. Die Anforderungen lassen sich in drei Kategorien unterteilen:</p>
<ul>
<li><strong>Anforderungen an die Integrität:</strong> <code>brig</code> muss die Daten, die es speichert, versionieren, auf Integrität prüfen können und korrekt wiedergeben.</li>
<li><strong>Anforderungen an die Sicherheit:</strong> Alle Daten, die <code>brig</code> anvertraut werden, sollten sowohl bei der Speicherung auf der Festplatte als auch bei der Übertragung zwischen Partnern verschlüsselt werden. Die Implementierung der Sicherheitstechniken sollte transparent von Nutzern und Experten nachvollzogen werden können.</li>
<li><strong>Anforderungen an die Usability:</strong> Die Software soll möglichst einfach zu nutzen und zu installieren sein. Der Nutzer soll <code>brig</code> auf den populärsten Betriebssystemen nutzen können und auch Daten mit Nutzern anderer Betriebssysteme austauschen können.</li>
</ul>
<p>Die Kategorien beinhalten einzelne, konkretere Anforderungen, die im Folgenden aufgelistet und erklärt werden. Dabei wird jeweils im ersten Paragraphen die eigentliche Anforderung formuliert und danach kurz beispielhaft erklärt. Ob und wie die Anforderung letztlich erfüllt wurde, wird in sec. 8 betrachtet.</p>
<p>Nicht jede Anforderung kann dabei voll umgesetzt werden. Teils überschneiden oder widersprechen sich Anforderungen an die Sicherheit und an die Effizienz, da beispielsweise verschlüsselte Speicherung mehr Prozessor–Ressourcen in Anspruch nimmt. Auch ist hohe Usability bei gleichzeitig hohen Sicherheitsanforderungen schwierig umzusetzen. Die Neueingabe eines Passworts bei jedem Zugriff mag sicherer sein, aber eben kaum benutzerfreundlich. Daher muss bei der Erfüllung der Anforderungen eine Priorisierung erfolgen. Im Zweifel wurde sich beim Entwurf von <code>brig</code> primär für die Usability entschieden. Zwar kann ein sehr sicheres System den Nutzer beschützen, doch wird der Nutzer es ungern einsetzen wollen, wenn es aufwendig zu bedienen ist. Das heißt allerdings keineswegs, dass <code>brig</code> »per Entwurf« unsicher ist. Es wurde darauf geachtet, dass Sicherheitstechniken den Benutzer möglichst wenig im Weg stehen und eher in den Hintergrund treten. Rob Pike hat diesen Punkt überspitzt, aber prägnant dargestellt:</p>
<blockquote>
<p><em>Weak security that’s easy to use will help more people than strong security that’s hard to use. Door locks are a good example.</em></p>
<p>— Rob Pike (<span class="citation">[31]</span> S.24)</p>
</blockquote>
<p>Die untenstehenden Anforderungen sind teilweise an die Eigenschaften des verteilten Dateisystems <em>Infinit</em> (beschrieben in <span class="citation">[26]</span>, siehe S.39) angelehnt und an die Ausrichtung von <code>brig</code> angepasst worden.</p>
<h2 id="anforderungen-an-die-integrität"><span class="header-section-number">3.1</span> Anforderungen an die Integrität</h2>
<p><strong>Entkopplung von Metadaten und tatsächlichen Daten:</strong> Statt einem zentralen Dienst, soll <code>brig</code> die Basis eines dezentralen Netzwerkes bilden. Dabei stellt jeder Teilnehmer einen Knoten in diesem Netzwerk dar. Nutzer des Netzwerkes können Dateien untereinander synchronisieren. Dabei muss nicht zwangsweise die gesamte Datei übertragen werden, jeder Nutzer verwaltet lediglich eine Liste der Metadaten der Dateien, die jeder Teilnehmer besitzt. Durch diese Entkopplung ist es möglich, bestimmte Dateien »on–demand« und für den Nutzer transparent zu übertragen.</p>
<p>Der Hauptvorteil einer dezentralen Architektur ist die erhöhte Ausfallsicherheit (kein <em>Single–Point–of–Failure</em>) und der Fakt, dass das Netzwerk durch seine Nutzer entsteht und keine eigene Infrastruktur benötigt. <code>brig</code> funktioniert daher als <em>Overlay–Netzwerk</em> (Siehe <span class="citation">[23]</span>, S.8) über das Internet.</p>
<p><strong>Pinning:</strong> Der Nutzer soll Kontrolle darüber haben, welche Dateien er lokal auf seinem Rechner speichert und welche er von anderen Teilnehmern dynamisch empfangen will. Dazu wird das Konzept des »Pinnings« und der »Quota« eingeführt. Ein Nutzer kann eine Datei manuell <em>pinnen</em>, um sie auf seinem lokalen Rechner zu behalten oder um <code>brig</code> anzuweisen, sie aus dem Netzwerk zu holen und lokal zwischenzulagern. Dateien, die <code>brig</code> explizit hinzugefügt wurden, werden implizit mit einem <em>Pin</em> versehen. Die <em>Quota</em> hingegen beschreibt ein Limit an Bytes, die lokal zwischengespeichert werden dürfen. Wird dies überschritten, so werden Daten gelöscht, die keinen Pin haben.</p>
<p>Das manuelle Pinnen von Dateien ist insbesondere nützlich, wenn eine bestimmte Datei zu einem Zeitpunkt ohne Internetzugang benötigt wird. Ein Beispiel wäre ein Zugpendler, der ein Dokument auf dem Weg zur Arbeit editieren möchte. Er kann dieses vorher <em>pinnen</em>, um es lokal auf seinem Laptop zu lagern.</p>
<p><strong>Langlebigkeit:</strong> Daten, die <code>brig</code> anvertraut werden, müssen solange ohne Veränderung und Datenverlust gespeichert werden bis kein Nutzer mehr diese Datei benötigt.</p>
<p>Dabei ist zu beachten, dass diese Anforderung nur mit einer gewissen Wahrscheinlichkeit erfüllt werden kann, da heutige Hardware nicht die Integrität der Daten gewährleisten kann. So können beispielsweise Bitfehler<a href="#fn42" class="footnoteRef" id="fnref42"><sup>42</sup></a> bei der Verarbeitung im Hauptspeicher oder konventionelle Festplatten mit beschädigten Platten die geschriebenen Daten verändern. Ist die Datei nur einmal gespeichert worden, kann sie von Softwareseite aus nicht mehr fehlerfrei hergestellt werden. Um diese Fehlerquelle zu verkleinern sollte eine Möglichkeit zur redundanten Speicherung geschaffen werden, bei der eine minimale Anzahl von Kopien einer Datei konfiguriert werden kann.</p>
<p><strong>Verfügbarkeit:</strong> Alle Daten die <code>brig</code> verwaltet sollen stets erreichbar sein und bleiben. In der Praxis ist dies natürlich nur möglich, wenn alle Netzwerkteilnehmer ohne Unterbrechung zur Verfügung stehen oder wenn alle Dateien lokal zwischengelagert worden sind.</p>
<p>Oft sind viele Nutzer zu unterschiedlichen Zeiten online oder leben in komplett verschiedenen Zeitzonen. Aufgrund der Zeitverschiebung wäre eine Zusammenarbeit zwischen einem chinesischen und einem deutschen Nutzer schwierig. Eine mögliche Lösung wäre die Einrichtung eines automatisierten Knoten der ständig verfügbar ist. Statt Dateien direkt miteinander zu teilen, könnten Nutzer diesen Knoten als Zwischenlager benutzen. Falls nötig, soll es also auch möglich sein den Vorteil eines zentralen Ansatzes (also seine permanente Erreichbarkeit) mit <code>brig</code> zu kombinieren.</p>
<p><strong>Integrität:</strong> Es muss sichergestellt werden, dass absichtliche oder unabsichtliche Veränderungen an den Daten festgestellt werden können.</p>
<p>Unabsichtliche Änderungen können wie oben beschrieben beispielsweise durch fehlerhafte Hardware geschehen. Absichtliche Änderungen können durch Angriffe von außen passieren, bei denen gezielt Dateien von einem Angreifer manipuliert werden. Als Beispiel könnte man an einen Schüler denken, welcher unbemerkt seine Noten in der Datenbank seiner Schule manipulieren will. Aus diesem Grund sollte das Dateiformat von <code>brig</code> mittels <em>Message Authentication Codes</em> (MACs) sicherstellen können, dass die gespeicherten Daten den ursprünglichen Daten entsprechen.</p>
<h2 id="anforderungen-an-die-sicherheit"><span class="header-section-number">3.2</span> Anforderungen an die Sicherheit</h2>
<p><strong>Verschlüsselte Speicherung:</strong> Die Daten sollten verschlüsselt auf der Festplatte abgelegt werden und nur bei Bedarf wieder entschlüsselt werden. Kryptografische Schlüssel sollten aus denselben Gründen nicht unverschlüsselt auf der Platte, sondern nur im Hauptspeicher abgelegt werden.</p>
<p>Wie in sec. 2 beleuchtet wurde, speichern die meisten Dienste und Anwendungen zum Dateiaustausch ihre Dateien in keiner verschlüsselten Form. Es gibt allerdings eine Reihe von Angriffsszenarien (siehe auch <span class="citation">[27]</span>), die durch eine Vollverschlüsselung der Daten verhindert werden können.</p>
<p><strong>Verschlüsselte Übertragung:</strong> Bei der Synchronisation zwischen Teilnehmern sollte der gesamte Verkehr ebenfalls verschlüsselt erfolgen. Nicht nur die Dateien selbst, sondern auch die dazugehörigen Metadaten sollen Ende–zu–Ende verschlüsselt werden.</p>
<p>Die Verschlüsselung der Metadaten erscheint vor allem im Lichte der Enthüllungen zur NSA–Affäre geboten<a href="#fn43" class="footnoteRef" id="fnref43"><sup>43</sup></a>. Eine Ende–zu–Ende Verschlüsselung ist in diesem Fall vor allem deswegen wichtig, weil der Datenverkehr auch über andere, ansonsten unbeteiligte, Knoten im Netzwerk gehen kann.</p>
<p><strong>Authentifizierung:</strong> <code>brig</code> sollte die Möglichkeit bieten zu überprüfen, ob Synchronisationspartner wirklich diejenigen sind, die sie vorgeben zu sein. Dabei muss zwischen der initialen Authentifizierung und der fortlaufenden Authentifizierung unterschieden werden. Bei der initialen Authentifizierung wird neben einigen Sicherheitsfragen ein Fingerprint des Kommunikationspartners übertragen, welcher bei der fortlaufenden Authentifizierung auf Änderung überprüft wird.</p>
<p>Mit welchen Partnern synchronisiert werden soll und wie vertrauenswürdig diese sind kann <code>brig</code> nicht selbstständig ermessen. Man kann allerdings dem Nutzer Hilfsmittel geben, um die Identität des Gegenüber zu überprüfen. So könnten Werkzeuge angeboten werden, mithilfe deren der Nutzer dem potenziellen Partner eine Frage (mit vordefinierter Antwort) schicken kann, die dieser dann beantworten muss. Alternativ können sich beide Partner vorher auf einem separaten Kanal auf ein gemeinsames Geheimnis einigen, welches dann über <code>brig</code> ausgetauscht und überprüft werden kann. Diese beiden Möglichkeiten sind ähneln der OTR–Implementierung des Instant-Messanger Pidgin<a href="#fn44" class="footnoteRef" id="fnref44"><sup>44</sup></a>.</p>
<p><strong>Identität:</strong> Jeder Benutzer des Netzwerks muss eine öffentliche Identität besitzen, welche ihn eindeutig identifiziert. Gekoppelt mit der öffentlichen Identität soll jeder Nutzer ein überprüfbares Geheimnis kennen, mithilfe dessen er sich gegenüber anderen authentifizieren kann. Zusätzlich dazu sollte es einen menschenlesbaren Nutzernamen für jeden Teilnehmer geben. Dieser sollte zur öffentlichen Identität des jeweiligen Nutzers auflösbar sein. Eine Registrierung bei einer zentralen Stelle soll nicht benötigt werden.</p>
<p><strong>Transparenz:</strong> Die Implementierung aller oben genannten Sicherheitsfeatures muss für Anwender und Entwickler nachvollziehbar und verständlich sein. Durch die Öffnung des gesamten Quelltextes können Entwickler den Code auf Fehler überprüfen. Normale Anwender können die Arbeit von Herrn Piechula (siehe <span class="citation">[27]</span>) lesen, um für die Themantik der Sicherheit sensibilisiert zu werden und ein Überblick über die Sicherheit von <code>brig</code> zu bekommen. Dort wird auch das Entwicklungsmodell besprochen, welches helfen soll, sichere Software zu entwickeln.</p>
<h2 id="anforderungen-an-die-usability"><span class="header-section-number">3.3</span> Anforderungen an die Usability</h2>
<p><em>Anmerkung:</em> In sec. 7 werden weitere Anforderungen zur Usability in Bezug auf eine grafische Oberfläche definiert. Da diese nicht für die Gesamtheit der Software relevant sind, werden sie hier ausgelassen.</p>
<p><strong>Automatische Versionierung:</strong> Die Dateien die <code>brig</code> verwaltet, sollen automatisch versioniert werden. Die Versionierung soll dabei in Form von <em>Checkpoints</em> bei jeder Dateiänderung erfolgen. Mehrere Checkpoints können manuell oder per <em>Timer</em> in einem zusammenhängenden <em>Commit</em> zusammengefasst werden. Die Menge an Dateien, die in alter Version vorhanden sind, sollen durch eine Speicher-Quota geregelt werden, die nicht überschritten werden darf. Wird dieses Limit überschritten, so werden die ältesten Dateien von der lokalen Maschine gelöscht. Die jeweiligen Checkpoints sind aber noch vorhanden und der darin referenzierte Stand kann von anderen Teilnehmern aus dem Netzwerk geholt werden, falls verfügbar.</p>
<p>Nutzer tendieren oft dazu mehrere Kopien einer Datei unter verschiedenen Orten als Backup anzulegen. Leider artet dies erfahrungsgemäß in der Praxis oft dazu aus, dass Dateinamen wie <code>FINAL-rev2.pdf</code> oder <code>FINAL-rev7.comments.pdf</code> entstehen. Daher wäre für viele Nutzer eine automatisierte und robuste Versionierung wünschenswert.</p>
<p><strong>Portabilität:</strong> <code>brig</code> soll in möglichst portabler Weise implementiert werden, um die zunehmende Fragmentierung des Betriebssystemmarkts<span class="citation">[17]</span> zu berücksichtigen. Es sollen neben den populärsten Systemen wie Windows, macOS und GNU/Linux auf lange Sicht auch mobile Plattformen wie Android unterstützt werden.</p>
<p><strong>Einfache Installation:</strong> <code>brig</code> sollte möglichst einfach und ohne Vorkenntnisse installierbar sein. Zur Installation gehört dabei nicht nur die Beschaffung der Software und deren eigentliche Installation, sondern auch die initiale Konfiguration. Die Erfahrungen des Autors haben gezeigt, dass Nutzer oft eine einfach zu installierende Software bevorzugen, obwohl eine schwerer zu installierende Software, ihr Problem möglicherweise besser löst.</p>
<p><strong>Keine künstlichen Limitierungen:</strong> Mit <code>brig</code> sollten die gleichen für den Nutzer gewohnten Operationen und Limitierungen gelten, wie bei einem normalen Dateisystem. Als Datei wird in diesem Kontext ein Datenstrom verstanden, der unter einem bestimmten Pfad im Dateisystem ausgelesen oder beschrieben werden kann. Ihm zugeordnet sind Metadaten, wie Größe, Änderungsdatum und Zugriffsdatum. Dateien sollen kopiert, verschoben und gelöscht werden können. Zudem sollten keine Limitierungen der Pfadlänge oder der Dateigröße durch <code>brig</code> erfolgen. Auch soll keine bestimmte Enkodierung des Pfadnamens forciert werden.</p>
<p><strong>Generalität:</strong> Die Nutzung von Techniken, die den Nutzerstamm auf bestimmte Plattformen einschränkt oder den Kauf zusätzlicher, spezieller Hardware benötigt, ist nicht erlaubt. Beispielsweise der Einsatz von plattformspezifischen Dateisystemen wie btrfs<a href="#fn45" class="footnoteRef" id="fnref45"><sup>45</sup></a> oder ZFS<a href="#fn46" class="footnoteRef" id="fnref46"><sup>46</sup></a> zur Speicherung entfällt daher. Auch darf nicht vorausgesetzt werden, dass alle Nutzer <code>brig</code> verwenden, da dies ein Lock–in wie bei anderen Produkten bedeuten würde.</p>
<p>Ein häufiger Anwendungsfall ist ein Nutzer, der ein bestimmtes Dokument anderen Nutzern zu Verfügung stellen möchte. Optimalerweise müssen dabei die Empfänger des Dokuments keine weitere Software installiert haben, sondern können die Datei einfach mittels eines Hyperlinks in ihrem Browser herunterladen. Zentrale Dienste können dies relativ einfach leisten, indem sie einen Webservice anbieten, welcher die Datei von einer zentralen Stelle herunterladbar macht. Ein dezentrales Netzwerk wie <code>brig</code> muss hingegen <em>Gateways</em> anbieten, also eine handvoll Dienste, welche zwischen den »normalen Internet« und dem <code>brig</code>–Netzwerk vermitteln (siehe fig. 10). Nutzer, welche die Dateien verteilen wollen, können ein solches Gateway selbst betreiben oder können ein von Freiwilligen betriebenes Gateway benutzen.</p>
<a name="fig:gateway"></a>
<div class="figure">
<img src="images/7/gateway.png" id="fig:gateway" />
<p class="caption">Figure 10: Figure 10. Schematischer Aufbau eines HTTPS–Gateways.</p>
</div>
<p><strong>Stabilität:</strong> Die Software muss bei normaler Benutzung ohne Abstürze und offensichtliche Fehler funktionieren. Eine umfangreiche Testsuite soll die Fehlerquote der Software minimieren, quantisierbar machen und die Weiterentwicklung erleichtern. Spätestens nach der Veröffentlichung der Software, sollten auch Regressionstests<a href="#fn47" class="footnoteRef" id="fnref47"><sup>47</sup></a> das erneute Auftreten von bereits reparierten Fehlern vermeiden.</p>
<p><strong>Effizienz:</strong> Die Geschwindigkeit der Software auf durchschnittlicher Hardware (siehe sec. 2.7) soll schnell genug sein, um dem Anwender ein flüssiges Arbeiten ermöglichen zu können. Die Geschwindigkeit sollte durch eine Benchmarksuite messbar gemacht werden und bei jedem neuen Release mit dem Vorgänger verglichen werden.</p>
<h1 id="sec:grundlagen"><span class="header-section-number">4</span> Grundlagen</h1>
<p>Für das Verständnis der Architektur von <code>brig</code> ist die Erklärung einiger Internas von <code>ipfs</code> und dem freien Versionsverwaltungssystem <code>git</code> nötig. Diese werden im Folgenden gegeben.</p>
<h2 id="ipfs-das-interplanetary-filesystem"><span class="header-section-number">4.1</span> <code>ipfs</code>: Das <em>Interplanetary Filesystem</em></h2>
<p>Anstatt das »Rad neu zu erfinden«, setzt <code>brig</code> auf das relativ junge <em>Interplanetary Filesystem</em> (kurz <code>ipfs</code>), welches von Juan Benet und seinen Mitentwicklern unter der MIT–Lizenz in der Programmiersprache Go entwickelt wird (siehe auch das Whitepaper<span class="citation">[4]</span>). Im Gegensatz zu den meisten anderen verfügbaren Peer–to-Peer Netzwerken kann <code>ipfs</code> als Software–Bibliothek genutzt werden. Dies ermöglicht es <code>brig</code> als, vergleichsweise dünne Schicht, zwischen Benutzer und <code>ipfs</code> zu fungieren (wie in fig. 11 dargestellt).</p>
<a name="fig:fuse-brig-ipfs"></a>
<div class="figure">
<img src="images/3/fuse-brig-ipfs.png" id="fig:fuse-brig-ipfs" style="width:30.0%" />
<p class="caption">Figure 11: Figure 11. Zusammenhang zwischen <code>ipfs</code>, <code>brig</code> und FUSE.</p>
</div>
<p><code>Ipfs</code> stellt dabei ein <em>Content Addressed Network</em> (kurz <em>CAN</em><a href="#fn48" class="footnoteRef" id="fnref48"><sup>48</sup></a>) dar. Dabei wird eine Datei, die in das Netzwerk gelegt wird nicht mittels eines Dateinamen angesprochen, sondern mittels einer Prüfsumme, die durch eine vorher festgelegte Hashfunktion berechnet wird. Andere Teilnehmer im Netzwerk können mittels dieser Prüfsumme die Datei lokalisieren und empfangen. Anders als bei einer HTTP–URL (<em>Unified Resource Locator</em>) steckt in der Prüfsumme einer Datei also nicht nur die Lokation der Datei, sondern sie dient auch als eindeutiges Identifikationsmerkmal (ähnlich eines Pfads) und gleicht daher eher einem Magnet Link<a href="#fn49" class="footnoteRef" id="fnref49"><sup>49</sup></a> als einer URL. Vereinfacht gesagt ist es nun die Hauptaufgabe von <code>brig</code> dem Nutzer die gewohnte Abstraktionsschicht eines Dateisystems zu geben, während im Hintergrund jede Datei zu einer Prüfsumme aufgelöst wird.</p>
<p>Im Vergleich zu zentralen Ansätzen können Dateien intelligent geroutet werden und müssen nicht physikalisch auf allen Geräten verfügbar sein. Eine Datei kann »im Netzwerk liegen«. Greift der Nutzer über ihre Prüfsumme darauf zu, wird sie vom <em>CAN</em> intelligent aus dem Netzwerk geholt, sofern sie lokal nicht vorhanden ist. Dabei wird die Datei typischerweise in kleine Blöcke unterteilt, welche einzeln verteilt und geholt werden können. Daher müssen beispielsweise bei einem Netzwerkfehler nur alle Blöcke heruntergeladen werden, die noch fehlen.</p>
<p>Technisch basiert <code>ipfs</code> auf der Distributed–Hashtable <em>Kademlia</em> (vgl. <span class="citation">[19]</span> und <span class="citation">[23]</span>, S. 247), welches mit den Erkenntnissen aus den Arbeiten <em>CoralDHST</em><span class="citation">[13]</span> (Ansatz um das Routing zu optimieren) und <em>S/Kademlia</em><span class="citation">[2]</span> (Ansatz um das Netzwerk gegen Angriffe zu schützen) erweitert und abgesichert wurde. <em>S/Kademlia</em> verlangt dabei, dass jeder Knoten im Netzwerk über ein Schlüsselpaar verfügt, bestehend aus einem öffentlichen und privaten Schlüssel. Die Prüfsumme des öffentlichen Schlüssels dient dabei als einzigartige Identifikation des Knotens und der private Schlüssel dient als Geheimnis mit dem ein Knoten seine Identität nachweisen kann. Diese Kernfunktionalitäten sind bei <code>ipfs</code> in einer separaten Bibliothek namens <code>libp2p</code><a href="#fn50" class="footnoteRef" id="fnref50"><sup>50</sup></a> untergebracht, welche auch von anderen Programmen genutzt werden können.</p>
<h3 id="sec:ipfs-attrs"><span class="header-section-number">4.1.1</span> Eigenschaften des <em>Interplanetary Filesystems</em></h3>
<p>Im Folgenden werden die Eigenschaften von <code>ipfs</code> kurz vorgestellt, welche von <code>brig</code> genutzt werden. Einige interessante Features wie beispielsweise das <em>Interplanetary Naming System</em> (IPNS) werden dabei ausgelassen, da sie für <code>brig</code> aktuell keine praktische Bedeutung haben.</p>
<p><strong>Weltweites Netzwerk:</strong> Standardmäßig bilden alle <code>ipfs</code>–Knoten ein zusammenhängendes, weltweites Netzwerk. <code>ipfs</code> verbindet sich beim Start mit einigen, wohlbekannten <em>Bootstrap–Nodes</em>, deren Adressen mit der Software mitgeliefert werden. Diese können dann wiederum den neuen Knoten an ihnen bekannte, passendere Knoten vermitteln. Die Menge der so entstandenen verbundenen Knoten nennt <code>ipfs</code> den <em>Swarm</em> (dt. Schwarm). Ein Nachbarknoten wird auch <em>Peer</em> genannt.</p>
<p>Falls gewünscht, kann allerdings auch ein abgeschottetes Subnetz erstellt werden. Dazu ist es lediglich nötig, die <em>Bootstrap</em>–Nodes durch Knoten auszutauschen, die man selbst kontrolliert. Unternehmen könnten diesen Ansatz wählen, falls ihr Netzwerk komplett von der Außenwelt abgeschottet sein soll. Wie in sec. 5 beleuchtet wird, ist eine Abschottung des Netzwerks rein aus Sicherheitsgründen nicht zwingend nötig.</p>
<p><strong>Operation mit Prüfsummen:</strong> <code>ipfs</code> arbeitet nicht mit herkömmlichen Dateipfaden, sondern nur mit der Prüfsumme einer Datei. Im folgenden Beispiel wird eine Fotodatei mittels der <code>ipfs</code>–Kommandozeile in das Netzwerk gelegt<a href="#fn51" class="footnoteRef" id="fnref51"><sup>51</sup></a>:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">ipfs</span> add my-photo.png
<span class="ex">QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG</span></code></pre></div>
<p>Wird eine Datei modifiziert, so muss sie neu mittels <code>ipfs add</code> hinzugefügt werden und wird in dieser Version unter einer anderen Prüfsumme erreichbar sein. Im Gegensatz zu normalen Dateisystemen kann es keinen allgemeinen Einstiegspunkt (wie das Wurzelverzeichnis »<code>/</code>«) geben. Die Prüfsumme eines Verzeichnisses definiert sich in <code>ipfs</code> durch die Prüfsummen seiner Inhalte. Das Wurzelverzeichnis hätte also nach jeder Modifikation eine andere Prüfsumme.</p>
<p><code>ipfs</code> nutzt dabei ein spezielles Format um Prüfsummen zu repräsentieren<a href="#fn52" class="footnoteRef" id="fnref52"><sup>52</sup></a>. Die ersten zwei Bytes einer Prüfsumme repräsentieren dabei den verwendeten Algorithmus und die Länge der darauf folgenden, eigentlichen Prüfsumme. Die entstandene Byte–Sequenz wird dann mittels <code>base58</code><a href="#fn53" class="footnoteRef" id="fnref53"><sup>53</sup></a> enkodiert, um sie menschenlesbar zu machen. Da der momentane Standardalgorithmus <code>sha256</code> ist, beginnt eine von <code>ipfs</code> generierte Prüfsumme stets mit »<code>Qm</code>«. Abbildung fig. 12 zeigt dafür ein Beispiel.</p>
<a name="fig:ipfs-hash-format"></a>
<div class="figure">
<img src="images/2/ipfs-hash-layout.png" id="fig:ipfs-hash-format" style="width:80.0%" />
<p class="caption">Figure 12: Figure 12. Layout der <code>ipfs</code> Prüfsumme.</p>
</div>
<p>Auf einem anderen Computer, mit laufenden <code>ipfs</code>–Daemon, ist das Empfangen der Datei möglich, indem die Prüfsumme an das Kommando <code>ipfs cat</code> gegeben wird. Dabei wird für den Nutzer transparent über die DHT ein Peer ausfindig gemacht, der die Datei anbieten kann und der Inhalt von diesem bezogen:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">ipfs</span> cat QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG <span class="op">&gt;</span> my-photo.png</code></pre></div>
<p><strong>Public–Key Infrastructure:</strong> Jeder Knoten im <code>ipfs</code>–Netzwerk besitzt ein RSA–Schlüsselpaar, welches beim Anlegen des Repositories erzeugt wird. Mittels einer Prüfsumme wird aus dem öffentlichen Schlüssel eine Identität berechnet (<span class="math inline">Id = <em>H</em><sub><em>s</em><em>h</em><em>a</em>256</sub>(<em>K</em><sub><em>P</em><em>u</em><em>b</em><em>l</em><em>i</em><em>c</em></sub>)</span>). Diese kann dann dazu genutzt werden, einen Knoten eindeutig zu identifizieren und andere Nutzer im Netzwerk nachzuschlagen und deren öffentlichen Schlüssel zu empfangen:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># Nachschlagen des öffentlichen Schlüssels eines zufälligen Bootstrap-Nodes:</span>
$ <span class="ex">ipfs</span> id QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ
<span class="kw">{</span>
  <span class="st">&quot;ID&quot;</span>: <span class="st">&quot;QmaCpDMGvV2BGHeYERUEnRQAwe3N8SzbUtfsmvsqQLuvuJ&quot;</span>,
  <span class="st">&quot;PublicKey&quot;</span>: <span class="st">&quot;CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK[...]&quot;</span>,
  <span class="ex">...</span>
<span class="kw">}</span></code></pre></div>
<p>Der öffentliche Schlüssel kann dazu genutzt werden, mit einem Peer mittels asymmetrischer Verschlüsselung eine verschlüsselte Verbindung aufzubauen (siehe <span class="citation">[27]</span>). Von <code>brig</code> wird dieses Konzept weiterhin genutzt, um eine Liste vertrauenswürdiger Knoten zu verwalten. Jeder Peer muss bei Verbindungsaufbau nachweisen, dass er den zum öffentlichen Schlüssel passenden privaten Schlüssel besitzt (für Details siehe <span class="citation">[27]</span>).</p>
<p><strong>Pinning und Caching:</strong> Das Konzept von <code>ipfs</code> basiert darauf, dass Knoten nur das speichern, woran sie auch interessiert sind. Daten, die von Außen zum eigenen Knoten übertragen worden sind werden nur kurzfristig zwischengelagert. Nach einiger Zeit bereinigt der eingebaute Garbage–Collector die Daten im <em>Cache</em> von <code>ipfs</code>.<a href="#fn54" class="footnoteRef" id="fnref54"><sup>54</sup></a></p>
<p>Werden Daten allerdings über den Knoten selbst hinzugefügt, so bekommen sie automatisch einen <em>Pin</em> (dt. Stecknadel). <em>Gepinnte</em> Daten werden automatisch vom <em>Garbage-Collector</em> ignoriert und beliebig lange vorgehalten, bis sie wieder <em>unpinned</em> werden. Möchte ein Nutzer sicher sein, dass die Datei im lokalen Speicher bleibt, so kann er sie manuell pinnen:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">ipfs</span> pin add QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG</code></pre></div>
<p>Wenn die Dateien nicht mehr lokal benötigt werden, können sie <em>unpinned</em> werden:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="ex">ipfs</span> pin rm QmYwAPJzv5CZsnA625s3Xf2nemtYgPpHdWEz79ojWnPbdG</code></pre></div>
<p><strong>Flexibler Netzwerkstack:</strong> Einer der größten Vorteile von <code>ipfs</code> ist, dass es auch über NAT–Grenzen hinweg funktioniert. Da aufgrund von <em>UDP–Hole–Punching</em> kein <em>TCP</em> genutzt werden kann, wird <em>UDP</em> genutzt. Um die Garantien zu erhalten, die <em>TCP</em> bezüglich der Paketzustellung gibt, nutzt <code>ipfs</code> das Anwendungs–Protokoll <em>UDT</em>. Insgesamt implementiert <code>ipfs</code> also einige Techniken, um, im Gegensatz zu den meisten theoretischen Ansätzen, eine leichte Usability zu gewährleisten. Speziell wäre hier zu vermeiden, dass ein Anwender die Einstellungen seines Routers ändern muss, um <code>brig</code> zu nutzen.</p>
<p>In Einzelfällen kann es trotzdem dazu kommen, dass die von <code>ipfs</code> verwendeten Ports durch eine besonders in Unternehmen übliche Firewall blockiert werden. Dies kann nötigenfalls aber vom zuständigen Administrator geändert werden.</p>
<p><strong>Übermittlung zwischen Internet und <code>ipfs</code>:</strong> Ein Client/Server–Betrieb lässt sich mithilfe der <code>ipfs</code>–<em>Gateways</em> emulieren. Gateways sind zentrale, wohlbekannte Dienste, die zwischen dem »normalen Internet« und dem <code>ipfs</code> Netzwerk mittels HTTP vermitteln. Die Datei <code>my-photo.png</code> aus dem obigen Beispiel kann von anderen Nutzern bequem über den Browser heruntergeladen werden:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="bu">export</span> <span class="va">PHOTO_HASH=</span>QmPtoEEMMnbTSmzr28UEJFvmsD2dW88nbbCyyTrQgA9JR9
$ <span class="ex">curl</span> https://gateway.ipfs.io/ipfs/<span class="va">$PHOTO_HASH</span> <span class="op">&gt;</span> my-photo.png</code></pre></div>
<p>Auf dem Gateway läuft dabei ein Webserver, der die gleiche Aufgabe hat wie »<code>ipfs cat</code>«, aber statt auf der Kommandozeile die Daten auf eine HTTP–Verbindung ausgibt. Standardmäßig wird bei jedem Aufruf von <code>ipfs daemon</code> ein Gateway auf der Adresse <a href="http://localhost:8080" class="uri">http://localhost:8080</a> gestartet.</p>
<h2 id="datenmodell-von-ipfs"><span class="header-section-number">4.2</span> Datenmodell von <code>ipfs</code></h2>
<p>Wie bereits beschrieben ist <code>brig</code> ein »Frontend«, welches <code>ipfs</code> zum Speichern und Teilen von Dokumenten nutzt. Die Dokumente werden dabei einzig und allein über ihre Prüfsumme (<code>QmXYZ...</code>) referenziert. Aus architektonischer Sicht kann man <code>ipfs</code> als eine verteilte Datenbank sehen, die vier simple Operationen beherrscht:</p>
<ul>
<li><span class="math inline"><em>P</em><em>u</em><em>t</em>(Stream)→Hash</span>: Speichert einen endlichen Datenstrom in der Datenbank und liefert die Prüfsumme als Ergebnis zurück.</li>
<li><span class="math inline"><em>G</em><em>e</em><em>t</em>(Hash)→Stream</span>: Holt einen endlichen Datenstrom aus der Datenbank der durch seine Prüfsumme referenziert wurde und gibt ihn aus.</li>
<li><span class="math inline"><em>P</em><em>i</em><em>n</em>(Hash, Count)</span>: Pinnt einen Datenstrom wenn <span class="math inline">Count</span> größer <span class="math inline">0</span> ist oder unpinnt ihn wenn er negativ ist. Im Falle von <span class="math inline">0</span> wird nichts getan. In jedem Fall wird der neue Status zurückgeliefert.</li>
<li><span class="math inline"><em>C</em><em>l</em><em>e</em><em>a</em><em>n</em><em>u</em><em>p</em></span>: Lässt einen »Garbage–Collector«<a href="#fn55" class="footnoteRef" id="fnref55"><sup>55</sup></a> laufen, der Datenströme aus dem lokalen Speicher löscht, die nicht gepinned wurden.</li>
</ul>
<p>Das Besondere ist, dass die <span class="math inline"><em>G</em><em>e</em><em>t</em>()</span> Operation von jedem verbundenen Knoten ausgeführt werden kann, wodurch die Nutzung von <code>ipfs</code> als verteilte Datenbank möglich wird. Die oben geschilderte Sicht ist rein die Art und Weise in der <code>ipfs</code> von <code>brig</code> benutzt wird. Die Möglichkeiten, die <code>ipfs</code> bietet, sind tatsächlich sehr viel weitreichender als »nur« eine Datenbank bereitzustellen. Intern hat es ein mächtiges Datenmodell, das viele Relationen wie eine Verzeichnisstruktur, Versionsverwaltung, ein alternatives World–Wide–Web oder gar eine Blockchain<a href="#fn56" class="footnoteRef" id="fnref56"><sup>56</sup></a> gut abbilden kann: Der <em>Merkle–DAG</em> (Direkter azyklischer Graph), im Folgenden kurz <em>MDAG</em> oder <em>Graph</em> genannt. Diese Struktur ist eine Erweiterung des Merkle–Trees<span class="citation">[30]</span>, bei der ein Knoten mehr als einen Elternknoten haben kann.</p>
<a name="fig:ipfs-merkledag"></a>
<div class="figure">
<img src="images/4/ipfs-merkledag.png" id="fig:ipfs-merkledag" />
<p class="caption">Figure 13: Figure 13. Beispielhafter MDAG der eine Verzeichnisstruktur abbildet.</p>
</div>
<p>In fig. 13 ist ein beispielhafter Graph gezeigt, der eine Verzeichnishierarchie modelliert. Die gezeigten Attributnamen entsprechen den <code>ipfs</code>–Internas. Gerichtet ist der Graph deswegen, weil es keine Schleifen und keine Rückkanten zu den Elternknoten geben darf. Jeder Knoten wird durch eine Prüfsumme referenziert und kann wiederum mehrere andere Knoten über weitere Prüfsümmen referenzieren. Im Beispiel sieht man zwei Wurzelverzeichnisse, bei denen das erste ein Unterverzeichnis <code>/photos</code> enthält, welches wiederum drei einzelne Dateien (<code>cat.png</code>, <code>me.png</code> und <code>small.mkv</code>) enthält. Das zweite Wurzelverzeichnis beinhaltet ebenfalls dieses, referenziert als zusätzliche Datei aber noch eine größere Datei namens <code>big.mkv</code>. Die Besonderheit ist dabei, dass die Dateien jeweils in einzelne Blöcke (<code>blobs</code>) zerlegt werden, die automatisch dedupliziert abgespeichert werden. In der Grafik sieht man das dadurch, dass <code>big.mkv</code> bereits aus zwei Blöcken von <code>small.mkv</code> besteht und der zweite Wurzelknoten auf <code>/photos</code> referenziert, ohne dessen Inhalt zu kopieren.</p>
<p>Im Datenmodell von <code>ipfs</code> (<span class="citation">[4]</span>) gibt es vier unterschiedliche Strukturen:</p>
<ul>
<li><code>blob:</code> Ein Datensatz mit definierter Größe und Prüfsumme. Wird teilweise auch <em>Chunk</em> genannt.</li>
<li><code>list:</code> Eine geordnete Liste von <code>blobs</code> oder weiteren <code>lists</code>. Wird benutzt um große Dateien in kleine, deduplizierbare Teile herunterzubrechen.</li>
<li><code>tree:</code> Eine Abbildung von Dateinamen zu Prüfsummen. Modelliert ein Verzeichnis, das <code>blobs</code>, <code>lists</code> oder andere <code>trees</code> beinhalten kann. Die Prüfsumme ergibt sich aus den Kindern.</li>
<li><code>commit:</code> Ein Snapshot eines der drei obigen Strukturen. In der Grafik nicht gezeigt, da diese Datenstrukutur noch nicht finalisiert ist<a href="#fn57" class="footnoteRef" id="fnref57"><sup>57</sup></a>.</li>
</ul>
<p>Wenn <code>ipfs</code> bereits ein Datenmodell hat, welches Verzeichnisse abbilden kann, ist es eine berechtigte Frage, warum <code>brig</code> ein eigenes Datenmodell implementiert und nicht das vorhandene als Basis verwendet. Der Grund dafür liegt in der bereits erwähnten Entkopplung von Daten und Metadaten. Würden die Dateien und Verzeichnisse direkt in <code>ipfs</code> abgebildet, so wäre diese Teilung nicht mehr gegeben, da trotzdem alle Daten in einem gemeinsamen Speicher liegen. Dies hätte zur Folge, dass ein Angreifer zwar nicht die verschlüsselten Daten lesen könnte, aber problemlos die Verzeichnisstruktur betrachten könnte, sobald er die Prüfsumme des Wurzelknotens hat. Dies würde den Sicherheitsversprechen von <code>brig</code> widersprechen. Abgesehen davon wurde ein eigenes Datenmodell entwickelt, um mehr Freiheiten beim Design zu haben.</p>
<p>Zusammengefasst lässt sich also sagen, dass <code>ipfs</code> in dieser Arbeit als Content–Adressed–Storage–Datenbank verwendet wird, die sich im Hintergrund um die Speicherung von Datenströmen und deren Unterteilung in kleine Blöcke mittels <em>Chunking</em> kümmert. Die Aufteilung geschieht dabei entweder simpel, indem die Datei in gleichgröße Blöcke unterteilt wird, oder indem ein intelligenter Algorithmus wie Rabin–Karp–Chunking<span class="citation">[14]</span> angewandt wird.</p>
<h2 id="datenmodell-von-git"><span class="header-section-number">4.3</span> Datenmodell von <code>git</code></h2>
<p>Der interne Aufbau von <code>brig</code> ist relativ stark von den Internas des freien Versionsverwaltungssystem <code>git</code> inspiriert. Deshalb werden im Folgenden immer wieder Parallelen zwischen den beiden Systemen gezogen, um die jeweiligen Unterschiede aufzuzeigen und zu erklären warum <code>brig</code> letztlich einige wichtige Differenzen aus architektonischer Sicht aufweist. Was die Usability angeht, soll allerdings aufgrund der relativ unterschiedlichen Ziele kein Vergleich gezogen werden.</p>
<p>Im Folgenden ist ein gewisses Grundwissen über <code>git</code> nützlich. Es wird bei Unklarheiten das Buch »<em>Git — Verteilte Versionsverwaltung für Code und Dokumente</em><span class="citation">[32]</span>« empfohlen. Alternativ bietet auch die offizielle Projektdokumentation<a href="#fn58" class="footnoteRef" id="fnref58"><sup>58</sup></a> einen sehr guten Überblick. Aus Platzgründen wird an dieser Stelle über eine gesonderte Einführung verzichtet, da es diese in ausreichender Menge frei verfügbar gibt.</p>
<p>Kurz beschrieben sind beide Projekte »<em>stupid content tracker</em>«<a href="#fn59" class="footnoteRef" id="fnref59"><sup>59</sup></a>, die Änderungen an tatsächlichen Dateien auf Metadaten abbilden, welche in einer dafür geeigneten Datenbank abgelegt werden. Die eigentlichen Daten werden dabei nicht mittels eines Pfades abgespeichert, sondern werden durch eine Prüfsumme referenziert (im Falle von <code>git</code> mittels <code>sha1</code>). Im Kern lösen beide Programme also Pfade in Prüfsummen auf und umgekehrt. Um diese Auflösung so einfach und effizient wie möglich zu machen, nutzt <code>git</code> ein ausgeklügeltes Datenmodell, mit dem sich Änderungen abbilden lassen. Dabei werden, anders als bei anderen Versionsverwaltungssystemen (wie Subversion), Differenzen »on-the-fly« berechnet und nicht zusätzlich abgespeichert, daher die Bezeichnung »stupid«. Abgespeichert werden, wie in fig. 14 gezeigt, nur vier verschiedene <em>Objekte</em>:</p>
<a name="fig:git-data-model"></a>
<div class="figure">
<img src="images/4/git-data-model.png" id="fig:git-data-model" style="width:80.0%" />
<p class="caption">Figure 14: Figure 14. Vereinfachte Darstellung des Datenmodells von <code>git</code>.</p>
</div>
<ul>
<li><strong>Blob:</strong> Speichert Daten einer bestimmten Größe komprimiert ab und assoziiert diese mit einer <code>sha1</code>–Prüfsumme des unkomprimierten Dateiinhaltes.</li>
<li><strong>Tree:</strong> Speichert <em>Blobs</em> oder weitere <em>Trees</em>, modelliert also eine Art »Verzeichnis«. Seine Prüfsumme ergibt sich, indem eine Prüfsumme aus den Prüfsummen der Kinder gebildet wird. Zusammen mit <em>Blobs</em> lässt sich bereits ein »unixoides Dateisystem« modellieren, bei dem alle Dateien von einem Wurzelknoten (ein <em>Tree</em> ohne Vorgänger) aus mittels eines Pfades erreichbar sind.</li>
<li><strong>Commit:</strong> Ein <em>Commit</em> speichert den Zustand des »Dateisystems«, indem es seinen Wurzelknoten referenziert. Zudem hat ein <em>Commit</em> mindestens einen Vorgänger (meist <em>Parent</em> genannt, kann beim initialen <em>Commit</em> leer sein) und speichert eine vom Nutzer verfasste Änderungszusammenfassung ab, sowie den Namen des Nutzers. Seine Prüfsumme ergibt sich indem eine Konkatenation der Wurzelprüfsumme, der Vorgängerprüfsumme, des Nutzernamen und der Commit–Nachricht<a href="#fn60" class="footnoteRef" id="fnref60"><sup>60</sup></a>.</li>
<li><strong>Ref:</strong> Eine Referenz auf einen bestimmten <em>Commit</em>. Er speichert lediglich dessen Prüfsumme und wird von <code>git</code> separat zu den eigentlichen Objekten gespeichert. In fig. 14 verweist beispielsweise die Referenz <code>HEAD</code> stets auf den aktuellsten <em>Commit</em>.</li>
</ul>
<p>Die ersten drei Objekte werden in einem MDAG untereinander in Relation gesetzt. Diese Struktur ergibt sich dadurch, dass bei Änderung einer Datei in <code>git</code> sich sämtliche Prüfsummen der Verzeichnisse darüber ändern. In Abbildung fig. 14 wurde im zweiten Commit die Datei <code>big.mkv</code> verändert (Prüfsumme ändert sich von <em>QmR5AWs9</em> zu <em>QmYYLnXi</em>). Als direkte Konsequenz ändert sich die Prüfsumme des darüber liegenden Verzeichnisses, in diesem Fall das Wurzelverzeichnis »<code>/</code>«. Bemerkenswert ist hier aber, dass das neue »<code>/</code>«–Verzeichnis trotzdem auf das <code>/photos</code>–Verzeichnis des vorherigen <em>Commits</em> verlinkt, da dieses sich in der Zwischenzeit nicht geändert hat.</p>
<p>Jede Änderung bedingt daher eine Veränderung der Prüfsumme des »<code>/</code>«–Verzeichnisses. Daher sichert dies die Integrität aller darin enthaltenen Dateien ab. Aufgrund dessen kann ein darüber liegender <em>Commit</em> einfach ein <em>Wurzelverzeichnis</em> referenzieren, um eine Momentaufnahme aller Dateien zu erzeugen. Jeder <em>Commit</em> lässt in seine eigene Prüfsumme zudem die Prüfsumme seines Vorgängers einfließen, weshalb jegliche (absichtliche oder versehentliche) Modifikation der von <code>git</code> gespeicherten Daten aufgedeckt werden kann.</p>
<p>Möchte <code>git</code> nun die Unterschiede zwischen zwei Dateiständen in zwei verschiedenen Commits anzeigen, so geht es folgendermaßen vor:</p>
<ol style="list-style-type: decimal">
<li>Löse die Prüfsummen der beiden zu untersuchenden <em>Commits</em> auf.</li>
<li>Löse die Prüfsummen der darin enthaltenen Wurzelverzeichnisse auf.</li>
<li>Traversiere in beiden Wurzelverzeichnisse zum gewünschten <em>Blob</em>.</li>
<li>Lade beide <em>Blobs</em> und wende einen Algorithmus an, der Differenzen findet (z. B. <code>diff</code> von Unix).</li>
<li>Gebe Differenzen aus.</li>
</ol>
<p>Dies ist ein signifikanter Unterschied zu zentralen Versionsverwaltungssystemen wie <code>svn</code>, die jeweils die aktuellste Datei ganz und ein oder mehrere »Reverse-Diff« abspeichern. Mithilfe des <em>Reverse-Diff</em> ist es möglich, die alten Stände wiederherzustellen. Obwohl das auf den ersten Blick wie ein Vorteil von <code>svn</code> wirkt, so nutzt dieses in der Praxis deutlich mehr Speicherplatz für ein Repository<a href="#fn61" class="footnoteRef" id="fnref61"><sup>61</sup></a> und ist signifikant langsamer als <code>git</code>, insbesondere da Netzwerkzugriffe nötig sind, während <code>git</code> lokal arbeitet. Insbesondere beim Erstellen von <em>Commits</em> und dem Wiederherstellen alter Stände ist <code>git</code> durch sein Datenmodell erstaunlich schnell. Tatsächlich speichert <code>git</code> auch nicht jeden <em>Blob</em> einzeln, sondern fasst diese gelegentlich zu sogenannten <em>Packfiles</em> zusammen, welche vergleichbar mit einem indizierten, komprimierten Archiv mehrerer Objekte sind<a href="#fn62" class="footnoteRef" id="fnref62"><sup>62</sup></a>.</p>
<p>Zusammengefasst hat <code>git</code> also aus architektonischer Sicht einige positive Eigenschaften:</p>
<ul>
<li>Objekte werden vollautomatisch und ohne weiteren Aufwand dedupliziert abgespeichert.</li>
<li>Das Datenmodell ist minimalistisch gehalten und relativ leicht verständlich.</li>
<li>Nicht alle Objekte müssen beim Start von <code>git</code> geladen werden. Lediglich die benötigten Objekte werden von <code>git</code> geladen, was den Startvorgang beschleunigt.</li>
<li>Das Bilden einer dezentralen Architektur liegt nahe, da das Datenmodell immer alle Objekte beinhalten muss. Jeder Knoten hat also dieselben Informationen.</li>
<li>Alle Dateien liegen in einem separaten <code>.git</code>–Verzeichnis und alle darin enthaltenen Internas sind durch die gute Dokumentation gut verständlich und nötigenfalls reparierbar. Zudem ist das Arbeitsverzeichnis ein ganz normales Verzeichnis, in dem der Benutzer arbeiten kann ohne von <code>git</code> gestört zu werden.</li>
<li>Die gespeicherten Daten sind durch kryptografische Prüfsummen gegen Veränderungen geschützt. Ein potentieller Angreifer müsste ein <em>Blob</em> generieren, der die von ihm gewünschten Daten enthält <em>und</em> die gleiche Prüfsumme, wie der bereits vorhandene <em>Blob</em> erzeugt. Obwohl <code>sha1</code> nicht mehr empfohlen wird<a href="#fn63" class="footnoteRef" id="fnref63"><sup>63</sup></a>, wäre das ein sehr rechenintensiver Angriff.</li>
</ul>
<p>Aus Sicht des Autors hat <code>git</code> aus architektonischer Sicht einige kleinere Schwächen:</p>
<ol style="list-style-type: decimal">
<li><strong>Prüfsummenalgorithmus nicht veränderbar:</strong> Ein MDAG–basiertes Versionsverwaltungssystem muss eine Abwägung zwischen der Prüfsummenlänge (länger ist typischerweise rechenaufwendiger, braucht mehr Speicher und ist unhandlicher für den Benutzer) und der Kollisionsresistenz der kryptografischen Prüfsumme treffen. Tritt trotzdem eine Kollision auf, so können Daten überschrieben werden<a href="#fn64" class="footnoteRef" id="fnref64"><sup>64</sup></a>. Unabsichtliche Kollisionen sind sehr unwahrscheinlich. Mit steigender Rechenleistungen wird die Berechnung einer absichtlichen Kollision aber denkbar. Leider kann <code>git</code> den genutzten Prüfsummenalgorithmus (<code>sha1</code>) nicht mehr ohne hohen Aufwand ändern<a href="#fn65" class="footnoteRef" id="fnref65"><sup>65</sup></a>. Bei <code>brig</code> ist dies möglich, da das Prüfsummenformat von <code>ipfs</code> die Länge und Art des Algorithmus in der Prüfsumme selbst abspeichert.</li>
<li><strong>Keine nativen Renames:</strong> <code>git</code> behandelt das Verschieben einer Datei als eine Sequenz aus dem Löschen und anschließendem Hinzufügen der Datei<a href="#fn66" class="footnoteRef" id="fnref66"><sup>66</sup></a>. Der Nachteil dabei ist, dass <code>git</code> dem Nutzer die Umbenennung nicht mehr als solche präsentiert, was für diesen verwirrend sein kann wenn er nicht sieht, dass die Datei anderswo neu hinzugefügt wurde. Neuere <code>git</code> Versionen nutzen Heuristiken, um Umbenennungen zu finden (Beispiel: Pfad wurde gelöscht, Prüfsumme der Datei tauchte aber anderswo auf). Diese können zwar nicht alle Fälle abdecken (umbenannt, dann modifiziert) leisten aber in der Praxis gute Dienste.</li>
<li><strong>Probleme mit großen Dateien:</strong> Da <code>git</code> für die Verwaltung von Quelltextdateien entwickelt wurde, ist es nicht auf die Verwaltung großer Dateien ausgelegt. Jede Datei muss einmal im <code>.git</code>–Verzeichnis und einmal im Arbeitsverzeichnis gespeichert werden, was den Speicherverbrauch mindestens verdoppelt. Da Differenzen zwischen Binärdateien nur wenig Aussagekraft haben (da Differenz–Algorithmen normalerweise zeilenbasiert arbeiten) wird bei jeder Modifikation jeweils noch eine Kopie angelegt. Nutzer, die ein solches Repository »<em>clonen</em>« (also sich eine eigene Arbeitskopie besorgen wollen), müssen diese Kopien lokal bei sich speichern. Werkzeuge wie <code>git-annex</code> versuchen das Problem zu lösen, indem sie statt den Dateien, nur symbolische Links versionieren, die zu den tatsächlichen Dateien zeigen<a href="#fn67" class="footnoteRef" id="fnref67"><sup>67</sup></a>. Symbolische Links sind allerdings wenig portabel.</li>
<li><strong>Kein Tracking von leeren Verzeichnissen:</strong> Es können keine leeren Verzeichnisse zu <code>git</code> hinzugefügt werden. Damit ein Verzeichnis von <code>git</code> verfolgt werden kann, muss sich mindestens eine Datei darin befinden. Das ist weniger eine Einschränkung des Datenmodells von <code>git</code>, als viel mehr ein kleiner Designfehler<a href="#fn68" class="footnoteRef" id="fnref68"><sup>68</sup></a> in der Implementierung, der bisher als zu unwichtig galt, um korrigiert zu werden.</li>
<li><strong>Keine eigene Historie pro Datei:</strong> Es gibt nur eine gesamte <em>Historie</em>, die durch die Verkettung von <em>Commits</em> erzeugt wird. Bei einem Befehl wie <code>git log &lt;filename&gt;</code> (Zeige alle Commits, in denen <code>&lt;filename&gt;</code> verändert wurde) müssen alle <em>Commits</em> betrachtet werden, auch wenn <code>&lt;filename&gt;</code> nur in wenigen davon tatsächlich etwas geändert wurde. Eine mögliche Lösung wäre das Anlegen einer Historie für einzelne Dateien.</li>
</ol>
<p>Zusammengefasst lässt sich sagen, dass <code>git</code> ein extrem flexibles und schnelles Werkzeug für die Verwaltung von Quelltext und kleinen Dateien ist. Weniger geeignet ist es für eine allgemeine Dateisynchronisationssoftware, die auch große Dokumente effizient behandeln können muss.</p>
<h1 id="sec:architektur"><span class="header-section-number">5</span> Architektur</h1>
<p>In diesem Kapitel wird die grundlegende Architektur von <code>brig</code> erklärt. Dabei wird vor allem das »Kernstück« beleuchtet: Das zugrundeliegende Datenmodell in dem alle Metadaten abgespeichert und in Relation gesetzt werden. Dazu wird auf die zuvor erklärten Internas von <code>ipfs</code> und <code>git</code> eingegangen.</p>
<p>Basierend darauf werden die umgebenden Komponenten beschrieben, die um den Kern von <code>brig</code> gelagert sind. Am Ende des Kapitels werden zudem noch einmal alle Einzelkomponenten in einer Übersicht gezeigt. Mögliche Erweiterungen werden in sec. 8 (<em>Evaluation</em>) diskutiert. Die technische Umsetzung des Prototypen hingegen wird in sec. 6 (<em>Implementierung</em>) besprochen.</p>
<h2 id="datenmodell-von-brig"><span class="header-section-number">5.1</span> Datenmodell von <code>brig</code></h2>
<p>Die Einsatzziele von <code>brig</code> und <code>git</code> unterscheiden sich: <code>git</code> ist primär eine Versionsverwaltugssoftware, mit der man auch synchronisieren kann. <code>brig</code> kann man hingegen eher als eine Synchronisationssoftware sehen, die auch Versionierung beherrscht. Aus diesem Grund wurde das Datenmodell von <code>git</code> für den Einsatz in <code>brig</code> angepasst und teilweise vereinfacht. Die Hauptunterschiede sind dabei wie folgt:</p>
<ul>
<li><strong>Strikte Trennung zwischen Daten und Metadaten:</strong> Metadaten werden von <code>brig</code>’s Datenmodell verwaltet, während die eigentlichen Daten lediglich per Prüfsumme referenziert und von <code>ipfs</code> gespeichert werden. So gesehen ist <code>brig</code> ein Versionierungsaufsatz für <code>ipfs</code>.</li>
<li><strong>Lineare Versionshistorie:</strong> Jeder <em>Commit</em> hat maximal einen Vorgänger und exakt einen Nachfolger. Dies macht die Benutzung von <em>Branches</em><a href="#fn69" class="footnoteRef" id="fnref69"><sup>69</sup></a> unmöglich, bei der ein <em>Commit</em> zwei Nachfolger haben kann, beziehungsweise sind auch keine Merge–Commits möglich, die zwei Vorgänger besitzen. Diese Vereinfachung ist nicht von der Architektur vorgegeben und könnte nachgerüstet werden. Allerdings hat die Benutzung dieses Features »Verwirrungspotenzial«<a href="#fn70" class="footnoteRef" id="fnref70"><sup>70</sup></a> für gewöhnliche Nutzer, die gedanklich eher von einer linearen Historie ihrer Dokumente ausgehen.</li>
<li><strong>Synchronisationspartner müssen keine gemeinsame Historie haben:<a href="#fn71" class="footnoteRef" id="fnref71"><sup>71</sup></a></strong> Es wird bei <code>brig</code> davon ausgegangen, dass unterschiedliche Dokumentensammlungen miteinander synchronisiert werden sollen, während bei <code>git</code> davon ausgegangen wird, dass eine einzelne Dokumentensammlung immer wieder modifiziert und zusammengeführt wird. Haben die Partner keine gemeinsame Historie, wird einfach angenommen, dass alle Dokumente synchronisiert werden müssen. Aus diesen Grund kennt <code>brig</code> auch keine <code>clone</code> und <code>pull</code>–Operation. Diese werden durch »<code>brig sync &lt;with&gt;</code>« ersetzt.</li>
</ul>
<a name="fig:brig-data-model"></a>
<div class="figure">
<img src="images/4/brig-data-model.png" id="fig:brig-data-model" />
<p class="caption">Figure 15: Figure 15. Das Datenmodell von <code>brig</code>. Checkpoints von Verzeichnissen wurden ausgelassen.</p>
</div>
<p>fig. 15 zeigt das oben verwendete Beispiel in <code>brig</code>’s Datenmodell. Es werden prinzipiell die gleichen Objekttypen verwendet, die auch <code>git</code> verwendet:</p>
<ul>
<li><strong>File:</strong> Speichert die Metadaten einer einzelnen, regulären Datei. Zu den Metadaten gehört die aktuelle Prüfsumme, die Dateigröße, der letzte Änderungszeitpunkt und der kryptografische Schlüssel mit dem die Datei verschlüsselt ist. Anders als ein <em>Blob</em> speichert ein <em>File</em> die Daten nicht selbst, sondern referenziert diese nur im <code>ipfs</code>–Backend.</li>
<li><p><strong>Directory:</strong> Speichert wie ein <em>Tree</em> einzelne <em>Files</em> und weitere <em>Directories</em>. Die Prüfsumme des Verzeichnisses <span class="math inline"><em>H</em><sub><em>d</em><em>i</em><em>r</em><em>e</em><em>c</em><em>t</em><em>o</em><em>r</em><em>y</em></sub></span> ergibt sich auch hier aus der XOR–Verknüpfung (<span class="math inline">⊕</span>) der Prüfsumme des Pfades <span class="math inline"><em>H</em><sub><em>p</em><em>a</em><em>t</em><em>h</em></sub></span> mit den Prüfsummen der direkten Nachfahren <span class="math inline"><em>x</em></span>: <br /><span class="math display">$$
H_{directory}(x) = \begin{cases}
        H_{path} &amp; \text{für } x = () \\
        x_1 \oplus f(x_{(x_2, \ldots, x_n)}) &amp; \text{sonst}
       \end{cases}
  $$</span><br /></p>
<p>Die Verwendung der XOR–Verknüpfung hat dabei den Vorteil, dass sie selbstinvers und kommutativ ist. Wendet man sie also zweimal an, so erhält man das neutrale Element <span class="math inline">0</span>. Analog dazu führt die Anwendung auf ein vorheriges Ergebnis wieder zur ursprünglichen Eingabe:</p>
<p><br /><span class="math display"><em>x</em> ⊕ <em>x</em> = 0 (Auslöschung)</span><br /> <br /><span class="math display"><em>y</em> = <em>y</em> ⊕ <em>x</em> ⊕ <em>x</em> = <em>x</em> ⊕ <em>y</em> ⊕ <em>x</em> = <em>x</em> ⊕ <em>x</em> ⊕ <em>y</em> (Kommutativität)</span><br /></p>
<p>Diese Eigenschaft kann man sich beim Löschen einer Datei zunutze machen, indem die Prüfsumme jedes darüberliegenden Verzeichnisses mit der Prüfsumme der zu löschenden Datei XOR–genommen wird. Der resultierende Graph hat die gleiche Prüfsumme wie vor dem Einfügen der Datei.</p></li>
<li><strong>Commits:</strong> Analog zu <code>git</code>; dienen aber bei <code>brig</code> nicht nur der logischen Kapselung von mehreren Änderungen, sondern werden auch automatisiert von der Software nach einem bestimmten Zeitintervall erstellt. Daher ist ihr Zweck eher mit den <em>Snapshots</em> vieler Backup–Programme vergleichbar, welche dem Nutzer einen Sicherungspunkt zu einem bestimmten Zeitpunkt in der Vergangenheit bieten. Als Metadaten speichert er als Referenz die Prüfsumme des Wurzelverzeichnisses, eine Commit–Nachricht sowie dessen Autor und eine Referenz auf den Vorgänger. Aus diesen Metadaten wird durch Konkatenation derselben eine weitere Prüfsumme errechnet, die den Commit selbst eindeutig referenziert. In diese Prüfsumme ist nicht nur die Integrität des aktuellen Standes gesichert, sondern auch aller Vorgänger.</li>
<li><p><strong>Refs:</strong> Analog zu <code>git</code> dienen sie dazu, bestimmten <em>Commits</em> einen Namen zu geben. Es gibt zwei vordefinierte Referenzen, welche von <code>brig</code> aktualisiert werden: <code>HEAD</code>, welche auf den letzten vollständigen <em>Commit</em> zeigt und <code>CURR</code>, welche auf den aktuellen Commit zeigt (meist dem <em>Staging Commit</em>, dazu später mehr). Da es keine Branches gibt, ist eine Unterscheidung zwischen <em>Refs</em> und <em>Tags</em> wie bei <code>git</code> nicht mehr nötig.</p></li>
</ul>
<a name="fig:path-resolution"></a>
<div class="figure">
<img src="images/4/path-resolution.png" id="fig:path-resolution" style="width:90.0%" />
<p class="caption">Figure 16: Figure 16. Jeder Knoten muss von dem aktuellen Wurzelverzeichnis aus neu aufgelöst werden, selbst wenn nur der Elternknoten gesucht wird.</p>
</div>
<p><em>Directories</em> und <em>Files</em> speichern zudem zwei weitere gemeinsame Attribute:</p>
<ul>
<li><strong>Ihren eigenen Namen und den vollen Pfad des darüber liegenden Knoten</strong>. Zusammen ergibt dieser den vollen Pfad der Datei oder des Verzeichnisses. Dieser Pfad ist nötig, um den jeweiligen Elternknoten zu erreichen. In einem gerichteten, azyklischen Graphen darf es keine Rückkanten nach »oben« geben, deswegen scheidet die direkte Referenzierung des Elternknotens mittels seiner Prüfsumme aus. Wie in fig. 16 gezeigt ist es daher nötig, beispielsweise den Elternknoten eines beliebigen Knotens vom aktuellen Wurzelknoten neu aufzulösen.</li>
<li><strong>Eine eindeutige Nummer</strong> (<em>Unique Identifier</em>, <code>UID</code>), welche die Datei oder das Verzeichnis eindeutig kennzeichnet. Diese Nummer bleibt auch bei Modifikation und Verschieben der Datei gleich. Neben der Prüfsumme (referenziert einen bestimmten Inhalt) und dem Pfad (referenziert eine bestimmte Lokation) ist die Nummer ein weiterer Weg eine Datei zu referenzieren (referenziert ein veränderliches »Dokument«) und ist grob mit dem Konzept einer <em>Inode–Nummer</em> bei Dateisystemen<a href="#fn72" class="footnoteRef" id="fnref72"><sup>72</sup></a> vergleichbar.</li>
</ul>
<a name="fig:file-history"></a>
<div class="figure">
<img src="images/4/file-history.png" id="fig:file-history" style="width:50.0%" />
<p class="caption">Figure 17: Figure 17. Jede Datei und jedes Verzeichnis besitzt eine Liste von Checkpoints.</p>
</div>
<p>Davon abgesehen fällt auf, dass zwei zusätzliche Strukturen eingeführt wurden:</p>
<ul>
<li><p><strong>Checkpoints:</strong> Jeder Datei ist über ihre <code>UID</code> eine Historie von mehreren, sogenannten <em>Checkpoints</em> zugeordnet. Jeder Einzelne dieser Checkpoints beschreibt eine atomare Änderung an der Datei. Da keine partiellen Änderungen<a href="#fn73" class="footnoteRef" id="fnref73"><sup>73</sup></a> möglich sind, müssen nur vier verschiedene Operation unterschieden werden: <code>ADD</code> (Datei wurde initial oder erneut hinzugefügt), <code>MODIFY</code> (Prüfsumme hat sich verändert), <code>MOVE</code> (Pfad hat sich verändert) und <code>REMOVE</code> (Datei wurde entfernt). Eine beispielhafte Historie findet sich in fig. 17. Werden mehrere Checkpoints eingepflegt, die den gleichen Typen haben (beispielsweise mehrere <code>MODIFY</code>–Operationen), so wird nur die letzte <code>MODIFY</code>–Operation in der Historie abgespeichert. Jeder Checkpoint kennt den Zustand der Datei zum Zeitpunkt der Modifikation, sowie einige Metadaten wie einen Zeitstempel, der Dateigröße, dem Änderungstyp, dem Vorgänger und dem Urheber der Änderung. Der Vorteil einer dateiabhängigen Historie ist die Möglichkeit, umbenannte Dateien zu erkennen, sowie Dateien zu erkennen, die gelöscht und dann wieder hinzugefügt worden sind. Ein weiterer Vorteil ist, dass zur Ausgabe der Historie einer Datei, nur die <em>Checkpoints</em> betrachtet werden müssen. Es muss nicht wie bei <code>git</code> jeder Commit betrachtet werden, um nachzusehen ob eine Änderung an einer bestimmten Datei stattgefunden hat.</p></li>
<li><p><strong>Staging–Commit:</strong> Es existiert immer ein sogenannter <em>Staging–Commit</em>. Dieser beinhaltet alle Knoten im MDAG, die seit dem letzten »vollwertigen« Commit modifiziert worden sind. fig. 18 zeigt den Staging–Bereich von <code>git</code> und <code>brig</code> im Vergleich. Im Falle von <code>git</code> handelt es sich um eine eigene, vom eigentlichen Graphen unabhängige, Datenstruktur, in die der Nutzer mittels <code>git add</code> explizit Dokumente aus dem Arbeitsverzeichnis hinzufügt. Bei <code>brig</code> hingegen gibt es kein Arbeitsverzeichnis und daher keine Unterscheidung zwischen »Unstaged Files« und »Staged Files«. Die Daten kommen entweder von einer externen Datei, welche mit <code class="sourceCode bash"><span class="ex">brig</span> stage <span class="op">&lt;</span>filename<span class="op">&gt;</span></code> dem Staging–Bereich hinzugefügt wurde, oder die Datei wurde direkt im FUSE–Dateisystem von <code>brig</code> modifiziert. In beiden Fällen wird die neue oder modifizierte Datei in den <em>Staging–Commit</em> eingegliedert, welcher aus diesem Grund eine veränderliche Prüfsumme aufweist und nach jeder inhaltlichen Modifikation auf ein anderes Wurzelverzeichnis verweist.</p></li>
</ul>
<a name="fig:staging-area"></a>
<div class="figure">
<img src="images/4/staging-area.png" id="fig:staging-area" />
<p class="caption">Figure 18: Figure 18. Der Staging–Bereich im Vergleich zwischen <code>git</code> und <code>brig</code></p>
</div>
<p>Da ein <em>Commit</em> nur einen Vorgänger haben kann, muss ein anderer Mechanismus eingeführt werden, um die Synchronisation zwischen zwei Partnern festzuhalten. Bei <code>git</code> wird dies mittels eines sogenannten <em>Merge–Commit</em> gelöst, welcher aus den Änderungen des Synchronisationspartners besteht. Hier wird das Konzept eines <em>Merge–Points</em> eingeführt. Innerhalb eines <em>Commit</em> ist das ein spezieller Marker, der festhält mit wem synchronisiert wurde und welchen Stand er zu diesem Zeitpunkt hatte. Bei einer späteren Synchronisation muss daher lediglich der Stand zwischen dem aktuellen <em>Commit</em> (»<code>CURR</code>«) und dem letzten Merge–Point verglichen werden. Basierend auf diesem Vergleich wird ein neuer <em>Commit</em> (der <em>Merge–Commit</em>) erstellt, der alle (möglicherweise nach der Konfliktauflösung zusammengeführten) Änderungen des Gegenübers enthält und als neuer <em>Merge–Point</em> dient.</p>
<h3 id="operationen-auf-dem-datenmodell"><span class="header-section-number">5.1.1</span> Operationen auf dem Datenmodell</h3>
<p>Die Gesamtheit aller <em>Files</em>, <em>Directories</em>, <em>Commits</em>, <em>Checkpoints</em> und <em>Refs</em> wird im Folgenden als <em>Store</em> bezeichnet. Da ein <em>Store</em> nur aus Metadaten besteht, ist er selbst leicht auf andere Geräte übertragbar. Er kapselt den Objektgraphen und kümmert sich um die Verwaltung der Objekte. Basierend auf dem Store werden insgesamt elf verschiedene atomare Operationen implementiert, die jeweils den aktuellen Graphen nehmen und einen neuen und veränderten Graphen erzeugen.</p>
<p>Es gibt sechs Operationen, die die Benutzung des Graphen als gewöhnliches Dateisystem ermöglichen:</p>
<p><code>STAGE</code>: Fügt ein Dokument dem Staging–Bereich hinzu oder aktualisiert die Version eines vorhandenen Dokuments. Der Pfad entscheidet dabei wo das Dokument eingefügt wird, beziehungsweise welches existierende Dokument modifiziert wird. fig. 19 zeigt die Operationen, die zum Einfügen einer Datei notwendig sind. Als Vorarbeit muss allerdings erst die gesamte Datei gelesen werden und in das <code>ipfs</code>–Backend eingefügt werden. Die Datei wird zudem gepinnt. Als Ergebnis dieses Teilprozesses wird die Größe und Prüfsumme der verschlüsselten und komprimierten Datei zurückgeliefert. Handelt es sich bei dem hinzuzufügenden Objekt um ein Verzeichnis, wird der gezeigte Prozess für jede darin enthaltene Datei wiederholt.</p>
<a name="fig:op-add"></a>
<div class="figure">
<img src="images/4/op-add" alt="Figure 19: Figure 19. Die Abfolge der STAGE-Operation im Detail" id="fig:op-add" />
<p class="caption">Figure 19: Figure 19. Die Abfolge der <code>STAGE</code>-Operation im Detail</p>
</div>
<p><code>REMOVE:</code> Entfernt eine vorhandene Datei aus dem Staging–Bereich. Der Pin der Datei oder des Verzeichnisses und all seiner Kinder wird entfernt. Die gelöschten Daten werden möglicherweise beim nächsten Durchgang der <span class="math inline"><em>C</em><em>l</em><em>e</em><em>a</em><em>n</em><em>u</em><em>p</em></span> Operation aus dem lokalen Speicher von <code>ipfs</code> entfernt. Die Prüfsumme der entfernten Datei wird aus den darüber liegenden Verzeichnissen herausgerechnet. Handelt es sich dabei um ein Verzeichnis, wird der Prozess <em>nicht</em> rekursiv für jedes Unterobjekt ausgeführt. Es genügt die Prüfsumme des zu löschenden Verzeichnisses aus den Eltern mittels der XOR–Operation herauszurechnen und die Kante zu dem Elternknoten zu kappen.</p>
<p><code>LIST:</code> Entspricht konzeptuell dem Unix–Werkzeug <code>ls</code>. Besucht alle Knoten unter einem bestimmten Pfad rekursiv (breadth-first) und gibt diese aus.</p>
<p><code>MKDIR:</code> Erstellt ein neues, leeres Verzeichnis. Die initiale Prüfsumme des neuen Verzeichnisses ergibt sich aus dem Pfad des neuen Verzeichnisses. Diese wird in den Elternknoten eingerechnet. Die Referenz auf das Wurzelverzeichnis wird im Staging–Commit angepasst. Eventuell müssen noch dazwischenliegende Verzeichnisse erstellt werden. Diese werden einzeln von oben nach unten mit den eben beschriebenen Prozess erstellt.</p>
<p><code>MOVE:</code> Verschiebt eine Quelldatei oder Verzeichnis zu einem Zielpfad. Es muss eine Fallunterscheidung getroffen werden, je nachdem ob und welcher Knoten im Zielpfad vorhanden ist:</p>
<ol style="list-style-type: decimal">
<li><em>Ziel existiert noch nicht:</em> Quelldaten werden zum neuen Pfad verschoben.</li>
<li><em>Ziel existiert und ist eine Datei:</em> Vorgang wird abgebrochen, es sei denn die Aktion wird »forciert«.</li>
<li><em>Ziel existiert und ist ein Verzeichnis:</em> Quelldaten werden direkt unter das Zielverzeichnis verschoben, sofern darunter noch kein Verzeichnis mit diesem Namen existiert. Andernfalls wird die Aktion mit einem Fehler abgebrochen.</li>
</ol>
<p>In jedem Fall entspricht diese Operation technisch dem, möglicherweise mehrfachen, sequentiellen Ausführen der Operationen <code>REMOVE</code> und <code>ADD</code>. Im Unterschied dazu ist sie im Ganzen atomar und erstellt einen Checkpoint mit dem Typen <code>MOVED</code> für alle verschobenen Knoten.</p>
<p><code>CAT:</code> Gibt ein Dokument als einen Datenstrom aus. Der Name lehnt sich dabei an das Unix–Tool <code>cat</code> an, welches ebenfalls Dateien ausgeben kann. Es wird lediglich wie in fig. 16 gezeigt der gesuchte Knoten per Pfad aufgelöst und die darin enthaltene Prüfsumme wird vom <code>ipfs</code>–Backend aufgelöst. Die ankommenden Daten werden entschlüsselt und dekomprimiert bevor sie dem Nutzer präsentiert werden.</p>
<p>Neben den oben stehenden Operationen, gibt es noch fünf weitere, die zur Versionskontrolle dienen und in dieser Form normalerweise nicht von Dateisystemen implementiert werden:</p>
<p><code>UNSTAGE:</code> Entfernt ein Dokument aus dem Staging–Bereich und setzt den Stand auf den zuletzt bekannten Wert zurück (also der Stand der in <code>HEAD</code> präsent war). Die Prüfsumme des entfernten Dokumentes wird aus den Elternknoten herausgerechnet und dafür die alte Prüfsumme wieder eingerechnet.</p>
<p><em>Anmerkung:</em> Die Benennung der Operationen <code>STAGE</code>, <code>UNSTAGE</code> und <code>REMOVE</code> ist anders als bei den semantisch gleichen <code>git</code>–Werkzeugen <code>add</code>, <code>reset</code> und <code>rm</code>. Die Benennung nach dem <code>git</code>–Schema ist irreführend, da <code>git add</code> nicht nur neue Dateien hinzufügt, sondern auch modifizierte Dateien aktualisiert. Zudem ist <code>git add</code> nicht das Gegenteil von <code>git rm</code><a href="#fn74" class="footnoteRef" id="fnref74"><sup>74</sup></a>, wie man vom Namen annehmen könnte. Das eigentliche Gegenteil ist <code>git reset</code>. Eine mögliche Alternative zu <code>brig stage</code> wäre vermutlich auch <code>brig track</code>, beziehungsweise <code>brig untrack</code> statt <code>brig rm</code>.</p>
<p><code>COMMIT:</code> Erstellt einen neuen Commit, basierend auf dem Inhalt des <em>Staging–Commits</em> (siehe auch fig. 20 für eine Veranschaulichung). Dazu werden die Prüfsummen des aktuellen und des Wurzelverzeichnisses im letzten Commit (<code>HEAD</code>) verglichen. Unterscheiden sie sich nicht, wird abgebrochen, da keine Veränderung vorliegt. Im Anschluss wird der <em>Staging–Commit</em> finalisiert, indem die angegebene <em>Commit–Message</em> und der Autor in den Metadaten des Commits gesetzt werden. Basierend darauf wird die finale Prüfsumme berechnet und der entstandene Commit abgespeichert. Ein neuer <em>Staging-Commit</em> wird erstellt, welcher im unveränderten Zustand auf das selbe Wurzelverzeichnis zeigt wie sein Vorgänger. Zuletzt werden die Referenzen von <code>HEAD</code> und <code>CURR</code> jeweils um einen Platz nach vorne verschoben.</p>
<a name="fig:op-commit"></a>
<div class="figure">
<img src="images/4/op-commit.png" id="fig:op-commit" />
<p class="caption">Figure 20: Figure 20. Die Abfolge der <code>COMMIT</code>–Operation im Detail. Links der vorige Stand, rechts der Stand nach der <code>COMMIT</code>–Operation.</p>
</div>
<p><code>CHECKOUT:</code> Stellt einen alten Stand wieder her. Dabei kann die Operation eine alte Datei oder ein altes Verzeichnis basierend auf der alten Prüfsumme oder den Stand eines gesamten, in der Vergangenheit liegenden, Commits wiederherstellen.</p>
<p>Im Gegensatz zu <code>git</code> ist es allerdings nicht vorgesehen, in der Versionshistorie »herumzuspringen«. Soll ein alter <em>Commit</em> wiederhergestellt werden, so wird der Staging–Commit so verändert, dass er dem gewünschten, alten Stand entspricht (siehe auch Abbildung fig. 21). Das Verhalten von <code>brig</code> entspricht an dieser Stelle also nicht dem Namensvetter <code>git checkout</code> sondern eher dem wiederholten Anwenden von <code>git revert</code> zwischen dem aktuellen und dem Nachfolger des gewünschten Commits.</p>
<a name="fig:op-checkout"></a>
<div class="figure">
<img src="images/4/op-checkout.png" id="fig:op-checkout" style="width:75.0%" />
<p class="caption">Figure 21: Figure 21. Die Abfolge der <code>CHECKOUT</code>–Operation im Detail.</p>
</div>
<p>Begründet ist dieses Verhalten darin, dass kein sogenannter »Detached HEAD«–Zustand entstehen soll, da dieser für den Nutzer irreführend sein kann. Dieser Zustand kann in <code>git</code> erreicht werden, indem man in einen früheren <em>Commit</em> springt ohne einen neuen <em>Branch</em> davon abzuzweigen. Der <code>HEAD</code> zeigt dann nicht mehr auf einen benannten Branch, sondern auf die Prüfsumme des neuen Commits, der vom Nutzer nur noch durch die Kenntnis derselben erreichbar ist. Macht man in diesem Zustand Änderungen, ist es möglich die geänderten Daten zu verlieren<a href="#fn75" class="footnoteRef" id="fnref75"><sup>75</sup></a>. Um das zu vermeiden, hält <code>brig</code> die Historie stets linear und unveränderlich. Dies stellt keine Einschränkung der Architektur an sich dar.</p>
<p><code>LOG/HISTORY:</code> Zeigt alle Commits, bis auf den Staging–Commit. Begonnen wird die Ausgabe mit <code>HEAD</code> und beendet wird sie mit dem initialen Commit. Alternativ kann auch die Historie eines einzelnen Verzeichnisses oder einer Datei angezeigt werden. Dabei werden statt Commits alle Checkpoints dieser Datei, beginnend mit dem Aktuellsten, ausgegeben.</p>
<p><code>STATUS:</code> Zeigt den Inhalt des aktuellen Staging–Commits (analog zu <code>git status</code>) und damit aller geänderten Dateien und Verzeichnisse im Vergleich zu <code>HEAD</code>. Es gibt keine eigene <code>DIFF</code>–Operation, da es keine partiellen Differenzen gibt. Eine Übersicht der Änderung erhält man durch Anwendung der <code>STATUS</code> und <code>HISTORY</code>–Operationen.</p>
<h2 id="synchronisation"><span class="header-section-number">5.2</span> Synchronisation</h2>
<p>Ähnlich wie <code>git</code> speichert <code>brig</code> für jeden Nutzer seinen zuletzt bekannten <em>Store</em> ab. Mithilfe dieser Informationen können dann Synchronisationsentscheidungen größtenteils automatisiert getroffen werden. Welche Stores dabei lokal zwischengespeichert werden, entscheiden die Einträge der sogenannten <em>Remote–Liste</em>.</p>
<h3 id="sec:remote-list"><span class="header-section-number">5.2.1</span> Die Remote–Liste</h3>
<p>Jeder Teilnehmer mit dem synchronisiert werden soll, muss zuerst in eine spezielle Liste von <code>brig</code> eingetragen werden, damit dieser dem System bekannt wird. Dies ist vergleichbar mit der Liste die <code>git remote -v</code> erzeugt: Eine Zuordnung eines menschenlesbaren Namen zu einer eindeutigen Referenz zum Synchronisationspartner. Im Falle von <code>git</code> ist das eine URL, bei <code>brig</code> handelt es sich um die öffentliche Identität des Partners, also einer Prüfsumme. Wie später gezeigt wird, ist dieses explizite Hinzufügen des Partners eine Authentifizierungsmaßnahme, die bewusst eingefügt wurde. Unter sec. 5.4.3 wird das Konzept genauer erläutert. Dadurch, dass nur mit authentifizierten Knoten Verbindungen aufgebaut werden, bildet <code>brig</code> ein <em>Private-Peer–to–Peer</em>–Netzwerk<a href="#fn76" class="footnoteRef" id="fnref76"><sup>76</sup></a> auf Basis von <code>ipfs</code>.</p>
<a name="fig:multiple-repos"></a>
<div class="figure">
<img src="images/4/multiple-repos.png" id="fig:multiple-repos" />
<p class="caption">Figure 22: Figure 22. Remote–Liste von vier Repositories und verschiendenen Synchronisationsrichtungen.</p>
</div>
<p>Wie in fig. 22 gezeigt wird, können alle Knoten miteinander synchronisieren, die sich gegenseitig in die Liste eingetragen haben, da von diesen jeweils der zuletzt bekannte Store übertragen wurde. Die Synchronisation ist dabei, wie ein <code>git pull</code>, nicht bidirektional. Lediglich die eigenen Daten werden mit den Fremddaten zusammengeführt. Es gibt kein Äquivalent zu <code>git push</code>, welches die eigenen Daten zu einem Partner überträgt. Jeder Partner entscheidet selbst, mit welchen anderen Teilnehmern er synchronisiert, ohne dass seine eigenen Daten überschrieben werden können. In der Grafik wird zudem ein spezieller Anwendungsfall gezeigt: Das Repository <code>rabbithole@wonderland</code> ist eine gemeinsame Datenablage für zwei Parteien, die stets online verfügbar ist<a href="#fn77" class="footnoteRef" id="fnref77"><sup>77</sup></a>. Dieses kann durch ein Skript automatisiert stets die Änderungen aller bekannten Teilnehmer synchronisieren und auch weitergeben, wenn der eigentliche Nutzer gerade offline ist. Dieses Vorgehen bietet sich vor allem dann an, wenn aufgrund der Zeitverschiebung zwei Nutzer selten zur selben Zeit online sind.</p>
<h3 id="sec:sync-single-file"><span class="header-section-number">5.2.2</span> Synchronisation einzelner Dateien</h3>
<p>In seiner einfachsten Form nimmt ein Synchronisationsalgorithmus als Eingabe die Metadaten zweier Dateien von zwei Synchronisationspartnern. Als Ausgabe trifft der Algorithmus auf dieser Basis eine der folgenden Entscheidungen:</p>
<ol style="list-style-type: decimal">
<li>Die Datei existiert nur bei Partner A.</li>
<li>Die Datei existiert nur bei Partner B.</li>
<li>Die Datei existiert bei beiden und ist gleich.</li>
<li>Die Datei existiert bei beiden und ist verschieden.</li>
</ol>
<p>Je nach Entscheidung kann für diese Datei eine entsprechende Aktion ausgeführt werden:</p>
<ol style="list-style-type: decimal">
<li>Die Datei muss zu Partner B übertragen werden (falls bidirektionale Synchronisation gewünscht ist).</li>
<li>Die Datei muss zu Partner A übertragen werden.</li>
<li>Es muss nichts weiter gemacht werden.</li>
<li>Konfliktsituation: Auflösung nötig.</li>
</ol>
<p>Bis auf den vierten Schritt ist die Implementierung trivial und kann von einem Computer erledigt werden. Das Kriterium, ob die Datei gleich ist, kann entweder durch einen direkten Vergleich der Daten gelöst werden (aufwendig) oder durch den Vergleich der Prüfsummen beider Dateien (schnell, aber vernachlässigbares Restrisiko durch Kollision). Manche Werkzeuge wie <code>rsync</code> setzen sogar auf Heuristiken, indem sie in der Standardkonfiguration aus Geschwindigkeitsgründen nur das Änderungsdatum und die Dateigröße vergleichen.</p>
<p>Für die Konfliktsituation hingegen kann es keine perfekte, allumfassende Lösung geben, da die optimale Lösung von der jeweiligen Datei und der Absicht des Nutzers abhängt. Bei Quelltext–Dateien möchte der Anwender vermutlich, dass beide Stände möglichst automatisch zusammengeführt werden, bei großen Videodateien ist das vermutlich nicht seine Absicht. Selbst wenn die Dateien nicht automatisch zusammengeführt werden sollen (englisch »to merge«), ist fraglich was mit der Konfliktdatei des Partners geschehen soll. Soll die eigene oder die fremde Version behalten werden? Dazwischen sind auch weitere Lösungen denkbar, wie das Anlegen einer Konfliktdatei (<code>photo.png:conflict-by-bob-2015-10-04_14:45</code>), so wie es beispielsweise Dropbox macht.<a href="#fn78" class="footnoteRef" id="fnref78"><sup>78</sup></a> Alternativ könnte der Nutzer auch bei jedem Konflikt befragt werden. Dies wäre allerdings im Falle von <code>brig</code> nach Meinung des Autors der Usability stark abträglich.</p>
<p>Im Falle von <code>brig</code> müssen nur die Änderungen von ganzen Dateien betrachtet werden, aber keine partiellen Änderungen darin. Eine Änderung der ganzen Datei kann dabei durch folgende Aktionen des Nutzers entstehen:</p>
<ol style="list-style-type: decimal">
<li>Der Dateiinhalt wurde modifiziert, ergo muss sich die Prüfsumme geändert haben (<code>MODIFY</code>).</li>
<li>Die Datei wurde verschoben, ergo muss sich der Pfad geändert haben (<code>MOVE</code>).</li>
<li>Die Datei wurde gelöscht, ergo ist sie im <em>Staging–Commit</em> nicht mehr vorhanden (<code>REMOVE</code>).</li>
<li>Die Datei wurde (initial oder erneut nach einem <code>REMOVE</code>) hinzugefügt (<code>ADD</code>).</li>
</ol>
<p>Der vierte Zustand (<code>ADD</code>) ist dabei der Initialisierungszustand. Nicht alle dieser Zustände führen dabei automatisch zu Konflikten. So sollte beispielsweise ein guter Algorithmus kein Problem erkennen, wenn ein Partner die Datei modifiziert und der andere sie nicht verändert, sondern lediglich umbenennt. Eine Synchronisation der entsprechenden Datei sollte den neuen Inhalt mit dem neuen Dateipfad zusammenführen. tbl. <strong>??</strong> zeigt welche Operationen zu Konflikten führen und welche verträglich sind. Die einzelnen Möglichkeiten sind dabei wie folgt:</p>
<ul>
<li>»«: Die beiden Aktionen sind nicht miteinander verträglich, es sei denn ihre Prüfsummen sind gleich. Sind die Prüfsummen gleich, heißt das, dass die exakt gleiche Änderung auf beiden Seiten gemacht wurde.</li>
<li>»«: Die Aktion ist prinzipiell verträglich, hängt aber von der Konfiguration ab. Entweder wird die Löschung oder die Umbenennung vom Gegenüber propagiert (Standard) oder die eigene Datei wird behalten.</li>
<li>»«: Die beiden Aktionen sind verträglich.</li>
</ul>
<a name="tbl:sync-conflicts"></a>
<table>
<caption>Table 3. Verträglichkeit der atomaren Operationen untereinander für die Partner <strong>A</strong> und <strong>B</strong>.</caption>
<thead>
<tr class="header">
<th align="center"><strong>A/B</strong></th>
<th><code>ADD</code></th>
<th><code>REMOVE</code></th>
<th><code>MODIFY</code></th>
<th><code>MOVE</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><code>ADD</code></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td align="center"><code>REMOVE</code></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td align="center"><code>MODIFY</code></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td align="center"><code>MOVE</code></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Zusammenfassend wird der in Listing 1 gezeigte Pseudo–Code von beiden Teilenehmern ausgeführt, um zwei Dateien synchron zu halten. Unten stehender Go–Pseudocode ist eine modifizierte Version aus Russ Cox’ Arbeit »File Synchronization with Vector Time Pairs«<span class="citation">[9]</span>, welcher für <code>brig</code> angepasst wurde. Die Funktionen <code>HasConflictingChanges()</code> und <code>ResolveConflict()</code> prüfen dabei die Verträglichkeit mithilfe von tbl. <strong>??</strong>.</p>
<div id="lst:file-sync" class="listing go">
<p>Listing 1: Synchronisationsalgorithmus für eine einzelne Datei</p>
<div class="sourceCode"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// historyA ist die Historie der eigenen Datei A.</span>
<span class="co">// historyB ist die Historie der fremden Datei B mit gleichem Pfad.</span>
<span class="kw">func</span> sync(historyA, historyB History) Result {
    <span class="kw">if</span> historyA.Equal(historyB) {
        <span class="co">// Keine weitere Aktion nötig.</span>
        <span class="kw">return</span> NoConflict
    }

    <span class="co">// Prüfe, ob historyA mit den Checkpoints von historyB beginnt.</span>
    <span class="kw">if</span> historyA.IsPrefix(historyB) {
        <span class="co">// B hängt A hinterher.</span>
        <span class="kw">return</span> NoConflict
    }

    <span class="kw">if</span> historyB.IsPrefix(historyA) {
        <span class="co">// A hängt B hinterher. Kopiere B zu A.</span>
        <span class="bu">copy</span>(B, A)
        <span class="kw">return</span> NoConflict
    }

    <span class="kw">if</span> root := historyA.FindCommonRoot(historyB); root != <span class="ot">nil</span> {
        <span class="co">// A und B haben trotzdem eine gemeinsame Historie,</span>
        <span class="co">// haben sich aber auseinanderentwickelt.</span>
        <span class="kw">if</span> !historyA.HasConflictingChanges(historyB, root) {
            <span class="co">// Die Änderungen sind verträglich und</span>
            <span class="co">// können automatisch aufgelöst werden.</span>
            ResolveConflict(historyA, historyB, root)
            <span class="kw">return</span> NoConflict
        }
    }

    <span class="co">// Keine gemeinsame Historie.</span>
    <span class="co">// -&gt; Nicht automatisch zusammenführbar.</span>
    <span class="co">// -&gt; Eine Konfliktstrategie muss angewandt werden.</span>
    <span class="kw">return</span> Conflict
}</code></pre></div>
</div>
<h3 id="synchronisation-von-verzeichnissen"><span class="header-section-number">5.2.3</span> Synchronisation von Verzeichnissen</h3>
<p>Die naive Herangehensweise wäre, den obigen Algorithmus für jede Datei im Verzeichnis zu wiederholen[^SYNC_ONLY_FILE]. Der beispielhafte Verzeichnisbaum in fig. 23 zeigt allerdings bereits ein Problem dabei: Die Menge an Pfaden, die Alice besitzt wird sich selten ganz mit denen decken, die Bob besitzt. So kann natürlich Alice Pfade besitzen, die Bob nicht hat und umgekehrt. Im Beispiel synchronisiert Alice mit Bob. Das heißt, Alice möchte die Änderungen von Bob empfangen.</p>
<a name="fig:tree-sync"></a>
<div class="figure">
<img src="images/4/tree-sync.png" id="fig:tree-sync" />
<p class="caption">Figure 23: Figure 23. Unterteilung der zu synchronisierenden Pfade in drei Gruppen.</p>
</div>
<p>Man könnte also das »naive« Konzept weiterführen und die Menge der zu synchronisierenden Pfade in drei Untermengen unterteilten. Jede dieser Untermengen hätte dann eine unterschiedliche Semantik:</p>
<ul>
<li>Pfade die beide haben (<span class="math inline"><em>X</em> = <em>P</em><em>a</em><em>t</em><em>h</em><em>s</em><sub><em>A</em></sub>⋂<em>P</em><em>a</em><em>t</em><em>h</em><em>s</em><sub><em>B</em></sub></span>): Konfliktpotenzial. Führe obigen Algorithmus für jede Datei aus. Pfade die nur Alice hat (<span class="math inline"><em>Y</em> = <em>P</em><em>a</em><em>t</em><em>h</em><em>s</em><sub><em>A</em></sub> \ <em>P</em><em>a</em><em>t</em><em>h</em><em>s</em><sub><em>B</em></sub></span>): Brauchen keine weitere Behandlung. - Pfade die nur Bob hat (<span class="math inline"><em>Z</em> = <em>P</em><em>a</em><em>t</em><em>h</em><em>s</em><sub><em>B</em></sub> \ <em>P</em><em>a</em><em>t</em><em>h</em><em>s</em><sub><em>A</em></sub></span>): Müssen nur hinzugefügt werden.</li>
</ul>
<p>Wie in fig. 23 angedeutet, sind diese Mengen allerdings schwerer zu bestimmen als durch eine simple Vereinigung, beziehungsweise Differenz. Zwei Beispiele verdeutlichen dies:</p>
<ul>
<li>Löscht Bob eine Datei, während Alice sie nicht verändert, würde der Pfad trotzdem in der Menge <span class="math inline"><em>Y</em></span> landen. Dies hätte zur Folge, dass die Löschung nicht zu Alice propagiert wird.</li>
<li>Verschiebt Bob eine Datei zu einem neuen Pfad, muss dieser neue Pfad trotzdem mit dem alten Pfad von Alice verglichen werden, um die Umbenennung zusammenzuführen. In fig. 23 sollte also der blaue Knoten mit dem grünen verglichen werden.</li>
</ul>
<p>Es muss also eine Abbildungsfunktion gefunden werden, die jedem Pfad von Alice einen Pfad von Bob zuordnet. Die Wertemenge dieser Funktion entspricht der Menge <span class="math inline"><em>X</em></span>, also aller Pfade die einer speziellen Konfliktauflösung bedürfen. Die Menge <span class="math inline"><em>Z</em></span> (also alle Pfade die Bob hat, aber Alice nicht) ergibt sich dann einfach durch <span class="math inline"><em>Z</em> = <em>P</em><em>a</em><em>t</em><em>h</em><em>s</em><sub><em>B</em></sub> \ <em>X</em></span>. Für die Abbildung der Pfade von Alice zu Bob’s Pfaden funktioniert die Abbildungsfunktion folgendermaßen:</p>
<ol style="list-style-type: decimal">
<li>Aus Bob’s Store werden alle Knoten gesammelt, die sich seit dem letzten gemeinsamen Merge–Point verändert haben. Falls es noch keinen gemeinsamen Merge–Point gab, werden alle Knoten angenommen.</li>
<li>Aus Bob’s Store wird für jeden Knoten die Historie (<span class="math inline">=</span> Liste aller Checkpoints) seit dem letzten Merge–Point gesammelt, oder die gesamte Historie (<span class="math inline">=</span> alle Checkpoints) falls es noch keinen Merge–Point gab.</li>
<li>Es wird eine Abbildung (als assoziatives Array) erstellt, die alle bekannten Pfade von Bob der jeweiligen Historie zuordnen, in dem der Pfad vorkommt. Mehr als ein Pfad kann dabei auf die gleiche Historie zeigen, wenn Verschiebungen vorkamen. Innerhalb dieser Spanne gelöschte Dateien sind in der Abbildung unter ihrem zuletzt bekannten Pfad zu finden.</li>
<li>Für alle Pfade, die Alice momentan besitzt (Alle Pfade unter <code>HEAD</code>), wird der Algorithmus in Listing <strong>??</strong> ausgeführt. Dieser ordnet jedem Pfad von Alice, einem Pfad von Bob zu oder meldet, dass er kein passendes Gegenstück finden konnte.</li>
</ol>
<div class="sourceCode" id="lst:sync-map"><pre class="sourceCode go"><code class="sourceCode go"><span class="co">// Ein assoziatives Array mit dem Pfad zu der Historie</span>
<span class="co">// seit dem letzten gemeinsamen Merge-Point.</span>
<span class="kw">type</span> PathToHistory <span class="kw">map</span>[<span class="dt">string</span>]History

<span class="co">// BobMapping enthält alle Pfade;</span>
<span class="co">// also auch Pfade die entfernt wurden (unter ihrem letzten Namen)</span>
<span class="co">// Wurden Pfade verschoben, so enthält das Mapping auch alle Zwischenschritte.</span>
<span class="kw">func</span> MapPath(HistA History, BobMapping PathToLastHistory) (<span class="dt">string</span>, <span class="dt">error</span>) {
    <span class="co">// Iteriere über alle Zwischenpfade, die `HistA` hatte.</span>
    <span class="co">// In den meisten Fällen (ohne Verschiebungen) also nur ein einziger.</span>
    <span class="kw">for</span> _, path := <span class="kw">range</span> HistA.AllPaths() {
        HistB, ok := BobMapping[path]

        <span class="co">// Diesen Pfad hatte Bob nicht.</span>
        <span class="kw">if</span> !ok {
            <span class="kw">continue</span>
        }

        <span class="co">// Erfolg! Gebe den aktuellsten Pfad von Bob zurück.</span>
        <span class="co">// Also der Pfad an dem die Datei zuletzt bei Bob war,</span>
        <span class="co">// beziehungsweise der Pfad des aktuellsten Checkpoints.</span>
        <span class="kw">return</span> HistB.MostCurrentPath(), <span class="ot">nil</span>
    }

    <span class="co">// Bob hat diesen Pfad nirgends.</span>
    <span class="co">// -&gt; Es muss ein Pfad sein, den nur Alice hat.</span>
    <span class="kw">return</span> <span class="st">&quot;&quot;</span>, ErrNoMappingFound
}</code></pre></div>
<p>Das Ergebnis dieses Vorgehens ist eine Abbildung aller Pfade von Alice zu den Pfaden von Bob. Damit wurde eine eindeutige Zuordnung erreicht und die einzelnen Dateien können mit dem Algorithmus unter sec. 5.2.2 synchronisiert werden. Die Dateien, die Bob zusätzlich hat (aber Alice nicht) können nun leicht ermittelt werden, indem geprüft wird welche von Bob’s Pfaden noch nicht in der errechneten Wertemenge der Abbildung vorkommen. Diese Pfade können dann in einem zweiten Schritt dem Stand von Alice hinzugefügt werden.</p>
<p>Darüber hinaus gibt es noch einen Spezialfall, der vor der eigentlichen Synchronisation abgeprüft werden muss. Hat einer der beiden Partner keine Änderungen gemacht und haben beide Partner eine gemeinsame Historie, kann der Stand »vorgespult« werden. Das heißt, alle Änderungen der Gegenseite können direkt übernommen werden. Dieses Vorgehen ist bei <code>git</code> auch als <em>Fast–Forward–Merge</em> bekannt (<code>git merge --ff</code>). Anders als bei <code>git</code> wird bei <code>brig</code> allerdings immer ein Merge–Point erstellt, weswegen dies nur eine algorithmische Optimierung darstellt.</p>
<h3 id="sec:metadata-exchange"><span class="header-section-number">5.2.4</span> Austausch der Metadaten</h3>
<p>Um die Metadaten nun tatsächlich synchronisieren zu können, muss ein Protokoll etabliert werden, mit dem zwei Partner ihren Store über das Netzwerk austauschen können. Im Folgenden wird diese Operation, analog zum gleichnamigen <code>git</code>–Kommando<a href="#fn79" class="footnoteRef" id="fnref79"><sup>79</sup></a>, <code>brig fetch</code> genannt.</p>
<a name="fig:fetch-protocol"></a>
<div class="figure">
<img src="images/4/fetch-protokoll.png" id="fig:fetch-protocol" />
<p class="caption">Figure 24: Figure 24. Das Protokoll das bei der <code>FETCH</code>–Operation ausgeführt wird.</p>
</div>
<p>Wie in fig. 24 gezeigt, besteht das Protokoll aus drei Teilen:</p>
<ul>
<li>Alice schickt eine <code>FETCH</code>–Anfrage zu Bob, der den Namen des zu holenden Stores enthält. Im Beispiel ist dies Bob’s eigener Store, <code>bob@realworld.org</code>.</li>
<li>Falls Alice in Bob’s Remote–Liste steht, wandelt Bob seinen eigenen Store in eine exportierbare Form um, die aus einer großen serialisierten Nachricht<a href="#fn80" class="footnoteRef" id="fnref80"><sup>80</sup></a> besteht, die alle notwendigen Daten enthält.</li>
<li>Die serialisierte Form des Stores wird über den Transfer–Layer von <code>brig</code> (siehe sec. 5.4.2) zurück an <code>alice@wonderland.lit</code> geschickt.</li>
<li>Alice importiert die serialisierte Form in einen neuen, leeren Store und speichert das Ergebnis in der Liste der Stores ihrer Kommunikationspartner. Eine Synchronisation der beiden Metadatensätze kann nun lokal bei Alice erfolgen.</li>
</ul>
<p>Aus Zeitgründen ist dieses Protokoll momentan noch sehr einfach gehalten und beherrscht keine differentiellen Übertragungen. Da hier nur Metadaten übertragen werden sollte das nur bedingt ein Problem sein. In der Tat müssten aber nur die Commits seit dem letzten gemeinsamen Merge–Point übertragen werden.</p>
<p>Auch sind zum momentanen Stand noch keine <em>Live–Updates</em> möglich. Hierfür müssten sich die einzelnen Knoten bei jeder Änderung kleine <em>Update–Pakete</em> schicken, welche einen einzelnen <em>Checkpoint</em> beinhalten würden. Diese Checkpoints müssten dann jeweils in den aktuellen Staging–Bereich eingepflegt werden. Dadurch wären Änderungen in »Echtzeit« auf anderen Knoten verfügbar. Aus Zeitgründen wird an dieser Stelle aber nur auf diese Möglichkeit verwiesen; eine konzeptuelle Implementierung hierzu steht noch aus.</p>
<h3 id="abgrenzung-zu-anderen-synchronisationswerkzeugen"><span class="header-section-number">5.2.5</span> Abgrenzung zu anderen Synchronisationswerkzeugen</h3>
<p>In der Fachliteratur (vgl. unter anderem <span class="citation">[9]</span>) findet sich zudem die Unterscheidung zwischen <em>informierter</em> und <em>uninformierter</em> Synchronisation. Der Hauptunterschied ist, dass bei ersterer die Änderungshistorie jeder Datei als zusätzliche Eingabe zur Verfügung steht. Auf dieser Basis können dann intelligentere Entscheidungen bezüglich der Konflikterkennung getroffen werden. Insbesondere können dadurch aber leichter die Differenzen zwischen den einzelnen Ständen ausgemacht werden: Für jede Datei muss dabei lediglich die in Listing 1 gezeigte Sequenz abgelaufen werden, die von beiden Synchronisationspartnern unabhängig ausgeführt werden muss. Werkzeuge wie <code>rsync</code> oder <code>unison</code> betreiben eine <em>uninformierte Synchronisation</em>. Sie müssen bei jedem Programmlauf Metadaten über beide Verzeichnisse sammeln und darauf arbeiten.</p>
<h3 id="speicherquoten"><span class="header-section-number">5.2.6</span> Speicherquoten</h3>
<p>Werden immer mehr Modifikationen gespeichert, so steigt der Speicherverbrauch immer weiter an, da ohne ein Differenzmechanismus jede Datei pro Version einmal voll abgespeichert werden muss. Die Anzahl der Objekte die dabei gespeichert werden können, hängt von dem verfügbaren Speicherplatz ab. Sehr alte Versionen werden dabei typischerweise nicht mehr benötigt und können bei Platzbedarf gelöscht werden. Diese Aufgabe wird derzeit nicht von <code>brig</code> selbst übernommen, sondern vom <code>ipfs</code>–Backend. Dieses unterstützt mit dem Befehl <code>ipfs gc</code> eine Bereinigung von Objekten, die keinen Pin mehr haben. Zudem kann <code>brig</code> den Konfigurationswert <code>Datastore.StorageMax</code> von <code>ipfs</code> auf eine maximale Höhe (minus einen kleinen Puffer für <code>brig</code>–eigene Dateien) setzen. Wird dieser überschritten, geht der Garbage–Collector aggressiver vor und löscht nicht gepinnte Objekte sofort. In der momentanen Architektur und Implementierung sind allerdings zu diesem Zeitpunkt noch keine Speicherquoten vorhanden.</p>
<p>Eine Möglichkeit den Speicherverbrauch zu reduzieren, wäre die Einführung von <em>Packfiles</em>, wie <code>git</code> sie implementiert<a href="#fn81" class="footnoteRef" id="fnref81"><sup>81</sup></a>. Diese komprimieren nicht eine einzelne Datei, sondern packen mehrere Objekte in ein zusammengehöriges Archiv. Dies kann die Kompressionsrate stark erhöhen wenn viele ähnliche Dateien (beispielsweise viele subtil verschiedene Versionen der gleichen Datei) zusammen gepackt werden. Nachteilig sind die langsameren Zugriffszeiten. Eine Implementierung dieser Lösung müsste zwischen eigentlichem Datenmodell und dem <code>ipfs</code>–Backend eine weitere Schicht einschieben, welche transparent und intelligent passende Dateien in ein Archiv verpackt und umgekehrt auch wieder entpacken kann. Diese Idee wird in sec. 8.5.1 noch einmal aufgegriffen.</p>
<h2 id="architekturübersicht"><span class="header-section-number">5.3</span> Architekturübersicht</h2>
<p>Um den eigentlichen Kern des Store sind alle anderen Funktionalitäten gelagert. fig. 25 zeigt diese in einer Übersicht. Die einzelnen Unterdienste werden im Folgenden besprochen.</p>
<a name="fig:arch-overview"></a>
<div class="figure">
<img src="images/4/architecture-overview.png" id="fig:arch-overview" />
<p class="caption">Figure 25: Figure 25. Übersicht über die Architektur von <code>brig</code>.</p>
</div>
<h3 id="lokale-aufteilung-in-client-und-daemon"><span class="header-section-number">5.3.1</span> Lokale Aufteilung in Client und Daemon</h3>
<p><code>brig</code> ist architektonisch in einem langlebigen Daemon–Prozess und einem kurzlebigen Kontroll–Prozess aufgeteilt, welche im Folgenden jeweils <code>brigd</code> und <code>brigctl</code> genannt werden<a href="#fn82" class="footnoteRef" id="fnref82"><sup>82</sup></a>. Beide Prozesse kommunizieren dabei über das Netzwerk mit einem speziellen Protokoll, welches auf einen Serialisierungsmechanismus von Google namens <em>Protobuf</em><a href="#fn83" class="footnoteRef" id="fnref83"><sup>83</sup></a> basiert. Dabei wird basierend auf einer textuellen Beschreibung des Protokolls (einer <code>.proto</code>–Datei mit eigener Syntax) Quelltext in der gewünschten Zielsprache generiert. Dieser Quelltext ist dann in der Lage, Datenstrukturen von der Zielsprache in ein serialisiertes Format zu überführen, beziehungsweise dieses wieder einzulesen. Als Format steht dabei wahlweise eine speichereffiziente, binäre Repräsentation der Daten zur Verfügung, oder eine menschenlesbare Darstellung als JSON–Dokument.</p>
<p>Nötig ist die Aufteilung vor allem, da <code>brigd</code> im Hintergrund als Netzwerkdienst laufen muss, um Anfragen von Außen verarbeiten zu können. Auch läuft <code>ipfs</code> im selben Prozess wie <code>brigd</code> und muss daher stets erreichbar sein. Abgesehen davon ist es aus Effizienzgründen förderlich, wenn nicht bei jedem eingetippten Kommando das gesamte Repository geladen werden muss. Auch ist es durch die Trennung möglich, dass <code>brigd</code> auch von anderen Programmiersprachen und Prozessen auf dem selben Rechner aus gesteuert werden kann. Verbindungen von außen sollten aus Sicherheitsgründen nicht angenommen werden. Unter unixoiden Betriebssystemen wäre eine Alternative zu normalen Netzwerksockets die Nutzung von Unix–Domain–Sockets<a href="#fn84" class="footnoteRef" id="fnref84"><sup>84</sup></a>. Diese sind als Datei im Dateisystem erreichbar und können daher mit entsprechenden Zugriffsrechten nur von bestimmten Nutzern benutzt werden.</p>
<h3 id="sec:client"><span class="header-section-number">5.3.2</span> <code>brigctl</code>: Aufbau und Aufgabe</h3>
<p>Zusammengefasst ist <code>brigctl</code> eine »Fernbedienung« für <code>brigd</code>, welche im Moment exklusiv von der Kommandozeile aus bedient wird. In den meisten Fällen verbindet sich der Kommando–Prozess <code>brigctl</code> beim Start zu <code>brigd</code>, sendet ein mittels <em>Protobuf</em> serialisiertes Kommando und wartet auf die dazugehörige Antwort welche dann deserialisiert wird. Nachdem die empfangene Antwort, je nach Art, ausgewertet wurde, beendet sich der Prozess wieder.</p>
<p><strong>Protobuf Protokoll:</strong> Das Protokoll ist dabei so aufgebaut, dass für jede Aufgabe, die <code>brigd</code> erledigen soll ein separates Kommando existiert. Neben einer allgemeinen Typbezeichnung, können auch vom Kommando abhängige optionale und erforderliche Parameter enthalten sein. Ein gekürzter Auszug aus der Protokollspezifikation veranschaulicht dies in Listing <strong>??</strong>.</p>
<div class="sourceCode" id="lst:proto-command"><pre class="sourceCode c"><code class="sourceCode c"><span class="kw">enum</span> MessageType {
    ADD = <span class="dv">0</span>;
    <span class="co">// ...</span>
}

message Command {
    <span class="co">// Typ des Kommandos</span>
    required MessageType command_type = <span class="dv">1</span>;

    message AddCmd {
        <span class="co">// Absoluter Pfad zur Datei auf der Festplatte des Nutzers.</span>
        required string file_path = <span class="dv">1</span>;

        <span class="co">// Pfad innerhalb von brig (/photos/me.png)</span>
        required string repo_path = <span class="dv">2</span>;

        <span class="co">// Füge Verzeichnisse rekursiv hinzu? (Standard: Ja)</span>
        optional bool recursive = <span class="dv">3</span>;
    }
    <span class="co">// ... weitere Subkommandos ...</span>

    <span class="co">// Falls der Typ ADD war, lese von &#39;add_commando&#39;</span>
    optional AddCmd add_command = <span class="dv">2</span>;
    <span class="co">// ... weitere Kommandoeinträge ...</span>
}</code></pre></div>
<p>Analog dazu kann <code>brigd</code> mit einer <em>Response</em> auf ein <em>Command</em> antworten. In Listing <strong>??</strong> wird beispielhaft die Antwortspezifikation (<code>OnlineStatusResp</code>) auf ein <code>OnlineStatusCmd</code>–Kommando gezeigt, welches prüft, ob <code>brigd</code> Verbindungen von Außen annimmt.</p>
<div class="sourceCode" id="lst:proto-response"><pre class="sourceCode c"><code class="sourceCode c">message Response {
    <span class="co">// Typ der Antwort</span>
    required MessageType response_type = <span class="dv">1</span>;

    <span class="co">// Wahr, falls es keine Fehlerantwort ist</span>
    required bool success = <span class="dv">2</span>;

    <span class="co">// Bei einem Fehler wird ein optionale Fehlerbeschreibung angegeben.</span>
    optional string error = <span class="dv">3</span>;

    <span class="co">// Detaillierter Fehlercode (noch nicht benutzt)</span>
    optional id errno = <span class="dv">4</span>;

    message OnlineStatusResp {
        required bool is_online = <span class="dv">1</span>;
    }
    <span class="co">// ... Mehr Unterantworten ...</span>

    optional OnlineStatusResp online_status_resp = <span class="dv">5</span>;
    <span class="co">// ... Mehr Antworteinträge ...</span>
}</code></pre></div>
<p>Neben der Kommunikation mit <code>brigd</code> muss <code>brigctl</code> noch drei andere Aufgaben erledigen:</p>
<ul>
<li><strong>Initiales Anlegen eines Repositories:</strong> Bevor <code>brigd</code> gestartet werden kann, muss die in fig. 35 gezeigte Verzeichnisstruktur angelegt werden.</li>
<li><strong>Bereitstellung des User–Interfaces:</strong> Das zugrundeliegende Protokoll wird so gut es geht vom Nutzer versteckt und Fehlermeldungen müssen möglichst gut beschrieben werden.</li>
<li><strong>Autostart von <code>brigd</code>:</strong> Damit der Nutzer nicht explizit <code>brigd</code> starten muss, sollte der Daemon–Prozess automatisch im Hintergrund gestartet werden, falls er noch nicht erreichbar ist. Dies setzt <code>brigctl</code> um, indem es dem Nutzer nach dem Passwort zum Entsperren eines Repositories fragt und das Passwort beim Start an <code>brigd</code> weitergibt, damit der Daemon–Prozess das Repository entsperren kann.</li>
</ul>
<h3 id="brigd-aufbau-und-aufgabe"><span class="header-section-number">5.3.3</span> <code>brigd</code>: Aufbau und Aufgabe</h3>
<p>Der Daemon–Prozess implementiert alle Kernfunktionalitäten. Die einzelnen Komponenten werden in sec. 5.4 beschrieben.</p>
<p>Als Netzwerkdienst muss <code>brigd</code> auf einem bestimmten Port (momentan standardmäßig Port <code>6666</code> auf <code>127.0.0.1</code>) auf Anfragen warten. Es werden keine Anfragen von Außen angenommen, da über diese lokale Verbindung fast alle sicherheitskritischen Informationen ausgelesen werden können. Für den Fall, dass ein Angreifer den lokalen Netzwerkverkehr mitlesen kann wird der gesamte Netzwerkverkehr zwischen <code>brigctl</code> und <code>brigd</code> mit AES256 verschlüsselt. Der Schlüssel wird beim Verbindungsaufbau mittels Diffie–Hellmann ausgetauscht. Die Details des Protokolls werden in <span class="citation">[27]</span> beschrieben.</p>
<p>Die Anzahl der gleichzeitig offenen Verbindungen wird auf ein Maximum von <code>50</code> limitiert und Verbindungen werden nach Inaktivität mit einer Zeitüberschreitung von 10 Sekunden automatisch getrennt. Diese Limitierungen soll verhindern, dass fehlerhafte Clients den Hintergrundprozess zu stark auslasten.</p>
<p>Im selben Prozess wie <code>brigd</code> läuft auch der <code>ipfs</code>–Daemon und nutzt dabei standardmäßig den Port <code>4001</code>, um sich mit dem Netzwerk zu verbinden. Nachteilig an diesem Vorgehen ist, dass ein Absturz oder eine Sicherheitslücke in <code>ipfs</code> auch <code>brigd</code> betreffen kann. Längerfristig sollten beide Prozesse möglichst getrennt werden, auch wenn dies aus Effizienzgründen nachteilig ist.</p>
<h2 id="sec:einzelkomponenten"><span class="header-section-number">5.4</span> Einzelkomponenten</h2>
<p>Im Folgenden werden die einzelnen Komponenten von <code>brigd</code> aus architektonischer Sicht erläutert. Genauere Angaben zu Implementierungsdetails, insbesondere zum FUSE–Dateisystem, folgen im nächsten Kapitel.</p>
<h3 id="dateiströme"><span class="header-section-number">5.4.1</span> Dateiströme</h3>
<p>Im <code>ipfs</code>–Backend werden nur verschlüsselte und zuvor komprimierte Datenströme gespeichert. Verschlüsselung ist bei <code>brig</code> nicht optional. Hat ein Angreifer die Prüfsumme einer Datei erbeutet, so kann er die Datei aus dem <code>ipfs</code>–Netzwerk empfangen. Solange die Datei aber verschlüsselt ist, so wird der Angreifer alleine mit den verschlüsselten Daten ohne den dazugehörigen Schlüssel nichts anfangen können. In der Tat unterstützt er das <code>ipfs</code>–Netzwerk sogar, da der Knoten des Angreifers auch wieder seine Bandbreite zum Upload anbieten muss, da der Knoten sonst ausgebremst wird. Aus diesem Grund ist es aus Sicherheitsperspektive keine Notwendigkeit, <code>brig</code> in einem abgeschotteten Netzwerk zu betreiben. Standardmäßig verbindet sich <code>brig</code> mit dem weltweiten <code>ipfs</code>–Netzwerk, indem es die standardmäßig eingetragenen Bootstrap–Knoten kontaktiert.</p>
<p>Nachteilig an einer »zwangsweisen« Verschlüsselung ist, dass die Deduplizierungsfähigkeit von <code>ipfs</code> ausgeschaltet wird. Wird die selbe Datei mit zwei unterschiedlichen Schlüsseln verschlüsselt, so werden die resultierenden Daten (bis auf ihre Größe) keine Ähnlichkeit besitzen, sind also kaum deduplizierbar. Trotzdem ist die Unterteilung in Blöcke durch <code>ipfs</code> sinnvoll, da dadurch bereits heruntergeladene Blöcke nicht ein zweites Mal besorgt werden müssen. So lässt sich der Download von großen Dateien unterbrechbar und wieder fortsetzbar gestalten.</p>
<p>Eine mögliche Lösung wäre ein Verfahren namens <em>Convergent Encryption</em><span class="citation">[10]</span>. Dabei wird der Schlüssel der zu verschlüsselnden Datei aus der Prüfsumme derselben Datei abgeleitet. Dies hat den Vorteil, dass gleiche Dateien auch den gleichen (deduplizierbaren) Ciphertext generieren. Der Nachteil ist, dass ein Angreifer feststellen kann, ob jemand eine Datei (beispielsweise Inhalte mit urhebergeschützten Inhalten) besitzt. Im Protoypen werden die Dateischlüssel daher zufällig generiert, was die Deduplizierungsfunktion von <code>ipfs</code> momentan ausschaltet. Dies hat auch zur Folge, dass die Synchronisation von zwei unabhängig hinzugefügten, aber sonst gleichen Dateien zwangsweise dazu führt, dass diese unterschiedlich sind, da auf beiden Seiten jeweils ein anderer Schlüssel generiert wird. Die Vor- und Nachteile dieses Verfahrens wird weiter in <span class="citation">[27]</span> diskutiert.</p>
<h4 id="sec:encryption"><span class="header-section-number">5.4.1.1</span> Verschlüsselung</h4>
<p>Für <code>brig</code> wurde ein eigenes Containerformat für verschlüsselte Daten eingeführt, welches wahlfreien Zugriff auf beliebige Bereiche der verschlüsselten Datei erlaubt, ohne die gesamte Datei entschlüsseln zu müssen. Dies ist eine wichtige Eigenschaft für die Implementierung des FUSE–Dateisystems und ermöglicht zudem aus technischer Sicht das Streaming von großen, verschlüsselten Dateien wie Videos. Zudem kann das Format durch den Einsatz von <em>Authenticated Encryption (AE</em>, <span class="citation">[3]</span>) die Integrität der verschlüsselten Daten sichern.</p>
<p>Es werden lediglich reguläre Dateien verschlüsselt. Verzeichnisse existieren nur als Metadaten und werden nicht von <code>ipfs</code> gespeichert. Die Details und Entscheidungen zum Design des Formats werden in <span class="citation">[27]</span> dargestellt.</p>
<a name="fig:format-encryption"></a>
<div class="figure">
<img src="images/4/format-encryption.png" id="fig:format-encryption" />
<p class="caption">Figure 26: Figure 26. Aufbau des Verschlüsselungs–Dateiformats.</p>
</div>
<p><strong>Enkodierung:</strong> fig. 26 zeigt den Aufbau des Formats. Ein roher Datenstrom (dessen Länge nicht bekannt sein muss) wird an den Enkodierer gegeben. Als weitere Eingabe muss ein Algorithmus ausgewählt werden und ein entsprechend dimensionierter, symmetrischer Schlüssel mitgegeben werden. Werden die ersten Daten geschrieben, so schreibt der Kodierer zuerst einen 36–Byte großen Header. In diesem finden sich folgende Felder:</p>
<ul>
<li>Eine <em>Magic–Number</em><a href="#fn85" class="footnoteRef" id="fnref85"><sup>85</sup></a> (8 Byte, ASCII–Repräsentation von <code>moosecat</code>) zur schnellen Identifikation einer von <code>brig</code> geschriebenen Datei.</li>
<li>Die <em>Versionsnummer</em> (2 Byte) des vorliegenden Formats. Standardmäßig »<code>0x01</code>«. Sollten Änderungen am Format nötig sein, so müssen nur die ersten 10 Byte beibehalten werden und die Versionsnummer inkrementiert werden. Für die jeweilige Version kann dann ein passender Dekodierer genutzt werden.</li>
<li>Die verwendete <em>Blockchiffre</em> (siehe <span class="citation">[27]</span>) (2 Byte) zur Verschlüsselung. Standardmäßig wird <em>ChaCha20/Poly1305</em> (siehe <span class="citation">[20]</span>) eingesetzt, aber es kann auch AES (siehe <span class="citation">[18]</span>, S. 116 ff.) mit 256 Bit Schlüssellänge im Galois–Counter–Modus (GCM, siehe <span class="citation">[27]</span>) verwendet werden.</li>
<li>Die <em>Länge</em> (4 Byte) des verwendeten Schlüssels in Bytes.</li>
<li>Die <em>maximale Blockgröße</em> (4 Byte) der nachfolgenden Blöcke in Bytes.</li>
<li>Ein <em>Message–Authentication–Code (MAC, siehe auch <span class="citation">[18]</span>, S. 205 ff.)</em> (16 Byte) der die Integrität des Headers sicherstellt.</li>
</ul>
<p>Nachdem der Header geschrieben wurde, sammelt der Enkodierer in einem internen Puffer ausreichend viele Daten, um einen zusammenhängenden Block zu schreiben (standardmäßig 64 Kilobyte). Ist diese Datenmenge erreicht, wird der Inhalt des Puffers verschlüsselt und ein kompletter Block ausgegeben. Dieser enthält folgende Felder:</p>
<ul>
<li>Eine <em>Nonce</em> (siehe auch <span class="citation">[18]</span>, S. 263) (8 Byte). Diese eindeutige Nummer wird bei jedem geschriebenen Block inkrementiert und stellt daher die Blocknummer dar. Sie wird benutzt, um die Reihenfolge des geschriebenen Datenstroms zu validieren und wird zudem als öffentlich bekannte Eingabe für den Verschlüsselungsalgorithmus benutzt.</li>
<li>Die eigentlichen, verschlüsselten Daten. Diese sind maximal so lang wie die maximale Blockgröße, können aber im Falle des letzten Blockes kleiner sein.</li>
<li>Am Ende kann, je nach Algorithmus, ein gewisse Überlänge durch <em>Padding</em> entstehen. Zudem wird an jeden Block eine weitere MAC angehängt, welche die Integrität der Nonce und der nachfolgenden, verschlüsselten Daten sicherstellt.</li>
</ul>
<p>So wird blockweise weiter verfahren, bis alle Daten des Ursprungsdatenstroms aufgebraucht worden sind. Der letzte Block darf als einziger kleiner als die maximale Blockgröße sein. Der resultierende Datenstrom ist etwas größer als der Eingabedatenstrom. Seine Größe lässt sich wie in eq. 2 gezeigt mithilfe der Eingabegröße <span class="math inline"><em>s</em></span> der Datei in Bytes und der Blockgröße <span class="math inline"><em>b</em></span> berechnen:</p>
<p><br /><span class="math display">$$f_{\text{size}}(s) = 36 + s + \left\lceil\frac{s}{b}\right\rceil\times(8 + 16)\qquad(2)$$</span><br /></p>
<p>Was den Speicherplatz angeht, hält sich der »Overhead« in Grenzen. Zwar wächst eine fast leere Datei von 20 Byte Originalgröße auf 80 Byte nach der Verschlüsselung, aber bereits eine 20 Megabyte große Datei wächst nur noch um zusätzliche 7.5 Kilobyte (<span class="math inline">+0.03%</span>).</p>
<p><strong>Dekodierung:</strong> Beim Lesen der Datei wird zuerst der Header ausgelesen und auf Korrektheit geprüft. Korrekt ist er wenn eine Magic–Number vorhanden ist, alle restlichen Felder erlaubte Werte haben und die Integrität des Headers bis Byte 20 durch die darauffolgende MAC überprüft werden konnte. Konnte die Integrität nicht überprüft werden, wurden entweder Daten im Header verändert oder ein falscher Schlüssel wurde übergeben.</p>
<p>Jeder zu lesende Block wird im Anschluss komplett in einen Puffer gelesen. Die Nonce wird ausgelesen und dem Entschlüsselungsalgorithmus als Eingabge neben dem eigentlichen Datenblock und dem Schlüssel mitgegeben. Dieser überprüft ob die Integrität des Datenblocks korrekt ist und entschlüsselt diesen im Erfolgsfall. Anhand der Position im Datenstrom wird zudem überprüft ob die Blocknummer zum Wert in der Nonce passt. Stimmen diese nicht überein, wird die Entschlüsselung verweigert, da ein Angreifer möglicherweise die Reihenfolge der Blöcke hätte vertauschen können.</p>
<p><strong>Wahlfreier Zugriff:</strong> Wurde der Header bereits gelesen, so kann ein beliebiger Block im Datenstrom gelesen werden, sofern der unterliegende Datenstrom wahlfreien Zugriff (also die Anwendung von <code>Seek()</code>) erlaubt. Die Anfangsposition des zu lesenden Blocks kann mit eq. 3 berechnet werden, wobei <span class="math inline"><em>o</em></span> der Offset im unverschlüsselten Datenstrom ist.</p>
<p><br /><span class="math display">$$f_{\text{offset}}(o) = 36 + \left\lceil\frac{o}{b}\right\rceil\times(8 + 16 + b)\qquad(3)$$</span><br /></p>
<p>Der Block an dieser Stelle muss komplett gelesen und entschlüsselt werden, auch wenn nur wenige Bytes innerhalb des Blocks angefragt werden. Da typischerweise die Blöcke aber fortlaufend gelesen werden, ist das aus Sicht des Autors ein vernachlässigbares Problem.</p>
<p>Die einzelnen Blocks des vorgestellten Formats ähneln der <em>Secretbox</em> der freien NaCL–Bibliothek<a href="#fn86" class="footnoteRef" id="fnref86"><sup>86</sup></a>. Diese erlaubt allerdings keinen wahlfreien Zugriff. Abgesehen handelt es sich um eine Neuentwicklung, die auch außerhalb von <code>brig</code> eingesetzt werden kann.</p>
<h4 id="kompression"><span class="header-section-number">5.4.1.2</span> Kompression</h4>
<p>Bevor Datenströme verschlüsselt werden, werden diese von <code>brig</code> auch komprimiert<a href="#fn87" class="footnoteRef" id="fnref87"><sup>87</sup></a>. Auch hier wurde ein eigenes Containerformat entworfen, welches in fig. 27 gezeigt wird.</p>
<a name="fig:format-compression"></a>
<div class="figure">
<img src="images/4/format-compression.png" id="fig:format-compression" />
<p class="caption">Figure 27: Figure 27. Aufbau des Kompressions–Dateiformats.</p>
</div>
<p>Nötig war dieser Schritt auch hier wieder, weil kein geeignetes Format gefunden werden konnte, welches wahlfreien Zugriff im komprimierten Datenstrom zulässt, ohne dass dabei die ganze Datei entpackt werden muss.</p>
<p><strong>Enkodierung:</strong> Der Eingabedatenstrom wird in gleich große Blöcke unterteilt (standardmäßig maximal 64KB), wobei nur der letzte Block kleiner sein darf. Nachdem der Header geschrieben wurde, folgt jeder Eingabeblock als komprimierter Block mit variabler Länge. Am Schluss wird ein Index geschrieben, der beschreibt welcher Eingabeblock mit welchem komprimierten Block korrespondiert. Der Index kann nur am Ende geschrieben werden, da die genauen Offsets innerhalb dieses Indexes erst nach dem Komprimieren bekannt sind. Für eine effiziente Nutzung dieses Formats ist es also nötig, dass der Datenstrom einen effizienten, wahlfreien Zugriff am Ende der Datei bietet. Glücklicherweise unterstützt dies <code>ipfs</code>. Datenströme wie <code>stdin</code> unter Unix unterstützen allerdings keinen wahlfreien Zugriff, weshalb das vorgestellte Format für solche Anwendungsfälle eher ungeeignet ist.</p>
<p>Der Index besteht aus zwei Teilen: Aus dem eigentlichen Index und einem sogenannten »Trailer«, der die Größe des Indexes enthält. Zusätzlich enthält dieser Trailer noch die verwendete Blockgröße, in die der unkomprimierte Datenstrom unterteilt wurde. Der eigentliche Index besteht aus einer Liste von 64–Bit Offset–Paaren. Jedes Paar enthält einmal den unkomprimierten und einmal den komprimierten Offset eines Blocks als Absolutwert gemessen vom Anfang des Datenstroms. Am Ende wird ein zusätzliches Paar eingefügt, welches zu keinem realen Block verweist. Dieses letzte Paar beschreibt die Größe des unkomprimierten und komprimierten Datenstroms.</p>
<p>Der vorangestellte Header enthält alle Daten, die definitiv vor der Kompression des ersten Blockes vorhanden sind:</p>
<ul>
<li>Eine <em>Magic–Number</em> (8 Byte, ASCII Repräsentation von <code>elchwald</code>). Wie beim Verschlüsselungsformat dient diese zur schnellen Erkennung dieses Formats.</li>
<li>Eine <em>Formatversion</em> (2 Byte, momentan »<code>0x01</code>«). Kann analog zum Verschlüsselungsformat bei Änderungen inkrementiert werden.</li>
<li><p>Der verwendete <em>Algorithmustyp</em> (2 Byte, standardmäßig <em>Snappy</em>). Folgende Algorithmen werden momentan unterstützt:</p>
<ul>
<li>Snappy<span class="citation">[28]</span> (sehr schneller Algorithmus mit akzeptabler Kompressionsrate)</li>
<li>LZ4<span class="citation">[16]</span> (etwas langsamer, aber deutlich höhere Kompressionsrate)</li>
<li>None (gar keine Kompression, Index wird trotzdem geschrieben)</li>
</ul>
<p>Weitere Algorithmen wie <em>Brotli</em><span class="citation">[7]</span> können problemlos hinzugefügt werden, allerdings gab es zu diesen Zeitpunkten noch keine vernünftig nutzbaren Bibliotheken.</p></li>
</ul>
<p><strong>Dekodierung:</strong> Bevor der erste Block dekodiert werden kann muss sowohl der Header als auch der Index geladen werden. Dazu müssen die ersten 12 Bytes des Datenstroms gelesen werden. Im Anschluss muss fast an das Ende (Ende minus 12 Byte) des Datenstroms gesprungen werden, um dort den Trailer zu lesen. Mit der darin enthaltenen Größe des Indexes kann die Anfangsposition des Indexes bestimmt werden (Ende minus 12 Byte minus Indexgröße). Alle Offset–Paare im Index werden in eine sortierte Liste geladen. Die Blockgröße eines komprimierten/unkomprimierten Blocks an der Stelle ergibt sich dabei aus der Differenz des Offset–Paars an der Stelle <span class="math inline"><em>n</em> + 1</span> und seines Vorgängers an der Stelle <span class="math inline"><em>n</em></span>. Mithilfe der Blockgröße kann ein entsprechend dimensioniertes Stück vom komprimierten Datenstrom gelesen und dekomprimiert werden.</p>
<p><strong>Wahlfreier Zugriff:</strong> Um auf einen beliebigen Offset <span class="math inline"><em>o</em></span> im unkomprimierten Datenstrom zuzugreifen, muss dieser zunächst in den komprimierten Offset übersetzt werden. Dazu muss mittels binärer Suche im Index der passende Anfang des unkomprimierten Blocks gefunden werden. Wurde der passende Block bestimmt, ist auch der Anfangsoffset im komprimierten Datenstrom bekannt. Dadurch kann der entsprechende Block ganz geladen und dekomprimiert werden. Innerhalb der dekomprimierten Daten kann dann vom Anfangsoffset <span class="math inline"><em>a</em></span> noch zum Zieloffset <span class="math inline"><em>o</em> − <em>a</em></span> gesprungen werden.</p>
<h3 id="sec:transfer-layer"><span class="header-section-number">5.4.2</span> Transfer–Layer</h3>
<p>Damit Metadaten ausgetauscht werden können, ist ein sicherer Steuerkanal nötig, der unabhängig vom Datenkanal ist, über den die eigentlichen Daten ausgetauscht werden. Über diesen muss ein <em>Remote–Procedure–Call</em> (RPC<a href="#fn88" class="footnoteRef" id="fnref88"><sup>88</sup></a>) ähnliches Protokoll implementiert werden, damit ein Teilnehmer Anfragen an einen anderen stellen kann.</p>
<p>Die Basis dieses sicheren Steuerkanals wird von <code>ipfs</code> gestellt. Dabei wird kein zusätzlicher Netzwerkport für den RPC–Dienst in Anspruch genommen, da alle Kommunikation über den selben Kanal laufen, wie die eigentliche Datenübertragung. Es findet also eine Art »Multiplexing« statt.</p>
<p>Dies wird durch das fortgeschrittene Netzwerkmodell von <code>ipfs</code> möglich<a href="#fn89" class="footnoteRef" id="fnref89"><sup>89</sup></a>, welches in fig. 28 gezeigt wird. Nutzer des gezeigten Netzwerkstacks können eigene Protokolle registrieren, die mittels eines <em>Muxing–Protokolls</em> namens <em>Multistream</em><a href="#fn90" class="footnoteRef" id="fnref90"><sup>90</sup></a> in einer einzigen, gemeinsamen physikalischen Verbindung zusammengefasst werden. Der sogenannte <em>Swarm</em> hält eine Verbindung zu allen zu ihm verbundenen Peers und macht es so möglich jeden Netzwerkpartner von der Protokollebene aus über seine Peer–ID anzusprechen. Der eigentliche Verbindungsaufbau geschieht dann, wie in sec. 4.1.1 beschrieben auch über NAT–Grenzen hinweg.</p>
<a name="fig:ipfs-net"></a>
<div class="figure">
<img src="images/4/ipfs-network.png" id="fig:ipfs-net" style="width:60.0%" />
<p class="caption">Figure 28: Figure 28. Der Netzwerkstack von <code>ipfs</code> im Detail<a href="#fn91" class="footnoteRef" id="fnref91"><sup>91</sup></a>.</p>
</div>
<p>Im Falle von <code>brig</code> wird ein eigenes Protokoll registriert, um mit anderen Teilnehmern zu kommunizieren. Dieses ist ähnlich aufgebaut wie das Protokoll zwischen Daemon und Client (siehe sec. 5.3.2), unterstützt aber andere Anfragen und hat erhöhte Sicherheitsanforderungen. Eine genauere Beschreibung des Protokolls wird in <span class="citation">[27]</span> gegeben, hier werden nur kurz die wichtigsten Eigenschaften genannt:</p>
<ul>
<li>Authentifizierung mittels Remote–Liste bei jedem Verbindungsaufbau.</li>
<li>Anfragen und Antworten werden als Protobuf–Nachricht enkodiert. Die eigentliche Protokolldefinition kann in sec. 11.2 eingesehen werden.</li>
<li>Kompression der gesendeten Nachrichten mittels Snappy.</li>
<li>Zusätzliche Verschlüsselung der Verbindung, mittels eines via <em>Elliptic Curve Diffie Hellman</em> ausgetauschten Schlüssels.</li>
<li>Senden von »Broadcast«–Nachrichten zu allen bekannten, verbundenen Teilnehmern. Es wird keine Antwort auf Broadcast–Nachrichten erwartet. Diese sind daher eher für Status–Updates geeignet.</li>
</ul>
<p>Im momentanen Zustand wird nur eine einzige Anfrage unterstützt. Dies ist die in sec. 5.2.4 beschriebene <code>FETCH</code>–Anfrage. Zukünftig ist die Einführung weiterer Anfragen geplant. Um beispielsweise Echtzeit–Synchronisation zu unterstützen, müssten zwei weitere Nachrichten eingeführt werden:</p>
<ul>
<li><code>UPDATE</code>: Eine Nachricht die aktiv an alle Teilnehmer in der Remote–Liste geschickt wird. Sie enthält einen einzelnen Checkpoint. Die darin beschriebene atomare Änderung sollte dann auf Empfängerseite direkt in den Staging–Bereich eingegliedert werden.</li>
<li><code>DIFF &lt;COMMIT_HASH&gt;:</code> Wie <code>FETCH</code>, gibt aber nur die Änderungen seit dem angegebenen <code>COMMIT_HASH</code> zurück.</li>
</ul>
<h3 id="sec:user-management"><span class="header-section-number">5.4.3</span> Benutzermanagement</h3>
<p>In den Anforderungen in sec. 3 wird eine menschenlesbare Identität gefordert, mit der Kommunikationspartner einfach erkennbar sind. Der von <code>ipfs</code> verwendete Identitätsbezeichner ist allerdings eine für Menschen schwer zu merkende Prüfsumme (die »Peer–ID«).</p>
<p>Es wurden in dieser Arbeit bereits einige Identifikationsbezeichner beispielhaft verwendet. Diese entsprechen einer abgeschwächten Form der Jabber–ID<a href="#fn92" class="footnoteRef" id="fnref92"><sup>92</sup></a> (<em>JID</em>, vgl. auch <span class="citation">[24]</span>, S. 14). Diese hat, ähnlich wie eine E–Mail Adresse, die Form <code>user@domain/resource</code>. Beim Jabber/XMPP Protokoll ist der Teil hinter dem »<code>/</code>« optional, der Rest ist zwingend erforderlich. Als Abschwächung ist bei <code>brig</code> auch der Teil hinter dem »<code>@</code>« optional. Darüber hinaus sollen folgende Regeln gelten:</p>
<ul>
<li>Es sind keine Leerzeichen erlaubt.</li>
<li>Ein leerer String ist nicht valide.</li>
<li>Groß- und Kleinschreibung wird nicht unterschieden. Es wird empfohlen den Namen klein zu schreiben, so wie es bei Mailadressen und URLs der Fall ist.</li>
<li>Der String muss valides UTF8<a href="#fn93" class="footnoteRef" id="fnref93"><sup>93</sup></a> sein.</li>
<li>Der String muss der »UTF-8 Shortest Form<a href="#fn94" class="footnoteRef" id="fnref94"><sup>94</sup></a>« entsprechen</li>
<li>Der String darf durch die »UTF-8 NKFC Normalisierung<a href="#fn95" class="footnoteRef" id="fnref95"><sup>95</sup></a>« nicht verändert werden.</li>
<li>Alle Charaktere müssen druckbar und auf dem Bildschirm darstellbar sein.</li>
</ul>
<p>Insbesondere die letzten vier Punkte dienen der Sicherheit, da ein Angreifer versuchen könnte eine Unicode–Sequenz zu generieren, welche visuell genauso aussieht wie die eines anderen Nutzers, aber einer anderen Byte–Reihenfolge und somit einer anderen Identität entspricht.</p>
<p>Valide Identitätsbezeichner wären also beispielsweise:</p>
<ul>
<li><code>alice</code></li>
<li><code>alice@company</code></li>
<li><code>alice@company.de</code></li>
<li><code>alice@company.de/laptop</code></li>
<li><code>böb@subdomain.company.de/desktop</code></li>
</ul>
<p>Die Wahl der JID als Basis hat einige Vorteile:</p>
<ul>
<li>Eine E–Mail Adresse oder eine JID ist gleichzeitig ein valider Identitätsbezeichner.</li>
<li>Der Nutzer kann eine fast beliebige Unicode Sequenz als Name verwenden, was beispielsweise für Nutzer des kyrillischen Alphabetes nützlich ist.</li>
<li>Unternehmen können die Identifikationsbezeichner hierarchisch gliedern. So kann <em>Alice</em> der Bezeichner <code>alice@security.google.com</code> zugewiesen werden, wenn sie im Sicherheitsteam arbeitet.</li>
<li>Der <em>Ressourcen</em>–Teil hinter dem »<code>/</code>« ermöglicht die Nutzung desselben Nutzernamens auf verschiedenen Geräten, wie beispielsweise <code>desktop</code> oder <code>laptop</code>.</li>
</ul>
<p>Eine Nutzung des <code>domain</code> und <code>resource</code>–Teils ist kein Zwang, wird aber als Konvention empfohlen, da es eine Unterteilung in Gruppen und Geräte ermöglicht.</p>
<p>Um den Identifikationsbezeichner im Netzwerk auffindbar zu machen, wendet <code>brig</code> einen »Trick« an. Jeder <code>brig</code>–Knoten veröffentlicht einen einzelnen <code>blob</code> in das <code>ipfs</code>–Netzwerk mit dem Inhalt <code>brig#user:&lt;username&gt;</code>. Dieses Verfahren wird <em>Publishing</em> genannt. Ein Nutzer, der nun einen solchen menschenlesbaren Namen zu einer Netzwerkadresse auflösen möchte, kann den Inhalt des obigen Datensatzes generieren und daraus eine Prüfsumme bilden. Mit der entstandenen Prüfsumme kann wie in Listing <strong>??</strong> mittels dem folgenden Verfahren<a href="#fn96" class="footnoteRef" id="fnref96"><sup>96</sup></a> herausgefunden werden, welche Knoten diesen Datensatz anbieten:</p>
<div class="sourceCode" id="lst:user-hash"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="va">USER_HASH=$(</span><span class="bu">printf</span> <span class="st">&#39;brig#user:%s&#39;</span> alice  <span class="kw">|</span> <span class="ex">multihash</span> -<span class="va">)</span>
$ <span class="bu">echo</span> <span class="va">$USER_HASH</span>
<span class="ex">QmdNdLHqc1ryoCU5LPEMMCrxkLSafgKuHzpVZ5DFdzZ61M</span>
<span class="co"># Schlage Hash in der Distributed Hash Table nach:</span>
$ <span class="ex">ipfs</span> dht findprovs <span class="va">$USER_HASH</span>
<span class="op">&lt;</span><span class="ex">PEER_ID_OF_POSSIBLE_ALICE_1</span><span class="op">&gt;</span>
<span class="op">&lt;</span><span class="ex">PEER_ID_OF_POSSIBLE_ALICE_2</span><span class="op">&gt;</span>
<span class="ex">...</span></code></pre></div>
<a name="fig:id-resolving"></a>
<div class="figure">
<img src="images/4/id-resolving.png" id="fig:id-resolving" />
<p class="caption">Figure 29: Figure 29. Überprüfung eines Benutzernamens mittels Peer–ID</p>
</div>
<p>Da prinzipiell jeder Knoten sich als <em>Alice</em> ausgeben kann, wird aus den möglichen Peers, derjenige ausgewählt, dessen <code>ipfs</code>–Identitätsbezeichner (bei <code>brig</code> wird dieser als <em>Fingerprint</em> bezeichnet) als vertrauenswürdig eingestuft wurde. Vertrauenswürdig ist er, wenn der Fingerprint in der Remote–Liste in der Kombination von Nutzernamen und Fingerprint auftaucht. In diesem Fall muss der Nutzer explizit authentifiziert worden sein. fig. 29 zeigt dieses Verfahren noch einmal graphisch.</p>
<p>Analog kann das Konzept auch übertragen werden, um bestimmte Gruppen von Nutzern zu finden. Angenommen, Alice, Bob und Charlie arbeiten im gleichen Unternehmen. Das Unternehmen spiegelt sich auch in ihren Identitätsbezeichnern wieder:</p>
<ul>
<li><code>alice@corp.de/server</code></li>
<li><code>bob@corp.de/laptop</code></li>
<li><code>charlie@corp.de/desktop</code></li>
</ul>
<p>Neben den gesamten Nutzernamen, können diese drei Nutzer auch ihren Unternehmensnamen (<code>corp.de</code>) <em>publishen</em>, beziehungsweise auch ihren Nutzernamen ohne den <code>resource</code>–Zusatz. So ist es beispielsweise wie in Listing <strong>??</strong> möglich die öffentlichen Identitäten alle Unternehmensmitglieder aufzulösen:</p>
<div class="sourceCode" id="lst:corp-hash"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="va">CORP_HASH=$(</span><span class="bu">printf</span> <span class="st">&#39;brig#domain:%s&#39;</span> corp.de <span class="kw">|</span> <span class="ex">multihash</span> -<span class="va">)</span>
$ <span class="ex">ipfs</span> dht findprovs <span class="va">$CORP_HASH</span>
<span class="op">&lt;</span><span class="ex">PEER_ID_OF_POSSIBLE_CORP_MEMBER_1</span><span class="op">&gt;</span>
<span class="op">&lt;</span><span class="ex">PEER_ID_OF_POSSIBLE_CORP_MEMBER_2</span><span class="op">&gt;</span>
<span class="ex">...</span></code></pre></div>
<p>Die einzelnen IDs können dann, sofern bekannt, zu den »Klarnamen« aufgelöst werden, die in der Remote–Liste jedes Teilnehmers stehen. Insgesamt können folgende sinnvolle Kombinationen (falls möglich, da optional) von <code>brig</code> <em>published</em> werden, die jeweils eine spezielle Semantik hätten:</p>
<ul>
<li><code>user</code>: Finden des Nutzernamens alleine.</li>
<li>domain: Finden des Gruppennamen.</li>
<li><code>user@domain</code>: Alle Geräte eines Nutzers.</li>
<li><code>user@domain/resource</code>: Spezifisches Gerät eines Nutzers.</li>
</ul>
<p>Das Besondere an dieser Vorgehensweise ist, dass kein Nutzer sich an einer zentralen Stelle registriert. Trotzdem können sich die Nutzer gegenseitig im Netzwerk mit einem aussagekräftigen Namen finden und trauen nicht einer zentralen Instanz, sondern entscheiden selbst welchen Knoten sie trauen. Diese Eigenschaften entsprechen den drei Ecken von <em>Zooko’s Dreieck</em><span class="citation">[33]</span>, von denen gesagt wird, dass immer nur zwei Ecken gleichzeitig erfüllbar sind (siehe fig. 30). Allerdings ist die oben gezeigte Technik als Alternative für Techniken wie <em>DNS</em> kaum einsetzbar und ist daher keine allgemeine Lösung für <em>Zooko’s Dilemma</em>.</p>
<a name="fig:zooko"></a>
<div class="figure">
<img src="images/4/zooko.png" id="fig:zooko" style="width:50.0%" />
<p class="caption">Figure 30: Figure 30. Bildliche Darstellung von Zooko’s Dreieck.</p>
</div>
<p>Aus Sicht der Usability ist dabei die initiale Authentifizierung ein Problem. Diese kann nicht von <code>brig</code> automatisiert erledigt werden, da <code>brig</code> nicht wissen kann welche Prüfsumme die »richtige« ist. Es wird im aktuellen Entwurf vom Nutzer erwartet, dass er über einen sicheren Seitenkanal (beispielsweise durch ein persönliches Treffen) die angepriesene Prüfsumme überprüft.</p>
<p>Die oben vorgestellte Idee kann aber auch in Richtung eines <em>Web of Trust</em><a href="#fn97" class="footnoteRef" id="fnref97"><sup>97</sup></a> erweitert werden. Als Anwendungsfall könnte man eine geschlossene Gruppe von Nutzern betrachten, die sich nur teilweise bekannt sind. Vergrößert sich die Gruppe mit einem neuen Teilnehmer, so muss dieser alle anderen Teilnehmer authentifizieren und gegenseitig auch von diesen authentifiziert werden. Ab einer bestimmten Gruppengröße wird dies eine sehr aufwendige Aufgabe. Eine logische Lösung wäre das Anlegen eines <em>Blessed Repository</em>, dem alle Gruppenteilnehmer trauen und das von einem respektierten Teilnehmer der Gruppe betrieben wird. Möchte man diesen zentralen Ansatz nicht, so kann man wie beim <em>Web of Trust</em>, ein System einführen, das einem neuen Nutzer automatisch traut, wenn eine ausreichende Anzahl anderer Gruppenteilnehmer dem Neuling vertraut hat.</p>
<p>Daneben sind noch weitere Strategien denkbar, wie das automatische Akzeptieren neuer Teilnehmer (anwendbar, wenn beispielsweise ein Dozent Vorlesungsmaterial verteilen will), oder ein Frage–Antwort–Verfahren wie bei <em>Off–The–Record–Messaging (OTR)</em>. Dabei stellen sich beide Teilnehmer eine Frage, die sie jeweils korrekt beantworten müssen. Weitere Konzepte zur Authentifizierung werden in <span class="citation">[27]</span> beschrieben.</p>
<h1 id="sec:implementierung"><span class="header-section-number">6</span> Implementierung</h1>
<p>Dieses Kapitel dokumentiert die Implementierung. Der praktische Status der Implementierung kann in sec. 10 betrachtet werden. Dort werden nur Funktionen gezeigt, die auch tatsächlich schon existieren. An dieser Stelle werden eher Implementierungsdetails gezeigt, die einen Einstieg in die technische Umsetzung von <code>brig</code> geben sollen.</p>
<h2 id="wahl-der-sprache"><span class="header-section-number">6.1</span> Wahl der Sprache</h2>
<p>Als Sprache zur Implementierung wurde die relativ junge Programmiersprache <em>Go</em> ausgewählt. <em>Go</em> ist eine an <em>C</em> angelehnte Sprache, die von Ken Thompson, Rob Pike und Robert Griesemer initiiert wurde und mittlerweile von Google getragen und weiterentwickelt wird (siehe auch <span class="citation">[1]</span>, S. XI ff.). Für dieses spezielle Projekt bietet die Sprache aus Sicht des Autors folgende Vorteile:</p>
<p><strong>Garbage–Collector:</strong> Erleichtert die Entwicklung lang laufender Dienste und erleichtert den Programmierer die Arbeit durch den Wegfall der manuellen Speicherallokation und Bereinigung.</p>
<p><strong>Hohe Grundperformanz:</strong> Zwar erreicht diese nicht die Performanz von C, liegt aber zumindest in der selben Größenordnung (vgl. <span class="citation">[25]</span>, S. 37).</p>
<p><strong>Weitläufige Standardbibliothek:</strong> Es sind wenig externe Bibliotheken nötig. Insbesondere für die Entwicklung von Netzwerk- und Systemdiensten gibt es eine breite Auswahl von gut durchdachten Bibliotheken. Besonders Erwähnenswert ist das umfangreiche Angebot an gut dokumentierten kryptografischen Primitiven, die eine unsichere Benutzung möglichst ausschließen sollen<a href="#fn98" class="footnoteRef" id="fnref98"><sup>98</sup></a>.</p>
<p><strong>Schneller Kompiliervorgang:</strong> Selbst große Anwendungen werden in wenigen Sekunden in eine statisch gelinkte Binärdatei ohne Abhängigkeiten übersetzt. Kleinere bis mittlere Anwendungen können ähnlich wie bei einer Skriptsprache direkt mittels des <code>go run</code> Befehls ausgeführt werden.</p>
<p><strong>Cross–Kompilierung:</strong> Anwendungen können für viele verschiedene Systeme von einem Entwicklungsrechner aus gebaut werden. Da die entstehende Binärdatei statisch gelinkt ist, werden zudem keine weiteren Abhängigkeiten benötigt. Dadurch ist es möglich für verschiedene Systeme bereits gebaute Binärdateien anzubieten.</p>
<p><strong>Eingebauter Scheduler:</strong> Parallele und nebenläufige Anwendungen wie Netzwerkserver sind sehr einfach zu entwickeln ohne für jede Aufgabe einen dedizierten Thread starten zu müssen. Stattdessen wechseln sich viele Koroutinen<span class="citation">[8]</span> (<em>Go-Routinen</em> genannt) auf einer typischerweise geringeren Anzahl von Threads ab. Dadurch entfällt die Implementierung eines expliziten Mainloops und das Starten von Threads per Hand.</p>
<p><strong>Hohe Portabilität:</strong> Die meisten Programme lassen sich ohne Anpassung auf den gängigsten Desktop–Betriebssystemen kompilieren. Die Möglichkeit native Anwendungen für Android und iOS zu entwickeln ist ebenfalls in der Entwicklung<a href="#fn99" class="footnoteRef" id="fnref99"><sup>99</sup></a>.</p>
<p><strong>Große Anzahl mitgelieferter Werkzeuge:</strong> Im Gegensatz zu anderen Sprachen umfasst das <em>Go</em>–Paket nicht nur die Sprache, sondern auch ein Buildsystem, ein Race–Condition–Checker, ein Testrunner, ein Dokumentationsgenerator, ein Static–Code–Checker, eine Formatierungshilfe und eine Art Paketmanager.</p>
<p><strong>Einfache Installation und rapides Prototyping:</strong> Durch das <code>go get</code>–Werkzeug, ist es möglich direkt Bibliotheken und Anwendungen von Plattformen wie <em>GitHub</em> zu installieren. Gleichzeitig ist es einfach eigene Bibliotheken und Anwendungen einzustellen.</p>
<p><strong>Einheitliche Formatierung:</strong> Durch das »<code>go fmt</code>« Werkzeug und strikte Stilrichtlinien<a href="#fn100" class="footnoteRef" id="fnref100"><sup>100</sup></a> sieht jeder <em>Go</em>–Quelltext ähnlich und damit vertraut aus. Dies erleichtert externen Entwicklern den Einstieg.</p>
<p><strong>Geringe Sprachkomplexität:</strong> Die Sprache verzichtet bewusst auf Konstrukte, die die Implementierung des Compilers verlangsamen würden oder das Verständnis des damit produzierten Quelltextes erschweren würde. Daher ist <em>Go</em> eine Sprache, die verglichen mit <em>Python</em> zwar relativ wiederholend und gesprächig ist, aber dadurch gleichzeitig auch sehr einfach zu lesen ist.</p>
<p>Auch <em>Go</em> ist keine perfekte Sprache. Daher werden nachfolgend einige kleinere Nachteile und deren Lösungen im Kontext von <code>brig</code> aufgezählt:</p>
<p><strong>Schwergewichtige Binärdateien:</strong> Da bei <em>Go</em> alles statisch gelinkt wird, ist die entstehende Binärdatei relativ groß. Im Falle des <code>brig</code>–Prototypen sind das momentan etwa 35 Megabyte. Werkzeuge wie <code>upx</code><a href="#fn101" class="footnoteRef" id="fnref101"><sup>101</sup></a> können dies auf rund 8 Megabyte reduzieren, ohne dass der Anwender die Binärdatei selbst entpacken muss.</p>
<p><strong>Vendor:</strong> Der »Paketmanager« von <code>go</code> beherrscht nicht die Installation einer bestimmten Paketversion. Stattdessen wird einfach immer die momentan aktuelle Version installiert. Viele Projekte, <code>brig</code> eingeschlossen, brauchen und bevorzugen aber einen definierten Versionsstand, der von den Entwicklern getestet werden konnte. Dienste wie <em>gopkg.in</em><a href="#fn102" class="footnoteRef" id="fnref102"><sup>102</sup></a> versuchen eine zusätzliche Versionierung anzubieten, der aktuelle »Standard« ist die Nutzung des <code>vendor</code> Verzeichnisses. Diese Lösung läuft darauf hinaus, alle benötigten Abhängigkeiten in der gewünschten Version in das eigene Quelltext–Repository zu kopieren. Diese unelegante, aber gut funktionierende Lösung wird von <code>brig</code> verwendet<a href="#fn103" class="footnoteRef" id="fnref103"><sup>103</sup></a>.</p>
<h2 id="status-der-implementierung"><span class="header-section-number">6.2</span> Status der Implementierung</h2>
<p>Die momentane Implementierung setzt die vorher besprochene Architektur größtenteils um. Der Code der zuständig für die Synchronisierung ist funktioniert zwar, ist jedoch noch nicht so detailliert wie in der Architektur ausgearbeitet. Insbesondere beherrscht er noch nicht die Synchronisation leerer Verzeichnisse und kann kompatibel Änderungen nur sehr bedingt auflösen. Ansonsten unterscheidet sich die tatsächliche Implementierung und die theoretische Architektur nur in Details.</p>
<h3 id="umfang"><span class="header-section-number">6.2.1</span> Umfang</h3>
<p>Die Statistik in tbl. <strong>??</strong> wurde mit dem freien Werkzeug <code>cloc</code><a href="#fn104" class="footnoteRef" id="fnref104"><sup>104</sup></a> erstellt. Autogenerierte Dateien wurden dabei nicht mit eingerechnet, Testdateien hingegen schon. Auch fehlen in der Statistik die Module aus sec. 6.5, die zwar geschrieben worden sind, aber aufgrund sich ändernder Designanforderungen wieder gelöscht worden sind. Es wurde versucht, die Quelltextbasis möglichst klein zu halten.</p>
<a name="tbl:cloc-output"></a>
<table>
<caption>Table 4. Quelltextumfang, gestaffelt nach Sprache.</caption>
<thead>
<tr class="header">
<th><strong>Sprache</strong></th>
<th><strong>Dateianzahl</strong></th>
<th><strong>Leerzeilen</strong></th>
<th><strong>Kommentare</strong></th>
<th><strong>Codezeilen</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>Go</em></td>
<td>86</td>
<td>2944</td>
<td>1700</td>
<td>11427</td>
</tr>
<tr class="even">
<td><em>Go Tests</em></td>
<td>28</td>
<td>667</td>
<td>335</td>
<td>2890</td>
</tr>
<tr class="odd">
<td><em>Protocol Buffers</em></td>
<td>4</td>
<td>95</td>
<td>60</td>
<td>316</td>
</tr>
<tr class="even">
<td><em>Bourne Shell</em></td>
<td>5</td>
<td>11</td>
<td>8</td>
<td>134</td>
</tr>
<tr class="odd">
<td><em>make</em></td>
<td>4</td>
<td>6</td>
<td>1</td>
<td>34</td>
</tr>
<tr class="even">
<td><span class="math inline">∑</span></td>
<td><em>127</em></td>
<td><em>3743</em></td>
<td><em>2104</em></td>
<td><em>14801</em></td>
</tr>
</tbody>
</table>
<h3 id="dokumentation"><span class="header-section-number">6.2.2</span> Dokumentation</h3>
<p>Die Implementierung ist nicht auf ein Paradigma festgelegt. Zwar wird wie bei vielen Projekten hauptsächlich auf <em>objektorientierte Programmierung (OOP)</em> gesetzt, doch erlaubt <em>Go</em> auch die Anwendung prozeduraler und funktionaler Programmiertechniken. Aus diesem Grund macht eine Beschreibung der Implementierung als UML für <code>brig</code> wenig Sinn, da einige Konzepte von dieser Beschreibungssprache nicht ausreichend gut abgebildet werden können. Zudem würde eine Beschreibung aller implementierten Typen schlicht den Rahmen dieser Arbeit sprengen.</p>
<p>Einen guten Überblick über die Implementierung und aller benutzten Typen erlaubt die API–Dokumentation, die unter <em>»godoc.org«</em><a href="#fn105" class="footnoteRef" id="fnref105"><sup>105</sup></a> einsehbar ist. Die Software ist möglichst nahe an der Beschreibung von <em>Effective Go</em> gehalten<a href="#fn106" class="footnoteRef" id="fnref106"><sup>106</sup></a>, was den Einstieg für andere <em>Go</em>–Programmierer erleichtern sollte. Eines der meist genutzten Idiome bildet dabei die strikte Fehlerbehandlung, bei der jede Funktion, die einen Fehler zurückgeben kann, einen zweiten <code>error</code>–Wert zurückgibt. Dieser wird innerhalb der Funktion möglichst früh zurückgeben. So entstehen zwei »vertikale Linien« im optischen Aussehen des Quelltextes. Die eine Linie kümmert sich um die Fehlerbehandlung, die andere um den Erfolgsfall. Listing <strong>??</strong> zeigt ein Beispiel für diese Regel:</p>
<div class="sourceCode" id="lst:two-lines"><pre class="sourceCode go"><code class="sourceCode go"><span class="kw">func</span> someAction(msg <span class="dt">string</span>) (<span class="dt">int</span>, <span class="dt">error</span>) {
    <span class="co">//  | Fehlerbehandlung ist eingerückt.</span>
    <span class="kw">if</span> <span class="bu">len</span>(msg) &lt; <span class="dv">10</span> {
        <span class="kw">return</span> -<span class="dv">1</span>, ErrTooShort
    }<span class="co">// |</span>
     <span class="co">// |</span>
    <span class="kw">if</span> <span class="bu">len</span>(msg) &gt; <span class="dv">20</span> {
        <span class="kw">return</span> -<span class="dv">1</span>, ErrTooLong
    }<span class="co">// |</span>
     <span class="co">// |</span>
    <span class="co">// Erfolgsfall ist nicht eingerückt.</span>
    <span class="kw">return</span> <span class="bu">len</span>(msg) * <span class="bu">len</span>(msg), <span class="ot">nil</span>
}</code></pre></div>
<h3 id="paketübersicht"><span class="header-section-number">6.2.3</span> Paketübersicht</h3>
<a name="fig:package-diagram"></a>
<div class="figure">
<img src="images/5/package-diagram.png" id="fig:package-diagram" />
<p class="caption">Figure 31: Figure 31. Übersicht über alle Pakete in <code>brig</code>.</p>
</div>
<p>fig. 31 zeigt die Aufteilung des Quelltextes in die einzelnen Go–Pakete. Die Software ist dabei in fünf Hauptpakete und drei »umliegende« Pakete aufgeteilt. Die Hauptpakete sind dabei:</p>
<ul>
<li><code>repo</code>: Implementiert das Anlegen, Laden und Schreiben einer Repository–Struktur samt Konfiguration. Dient zudem als oberster Eintrittspunkt in die API von <code>brig</code>, da hier alle wichtigen Instanzen (<code>ipfs</code>–Layer, <em>Stores</em> etc.) vereint sind.</li>
<li><code>store</code>: Implementiert das eigentliche Datenmodell und alle Operationen darauf.</li>
<li><code>daemon</code>: Implementiert die Netzwerkschnittstelle zwischen <code>brigctl</code> und <code>brigd</code>.</li>
<li><code>id</code>: Implementiert das Benutzermanagement, Identitätsvalidierung und die Remote–Liste.</li>
<li><code>transfer</code>: Implementiert den RPC–Mechanismus zwischen zwei <code>brig</code>–Knoten und alle darin aufrufbaren Methoden.</li>
</ul>
<p>Die umliegenden Pakete bestehen aus:</p>
<ul>
<li><code>cmdline</code>: Implementiert die Kommandozeile.</li>
<li><code>fuse</code>: Implementiert die Dateisystemschicht.</li>
<li><code>util</code>: Implementiert allgemein nützliche Funktionen für alle Pakete.</li>
</ul>
<h2 id="ausgewählte-themen"><span class="header-section-number">6.3</span> Ausgewählte Themen</h2>
<p>Aufgrund des großen Umfangs der Implementierung würde eine detaillierte Beschreibung derselben den Rahmen dieser Arbeit sprengen. Stattdessen werden hier einige ausgewählte Stellen der Implementierung näher beleuchtet. Besonderer Wert wird dabei auf Details gelegt, die in der Besprechung der Architektur noch nicht vorkamen.</p>
<h3 id="aufbau-des-store"><span class="header-section-number">6.3.1</span> Aufbau des <em>Store</em></h3>
<p>Der <em>Store</em> kapselt alle Knoten des MDAG und implementiert die Operationen auf diesen Knoten. Die besondere Schwierigkeit bei der Implementierung ist dabei, dass jede Modifikation des Stores serialisiert werden muss, damit sie nach einem Neustart oder Absturz von <code>brigd</code> noch weiterhin vorhanden ist. Für diesen Zweck setzt <code>brig</code> eine eingebettete<a href="#fn107" class="footnoteRef" id="fnref107"><sup>107</sup></a> Key–Value–Datenbank namens <em>BoltDB</em><a href="#fn108" class="footnoteRef" id="fnref108"><sup>108</sup></a> ein.</p>
<p>BoltDB verfolgt ein sehr minimales Konzept, indem keine besonderen Datentypen unterstützt werden. Alle Schlüssel und Werte sind ausschließlich Binärdaten, um deren Serialisierung sich der Programmierer zu kümmern hat. Im Falle von <code>brig</code> wird jeder Knoten als Protobuf–Nachricht in der Datenbank gespeichert und wieder ausgelesen. Die Verschachtlung von Daten wird durch sogenannte <em>Buckets</em> (dt. Eimer) unterstützt. Jeder Schlüssel kann einen Bucket enthalten, der wiederum weitere Buckets und normale Schlüsselwertpaare enthalten kann. Dadurch ist die Bildung einer Hierarchie möglich.</p>
<p>Für jeden Knotentypen (File, Directory, Commit) und Metadatentypen (Checkpoint, Ref) wurde eine eigene, gleichnamige Go–Struktur eingeführt, welche die Daten in der Datenbank kapselt und alle Operationen darauf implementiert. Jede dieser Knotenstrukturen implementiert dabei ein gemeinsames Interface namens <code>Node</code>. Jedes <code>Node</code> weiß wie ein Knoten serialisiert und deserialisiert wird. Zudem fasst das Interface Metadaten zusammen, die für alle Knotentypen gleich sind (also Prüfsumme, Elternpfad, eigener Name, Größe, Änderungszeitpunkt und UID). Ein Verzeichnis speichert dabei allerdings nicht seine Kindknoten (siehe Listing <strong>??</strong>) als weitere Verzeichnisstrukturen, sondern verweist auf diese indirekt über deren Prüfsumme:</p>
<div class="sourceCode" id="lst:hash-ref"><pre class="sourceCode go"><code class="sourceCode go"><span class="kw">type</span> Directory {
    <span class="co">// Keine direkten Links: children []*Directory</span>
    <span class="co">// Stattdessen Referenzierung über Prüfsumme:</span>
    children []*Hash

    <span class="co">// Nutze &#39;fs&#39; als Auflöser für diese Prüfsummen.</span>
    fs *FS
}</code></pre></div>
<p>Würde man die Kindknoten direkt laden, so müsste beim Laden des <code>HEAD</code>–Commit der <em>gesamte</em> Graph geladen werden, da <code>HEAD</code> wiederum auf ein Wurzelverzeichnis und sein Vorgänger–Commit verweist. Es muss nun allerdings eine zentrale Instanz geben, die einen Knoten basierend auf dessen Prüfsumme auflösen kann. Diese zentrale Instanz heißt bei <code>brig</code> <em>FS</em> (kurz für <em>Filesystem</em>, dt. Dateisystem), da ihre Funktionalität dem Kern eines Dateisystems ähnelt. Genau wie ein Dateisystem organisiert <em>FS</em> den Inhalt der <em>BoltDB</em> und macht ihn über Pfade und Prüfsummen höheren Programmebenen zugreifbar. Um diese Aufgabe zu lösen, forciert <em>FS</em> eine hierarchische Ablagestruktur (gezeigt in fig. 32) innerhalb der BoltDB, die an <code>git</code> angelehnt ist.</p>
<a name="fig:bolt-layout"></a>
<div class="figure">
<img src="images/5/bolt-layout.png" id="fig:bolt-layout" />
<p class="caption">Figure 32: Figure 32. Hierarchische Aufteilung in der BoltDB mittels Buckets.</p>
</div>
<p>Basierend auf dieser Struktur kann <em>FS</em> die folgenden Funktionen effizient implementieren:</p>
<p><strong>func</strong> <code class="sourceCode go">NodeByHash(hash *Hash) (Node, <span class="dt">error</span>)</code>: Lädt die Metadaten eines Knoten anhand seiner Prüfsumme. Dabei wird zuerst in »<code>stage/objects/&lt;NODE_HASH&gt;</code>« nachgesehen und dann in »<code>objects/&lt;NODE_HASH&gt;</code>« falls der erste Schlüssel nicht existiert.</p>
<p><strong>func</strong> <code class="sourceCode go">ResolveNode(nodePath <span class="dt">string</span>) (Node, <span class="dt">error</span>)</code>: Löst einen Pfad zu einem <code>Node</code> auf. Es wird probiert die Prüfsumme des Knotens »<code>stage/tree/&lt;PFAD&gt;</code>« beziehungsweise »<code>tree/&lt;PFAD&gt;</code>« nachzuschlagen. Falls das Nachschlagen erfolgreich war, wird <code>NodeByHash()</code> mit der so ermittelten Prüfsumme aufgerufen. Im Falle von Verzeichnissen wird dem Pfad vorher ein ».« angehängt. Das ist nötig, da sonst der Bucket zu dem Verzeichnisinhalten (»<code>/photos/</code>«) gefunden werden würde und nicht das Verzeichnis an sich (»<code>/photos/.</code>«). Letztere Idee stammt dabei aus dem normalen Unix–Dateisystem, wo ein einzelner Punkt ebenfalls auf das aktuelle Verzeichnis zeigt. Es gibt allerdings noch kein Äquivalent zu »<code>..</code>«, welches auf das Elternverzeichnis zeigen würde.</p>
<p><strong>func</strong> <code class="sourceCode go">StageNode(node Node) <span class="dt">error</span></code>: Fügt dem Staging–Bereich einem Eintrag hinzu. Der Pfad des Knoten und seine Prüfsumme werden unter »<code>stage/...</code>« abgespeichert. Dabei sorgt die Funktion auch dafür, dass alle Elternverzeichnisse des Knotens im Staging–Bereich abgespeichert werden, da auch dessen Prüfsummen sich nach einer Modifikation von <code>node</code> verändert haben.</p>
<p><strong>func</strong> <code class="sourceCode go">StageCheckpoint(ckp *Checkpoint) <span class="dt">error</span></code>: Fügt einen Checkpoint dem Staging–Commit unter <code>stage/STATUS</code> hinzu und speichert ihn in »<code>checkpoints/&lt;UID&gt;/&lt;LAST_IDX&gt; + 1</code>« ab.</p>
<p><strong>func</strong> <code class="sourceCode go">MakeCommit(author id.Peer, message <span class="dt">string</span>) <span class="dt">error</span></code>: Kopiert das Wurzelverzeichnis des Staging–Commits und all seine Kinder in das Archiv (<code>objects/</code> und <code>tree/</code>). Der bisherige Staging–Commit wird der neue <code>HEAD</code> und ein neuer, leerer Staging–Commit wird angelegt, auf den <code>CURR</code> zeigt. Der Rest des Staging–Bereichs wird geleert.</p>
<p><strong>func</strong> <code class="sourceCode go">ResolveRef(refname <span class="dt">string</span>) (Node, <span class="dt">error</span>)</code>: Schlägt die Prüfsumme unter »<code>refs/&lt;refname&gt;</code>« nach und übergibt diese <code>NodeByHash()</code>.</p>
<p><strong>func</strong> <code class="sourceCode go">SaveRef(refname <span class="dt">string</span>, nd Node) <span class="dt">error</span></code>: Setzt den Wert unter »<code>refs/&lt;refname&gt;</code>« auf die Prüfsumme des übergebenen Knoten.</p>
<p><strong>func</strong> <code class="sourceCode go">History(uid <span class="dt">uint64</span>) (History, <span class="dt">error</span>)</code>: Lädt alle Checkpoints für ein bestimmtes Dokument anhand der UID des Dokuments. Für jeden neu angelegten Knoten wird eine neue UID generiert, indem die in »<code>stats/node-count</code>« abgespeicherte Ganzzahl um eins inkrementiert wird.</p>
<p><strong>func</strong> <code class="sourceCode go">LookupNode(repoPath <span class="dt">string</span>) (Node, <span class="dt">error</span>)</code>: Löst das Wurzelverzeichnis des Staging–Commits auf und versucht mittels des übergebenen Pfades von dort auf das angeforderte Kind zu kommen, indem die Kinder eines Verzeichnisses mit <code>NodeByHash()</code> nachgeladen werden. Diese Funktion unterscheidet sich von <code>ResolveNode()</code> dadurch, dass gelöschte Pfade berücksichtigt werden. <code>ResolveNode()</code> gibt hingegen den letzten Stand eines Knoten zurück, der an dieser Stelle gespeichert war.</p>
<p><strong>func</strong> <code class="sourceCode go">MetadataPut(key <span class="dt">string</span>, value []<span class="dt">byte</span>) <span class="dt">error</span></code>: Erlaubt das Setzen bestimmter Schlüssel–Wert–Paare unterhalb des <code>metadata</code>–Bucket. Aufrufender Code kann dies nutzen, um spezielle Werte persistent zu hinterlegen.</p>
<p><strong>func</strong> <code class="sourceCode go">MetadataGet(key <span class="dt">string</span>) ([]<span class="dt">byte</span>, <span class="dt">error</span>)</code>: Holt den Wert unter »<code>metadata/&lt;key&gt;</code>« aus der BoltDB.</p>
<p>Bei jeder Operation werden also die Daten direkt aus <em>BoltDB</em> geladen, deserialisiert und zu einer <code>Node</code>–Struktur umgewandelt. Als Effizienzsteigerung werden bereits aufgelöste Prüfsummen in ein assoziatives Array und bereits aufgelöste Pfade in einem Patricia–Trie<a href="#fn109" class="footnoteRef" id="fnref109"><sup>109</sup></a> gespeichert. Sobald eine Reihe von Änderungen an einem im Speicher befindlichen <code>Node</code> gemacht wurde (beispielsweise eine Änderung der Prüfsumme nach einer Modifikation), wird der <code>Node</code>, und all seine Eltern (da dessen Prüfsummen sich ja auch geändert haben), in den Staging–Bereich eingefügt (durch Aufruf von <code>StageNode()</code>). Der »<code>stage/...</code>« Bereich fungiert also als persistentes Sammelbecken für alle Änderungen, während die Änderungen im Speicher den jeweils aktuellsten Stand wiederspiegeln.</p>
<p>Jede weitere Operation auf den Stores läuft auf eine Sequenz von Aufrufen der oben gezeigten Operationen hinaus. Beim Anzeigen aller Commits (<code>Log()</code>) wird beispielsweise die Referenz <code>HEAD</code> aufgelöst (mittels <code>ResolveRef()</code>). Dessen Eltern–Commit wird dann rekursiv aufgelöst (mittels <code>NodeByHash()</code>), bis kein weiterer Eltern–Commit gefunden werden konnte. Die so gefundenen Commits werden dann von <code>Log()</code> in einem Array zurückgegeben.</p>
<p>Beim Abspeichern in der Datenbank wird der sich im Speicher befindliche <code>Node</code> wieder in eine Protobuf–Nachricht übertragen (siehe Listing <strong>??</strong>). Diese fasst für alle Knotentypen gemeinsame Attribute zusammen:</p>
<div class="sourceCode" id="lst:node-proto"><pre class="sourceCode c"><code class="sourceCode c">message Node {
  required NodeType type = <span class="dv">1</span>;     <span class="co">// Knotentyp (Enumeration)</span>
  required uint64 ID = <span class="dv">2</span>;         <span class="co">// UID des Knoten.</span>
  required uint64 node_size = <span class="dv">3</span>;  <span class="co">// Größe in Byte.</span>
  required bytes mod_time = <span class="dv">4</span>;    <span class="co">// Letzte änderung als RFC 3339 Timestamp.</span>
  required bytes hash = <span class="dv">5</span>;        <span class="co">// Prüfsumme.</span>
  required string basename = <span class="dv">6</span>;   <span class="co">// Basename der Datei.</span>
  required string dirname = <span class="dv">7</span>;    <span class="co">// Verzeichnis in dem die Datei liegt.</span>

  <span class="co">// Unternachrichten für die eigentlichen Knoten:</span>
  optional File file = <span class="dv">8</span>;
  optional Directory directory = <span class="dv">9</span>;
  optional Commit commit = <span class="dv">10</span>;
}</code></pre></div>
<h3 id="fusedateisystem"><span class="header-section-number">6.3.2</span> FUSE–Dateisystem</h3>
<p><em>Filesystem in Userspace</em> (kurz <em>FUSE</em><a href="#fn110" class="footnoteRef" id="fnref110"><sup>110</sup></a>) ist eine Technik, die es ermöglicht einen Ordner anzuzeigen, in dem von einem Programm (dem <em>Userspace–Treiber</em>) generierte Dateien angezeigt werden. Technisch basiert es darauf, dass ein Programm die spezielle Blockdatei <code>/dev/fuse</code> öffnet und mithilfe dieser mit dem Kernel kommuniziert. Die API, die dabei implementiert werden muss ist relativ umfangreich weswegen sich ein Wrapper anbietet, der eine »saubere« API für die jeweilige Sprache anbietet. Für <em>Go</em> gibt es mit <code>bazil/fuse</code><a href="#fn111" class="footnoteRef" id="fnref111"><sup>111</sup></a> eine sehr gute, entsprechende Bibliothek.</p>
<p>Die API basiert dabei auf Callbacks. Werden bestimmte Aktionen vom Nutzer getriggert (Beispiel: Er öffnet eine Datei), so wird im FUSE–Layer von <code>brig</code> eine entsprechende Funktion namens <code>Open()</code> aufgerufen. Dieser wird immer ein <em>Request-</em> sowie ein <em>Response–Objekt</em> mitgegeben. Die Aufgabe der aufgerufenen Funktion ist das Auslesen der Details aus dem <em>Request–Objekt</em> (Beispiel: In welchem Modus soll die Datei geöffnet werden?), das Ausführen einer Aktion (Beispiel: Öffne Datenstrom von <code>ipfs</code>) und das Befüllen des <em>Response–Objekts</em> (Beispiel: Kein Fehler, neuer Dateideskriptor wird zurückgegeben). Bei Fehlern kann verfrüht abgebrochen werden und ein spezieller Fehlercode wird zurückgegeben (Beispiel: <code>fuse.EIO</code> für einen Input/Output–Fehler). Auf diese Weise können die meisten Systemaufrufe<a href="#fn112" class="footnoteRef" id="fnref112"><sup>112</sup></a> (die normal vom Kernel vorgegeben sind) durch eigenen Code implementiert werden. Beispielsweise wird auch ein Callback aufgerufen, wenn das Kind eines Verzeichnisses nachgeschlagen werden muss.</p>
<p>Die meisten Operationen wie <code>mkdir()</code>, <code>create()</code>, <code>rename()</code> und <code>remove()</code> haben in der API des Store eine natürliche Entsprechung und sind entsprechend einfach zu implementieren. Schwieriger ist das Auslesen und vor allem die Modifikation von Dateiströmen. Die Sprache <em>Go</em> bietet mit dem Konzept von <code>io.Reader</code> und <code>io.Writer</code> ein sehr leicht wiederverwendbares Pattern, mit dem sich komplexe Dateistromverarbeitungen für den Nutzer transparent erledigen lassen, indem mehrere <code>io.Reader</code> ineinander verschachtelt werden. fig. 33 zeigt auf der linken Seite alle nötigen <code>io.Reader</code>, um dem Nutzer des FUSE–Dateisystems den Inhalt einer Datei zu liefern.</p>
<p>FUSE fordert dabei Daten blockweise an. Das bedeutet, dass ein Funktionsaufruf einen Block nach einem bestimmten Offset in der Datei zurückliefert. Da der Nutzer des Dateisystems frei darin ist, beliebig oft <code>Seek(&lt;offset&gt;)</code> auf einen Dateideskriptor aufzurufen, kann die Reihenfolge dieser Leseoperationen beliebig sein. Hier erklärt sich auch der Grund warum das Verschlüsselungs- und Kompressionformat- auf effizienten wahlfreien Zugriff Wert legt. Wird ein Block angefragt, so muss er also erst von <code>ipfs</code> beschafft werden, dann entschlüsselt, dann dekomprimiert und dann mit eventuellen Modifikationen vereint werden.</p>
<a name="fig:io-stack"></a>
<div class="figure">
<img src="images/5/io-stack.png" id="fig:io-stack" />
<p class="caption">Figure 33: Figure 33. Alle io.Reader und io.Writer auf einen Blick.</p>
</div>
<p>Wird eine Datei schreibbar geöffnet, müssen zusätzlich die gemachten Änderungen zurück geschrieben werden. Problematisch ist dabei, dass im Moment nur die gesamte Datei neu zu <code>ipfs</code> hinzugefügt werden kann. Würde das bei jedem Aufruf der <code>Write()</code>–Funktion im FUSE–Layer geschehen, wäre das spätestens bei großen Dateien sehr ineffizient. Als Kompromisslösung wird jeder geschriebene Block samt seinen Offset im Hauptspeicher zwischengelagert. Erst beim Aufruf von <code>Close()</code> (Schließen des Dateideskriptors) oder <code>Flush()</code> (explizites Herausschreiben aller zwischengelagerten Daten) werden die gespeicherten Blöcke mit dem darunterliegenden Datenstrom wie in fig. 34 kombiniert. Die kombinierte Version wird dann wieder komprimiert, verschlüsselt und <code>ipfs</code> übergeben. Die Implementierung ist etwas trickreich, da durch eine Modifikation auch der darunterliegende Datenstrom verlängert (durch mehrere <code>Write()</code>–Aufrufe am Ende) oder verkürzt werden kann (durch ein <code>Truncate()</code>).</p>
<p>Nachteilig an dieser Vorgehensweise ist vor allem, dass der Hauptspeicher sehr schnell überlaufen kann, wenn eine große Datei komplett neu geschrieben wird. Zukünftige Implementierungen sollten hier einzelne Blöcke auf die Festplatte auslagern können oder <code>ipfs</code> so erweitern, dass individuelle Blöcke direkt zurückgeschrieben werden können. Letzteres war im Rahmen dieser Arbeit zu zeitintensiv, um akkurat implementiert zu werden.</p>
<a name="fig:writer-overlay"></a>
<div class="figure">
<img src="images/5/write-overlay.png" id="fig:writer-overlay" />
<p class="caption">Figure 34: Figure 34. Funktionsweise eines beschreibbaren Overlays.</p>
</div>
<h3 id="repository-struktur"><span class="header-section-number">6.3.3</span> Repository Struktur</h3>
<a name="fig:brig-repo-tree"></a>
<div class="figure">
<img src="images/5/brig-repo-layout.png" id="fig:brig-repo-tree" style="width:60.0%" />
<p class="caption">Figure 35: Figure 35. <code>tree</code>–Ausgabe auf das Verzeichnis des Repositories.</p>
</div>
<p>fig. 35 zeigt den Aufbau eines Repositories auf der Festplatte, kurz nach dem Anlegen wenn <code>brigd</code> noch nicht läuft. Alle Daten sind nicht direkt im Repository hinterlegt, sondern liegen in einem Unterordner namens »<code>.brig</code>«. Ursprünglich sollte das FUSE–Dateisystem über das (größtenteils) leere Verzeichnis gelegt werden, um es wie einen normalen Ordner aussehen zu lassen. Das ist technisch möglich, wenn vor dem Erstellen des FUSE–Dateisystems ein offener Dateideskriptor auf das <code>.brig</code>–Verzeichnis vorhanden ist. Leider unterstützt <code>ipfs</code> dies nicht und stürzt beim versuchten Zugriff auf seine Datenbank ab.</p>
<p>Nach dem Anlegen eines Repositories sind einige Dateien noch verschlüsselt (Endung mit <code>.locked</code>). Erst durch Eingabe des Passworts beim Starten von <code>brigd</code> werden diese Dateien entschlüsselt. Der Schlüssel wird dabei vom Passwort mit der Schlüsselableitungsfunktion <code>scrypt</code><span class="citation">[22]</span> generiert. Das Verschlüsselungsformat entspricht dabei dem in sec. 5.4.1.1 beschriebenen Verfahren.</p>
<p>Ansonsten haben die Dateien folgenden Inhalt:</p>
<ul>
<li><code>config:</code> Enthält die Konfiguration des <code>brig</code>–Repositories.</li>
<li><code>remotes.yml.locked</code>: Enthält für jedes bekannte Remote seine Prüfsumme und einen Zeitstempel, wann dieser zuletzt online war.</li>
<li><code>index/</code>: Enthält für jeden Benutzer eine BoltDB mit seinen Metadaten.</li>
<li><code>ipfs/</code>: Ein <code>ipfs</code>–Repository. Hier werden die eigentlichen Daten gespeichert. Die Struktur des Verzeichnisses selbst wird von <code>ipfs</code> bestimmt.</li>
<li><code>shadow</code>: Enthält die Prüfsumme der vom Nutzer angegebenen Passphrase. Wird zum Abgleich der Passphrase beim Öffnen des Repositories genutzt.</li>
<li><code>master.key</code>: Noch keine Verwendung. Wird zufällig beim Anlegen eines Repositories generiert. Soll als Basis einer Schlüsselhierarchie dienen (vgl. <span class="citation">[27]</span>).</li>
</ul>
<h3 id="nennenswerte-bibliotheken"><span class="header-section-number">6.3.4</span> Nennenswerte Bibliotheken</h3>
<p>Einige Bibliotheken haben bei der Entwicklung von <code>brig</code> sehr geholfen. Bei der Auswahl wurde auf drei Kriterien geachtet:</p>
<ul>
<li>Lizenz der Bibliothek muss mit der APGLv3–Lizenz von <code>brig</code> kompatibel sein.</li>
<li>Die Bibliothek sollte plattformübergreifend funktionieren.</li>
<li>Die Bibliothek sollte möglichst rein in <em>Go</em> geschrieben sein. Dies vereinfacht die Installation, da neben <em>Go</em> keine weiteren Abhängigkeiten installiert werden müssen.</li>
</ul>
<p>Nennenswert sind dabei folgende Bibliotheken, die sich alle auf <em>GitHub</em> befinden. In Klammern wird jeweils die Lizenz der Bibliothek mit angegeben:</p>
<ul>
<li><code>urfave/cli:</code> Umfangreiche Bibliothek um Kommandozeilen zu parsen. (<em>MIT</em>)</li>
<li><code>golang/snappy:</code> Go–Implementierung des Snappy–Kompressionsalgorithmus. (<em>BSD–3–Clause</em>)</li>
<li><code>bkaradzic/go-lz4:</code> Go–Implementierung des LZ4–Kompressionsalgorithmus. (<em>BSD–3–Clause</em>)</li>
<li><code>dustin/go-humanize:</code> Enthält nützliche Konvertierungsfunktionen, um beispielsweise Bytes in eine passende, menschenlesbare Form zu formatieren. (<em>MIT</em>)</li>
<li><code>jbenet/go-multihash:</code> Implementiert die Enkodierung und Dekodierung des <em>Multihash</em>–Format. (<em>MIT</em>)</li>
<li><code>VividCortex/godaemon:</code> Wird benutzt, um den Pfad zur eigenen ausführbaren Datei plattformübergreifend zu finden. (<em>MIT</em>)</li>
<li><code>gogo/protobuf/proto:</code> Optimierte Version des Original–Protobuf–Compilers. (<em>BSD–3–Clause</em>)</li>
<li><code>codahale/chacha20poly1305:</code> Nutzt die Streaming–Cipher <em>ChaCha20</em> und die MAC <em>Poly1305</em>, um authentifizierte Verschlüsselung umzusetzen. (Siehe auch: <span class="citation">[20]</span>, <em>MIT</em>).</li>
<li><code>chzyer/readline:</code> Komfortable Eingabe von Text auf dem Terminal. (<em>MIT</em>)</li>
<li><code>nbutton23/zxcvbn-go:</code> Prüft eine Passphrase auf ihre Entropie. (<em>MIT</em>)</li>
</ul>
<h3 id="sonstiges"><span class="header-section-number">6.3.5</span> Sonstiges</h3>
<p><strong>Logging:</strong> <code>brigd</code> nutzt eine farbige Log–Ausgabe und Unicode–Glyphen, um dem Entwickler das Erkennen von verschiedenen Log–Leveln zu erleichtern (siehe fig. 36). Farbig ist die Ausgabe nur, wenn <code>brigd</code> im Vordergrund läuft und auf <code>stdout</code> ausgibt. Läuft der Daemon im Hintergrund, werden die Log–Ausgaben in eine Datei geschrieben und die Farbinformationen weggelassen.</p>
<a name="fig:log-levels"></a>
<div class="figure">
<img src="images/5/log-levels.png" alt="Figure 36: Figure 36. Beispielhafte Ausgabe mit allen verfügbaren Log–Leveln" id="fig:log-levels" style="width:75.0%" />
<p class="caption">Figure 36: Figure 36. Beispielhafte Ausgabe mit allen verfügbaren Log–Leveln</p>
</div>
<p><strong>Konfiguration:</strong> Einige Parameter von <code>brig</code> sind konfigurierbar. Diese werden in einer menschenlesbaren YAML–Datei<a href="#fn113" class="footnoteRef" id="fnref113"><sup>113</sup></a> gespeichert. Der Zugriff auf einen Wert erfolgt dabei durch einen mit ».« getrennten Pfad. So liefert der Schlüssel »<code>daemon.port</code>« dem Schlüssel »<code>port</code>« in dem assoziativen Array »<code>daemon</code>« (siehe Beispiel Listing <strong>??</strong>).</p>
<div class="sourceCode" id="lst:local-config"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="fu">daemon:</span>
  <span class="fu">port:</span> 6666                       <span class="co"># Port von brigd.</span>
<span class="fu">ipfs:</span>
  <span class="fu">path:</span> /tmp/alice/.brig/ipfs      <span class="co"># Pfad zum Repository.</span>
  <span class="fu">swarmport:</span> 4001                  <span class="co"># Port von ipfs.</span>
<span class="fu">repository:</span>
  <span class="fu">id:</span> alice@wonderland.lit/laptop  <span class="co"># Nutzername.</span></code></pre></div>
<p><strong>Global–Config:</strong> Es ist möglich, mehrere <code>brig</code>–Repositories auf einem Rechner parallel laufen zu lassen. Dabei ist allerdings darauf zu achten, dass <code>brigd</code> zwei Ports pro laufender Instanz benötigt (4001 für <code>ipfs</code> und 6666 für <code>brigd</code> selbst). Deshalb hinterlegt jedes angelegte Repository in der sogenannten <em>Global Config</em> einen Eintrag, welche Ports es nutzt. Neu angelegte Repositories konsultieren die <em>Global Config</em>, um automatisch eine vernünftige Portkonfiguration zu erhalten. Die Konfiguration ist wie die lokale Konfiguration eine YAML–Datei und befindet sich im Home–Verzeichnis des Nutzers unter <code>.brig-config/</code>. Listing <strong>??</strong> zeigt ein Beispiel mit zwei unterschiedlichen Repositories. Die <em>Global Config</em> ist zudem dazu gedacht, globale Standardwerte für neue Repositories zu definieren (ähnlich wie die globale <code>git config</code>).</p>
<div class="sourceCode" id="lst:global-config"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span class="co"># ~/.brig-config/repos</span>
<span class="fu">repos:</span>
  <span class="kw">-</span> <span class="fu">alice@wonderland.lit/desktop:</span>
      <span class="fu">repopath:</span> /home/alice/.brig
      <span class="fu">daemonport:</span> 6666
      <span class="fu">ipfsport:</span> 4001
  <span class="kw">-</span> <span class="fu">rabbithole@wonderland.lit/desktop:</span>
      <span class="fu">repopath:</span> /var/rabbithole/.brig
      <span class="fu">daemonport:</span> 6667
      <span class="fu">ipfsport:</span> 4002</code></pre></div>
<p><strong>Umgebungsvariablen:</strong> Das Verhalten von <code>brig</code> wird teilweise auch über Umgebungsvariablen gesteuert, sofern diese nicht von der Kommandozeile überschrieben werden. Momentan gibt es drei Variablen, die gesetzt werden können.</p>
<ul>
<li><code>BRIG_PATH:</code> Falls gesetzt, operiert <code>brig</code> auf diesem Verzeichnis anstatt dem aktuellen Arbeitsverzeichnis. Kann dazu genutzt werden, um außerhalb des Repositories zu arbeiten.</li>
<li><code>BRIG_LOG:</code> Schreibt die Logdatei an den Pfad in der Umgebungsvariable.</li>
<li><code>BRIG_PORT:</code> Überschreibt den konfigurierten Port mit der Ganzzahl in der Umgebungsvariable.</li>
</ul>
<h2 id="entwicklungsumgebung"><span class="header-section-number">6.4</span> Entwicklungsumgebung</h2>
<p>Die gesamte Implementierung wurde auf einem herkömmlichen Linux–System mit aktuellen Softwarestand geschrieben und getestet. Als Editor kam »neovim«<a href="#fn114" class="footnoteRef" id="fnref114"><sup>114</sup></a> mit dem »vim-go«–Pluginset zum Einsatz.</p>
<p>Neben der von <em>Go</em> mitgelieferten Toolbox werden für die Verwaltung von <code>brig</code> noch <code>glide</code><a href="#fn115" class="footnoteRef" id="fnref115"><sup>115</sup></a> und <code>gometalinter</code><a href="#fn116" class="footnoteRef" id="fnref116"><sup>116</sup></a> verwendet. Ersteres verwaltet alle Abhängigkeiten von <code>brig</code> und wird genutzt, um sie aktuell zu halten. Letzteres ist ein Programm zur statischen Code–Analyse. Es lässt viele verschiedene in der Go–Welt gebräuchlichen Programme auf den Quelltext laufen und sammelt deren Ergebnisse in einer konsistenten Ausgabe. Die Prüfungen dabei sind vergleichsweise strikt und umfangreich. Beispielsweise werden nicht nur undokumentierte Funktionen gefunden, sondern auch duplizierter Code. Es wurde versucht, ein Großteil der so gefundenen Probleme zu reparieren.</p>
<p>Der gesamte Quelltext wird mit <code>git</code> verwaltet und zu mindestens drei verschiedenen Rechnern synchronisiert. Dazu gehört der bereits genannte GitHub–Account (<a href="https://github.com/disorganizer/brig" class="uri">https://github.com/disorganizer/brig</a>), sowie ein von Herrn Prof. Schöler dankenswerterweise bereitgestelltes GitLab–Repository<a href="#fn117" class="footnoteRef" id="fnref117"><sup>117</sup></a>. Zusätzlich wird der Quelltext noch auf einem privaten Rechner synchronisiert und ist auf den Entwicklerrechnern vorhanden.</p>
<p>Dabei wird sämtlicher Code auf dem <code>master</code>–Branch entwickelt. Nach einem öffentlichen Release sollte der <code>master</code>–Branch stets den aktuellsten, stabilen Stand von <code>brig</code> widerspiegeln, während der <code>develop</code>–Branch alle möglicherweise instabilen Änderungen sammelt. Vom <code>develop</code>–Branch sollten <code>feature/&lt;name&gt;</code> oder <code>bugfix/&lt;name&gt;</code>–Branches abgezweigt werden, in denen unabhängig ein eigenes Feature entwickelt wird. Später werden diese »Feature«–Branches dann wieder mit dem <code>develop</code>–Branch zusammengeführt, welcher ebenfalls vor dem Release einer neuen Version mit dem <code>master</code>–Branch zusammengeführt wird. Jedes Release soll zudem mit einem <em>Tag</em> versehen werden, dessen Name sich nach den Regeln des <em>Semantic Versioning</em><a href="#fn118" class="footnoteRef" id="fnref118"><sup>118</sup></a> richtet.</p>
<p>Bei jedem veröffentlichten Commit auf GitHub werden zudem von der Continous–Integration–Plattform <em>Travis</em> alle Tests automatisch ausgeführt. Bei Fehlern wird man durch eine E–Mail benachrichtigt. Diese Plattform ist für freie Softwareprojekte dankenswerterweise kostenfrei.</p>
<h2 id="sec:dev-history"><span class="header-section-number">6.5</span> Entwicklungshistorie</h2>
<p>Der Beginn der Entwicklung reicht bis in den November des Jahres 2015 zurück. Zu diesem Zeitpunkt war <code>brig</code> konzeptuell noch anders gelagert und es wurde beispielsweise die Verwendung von <code>ssh</code> und <code>rsync</code> als Backend diskutiert. Erst nach der Beschäftigung mit <code>ipfs</code> und seinen Möglichkeiten entstand der Grundgedanke, der hinter dem heutigen <code>brig</code> steht.</p>
<h3 id="sec:sackgasse"><span class="header-section-number">6.5.1</span> Sackgassen bei der Entwicklung</h3>
<p>Leider wurden auch einige Techniken sehr zeitaufwendig ausprobiert und wieder verworfen. Dazu gehört auch der geplante Einsatz von <em>XMPP</em><a href="#fn119" class="footnoteRef" id="fnref119"><sup>119</sup></a> als sicherer Steuerkanal und als Möglichkeit, ein Benutzermanagement zu implementieren. Nach kurzer Recherche stellte sich heraus, dass zum damaligen Zeitpunkt für <em>Go</em> noch keine verwertbaren Bibliotheken existierten. Daher wurde ein eigener XMPP–Client entwickelt, der in Kombination mit <em>Off–the–Record–Messaging (OTR)<a href="#fn120" class="footnoteRef" id="fnref120"><sup>120</sup></a></em> für eine sichere Verbindung zwischen zwei <code>brig</code>–Knoten sorgen sollte. Nach einigem Implementierungsaufwand stellte sich dieser als zu langsam und ineffizient heraus (teilweise Verbindungsaufbau <span class="math inline">&gt;</span> 30 Sekunden)<a href="#fn121" class="footnoteRef" id="fnref121"><sup>121</sup></a>. Zudem handelt es sich bei <em>XMPP</em> um kein gänzlich dezentralisiertes Protokoll, da die meisten Nachrichten über zentrale Server geleitet werden. Von <em>XMPP</em> ist im heutigen Konzept nur das Format des Benutzernamens geblieben, welcher an die JID angelehnt ist.</p>
<p>Als Ersatz für XMPP wurde <em>MQTT</em><a href="#fn122" class="footnoteRef" id="fnref122"><sup>122</sup></a> erwogen. Dabei handelt es sich um ein offenes Machine–to–Machine Nachrichtenprotokoll. Clients registrieren sich bei einem (normalerweise zentralen) Broker auf benannte Kanäle (<em>Topics</em> genannt) und werden benachrichtigt, wenn ein anderer Client eine Nachricht auf einem registrieren Topic veröffentlicht. Die Idee war, jeden <code>brig</code>–Knoten zu einem MQTT–Broker zu machen. Dabei ist jeder Knoten auch ein <em>Client</em>, der auf den <em>Topics</em> des eigenen Brokers und aller anderen, benachbarten Knoten hört. Aus einem zentral aufgebauten Protokoll wurde so ein dezentrales Protokoll gemacht. Und obwohl die Lösung dem ursprünglichen Konzept von <em>MQTT</em> widersprach, hat ein Prototyp zufriedenstellend funktioniert. Nachteilig war aber vor allem die schwierige Absicherung des Datenverkehrs und dass ein zusätzlicher Port für MQTT gebraucht wurde. Als beinahe unlösbar hat sich auch die Notwendigkeit herausgestellt, MQTT über NAT–Grenzen hinweg zu betreiben. Zusammen haben diese »Sackgassen« zwei bis drei Monate Entwicklungszeit verschlungen.</p>
<p>Bevor das in sec. 5 beschriebene Datenmodell eingeführt wurde, wurde sehr lange Zeit ein simpleres Datenmodell genutzt. Dieses existierte alleine im Speicher und wurde zu bestimmten Anlässen in seiner Gesamtheit in die <em>BoltDB</em> geschrieben. Die Basis hat ein Patricia–Trie gebildet, der alle Pfade als Schlüssel und die Metadaten als deren zugeordnete Werte gespeichert hat. Aufgrund von Problemen bei der Erweiterbarkeit in Richtung Versionsverwaltung und Wartung wurde dieses Datenmodell mit dem heutigen ersetzt. In der Anfangszeit der Entwicklung wurde <code>ipfs</code> nicht als Bibliothek genutzt, sondern es wurde direkt das <code>ipfs</code>–Programm als Subprozess für jedes auszuführende Kommando (Beispiel: <code>ipfs add</code>) gestartet. Aufgrund von schlechter Effizienz wurde dieser Ansatz nicht weiter verfolgt.</p>
<p>Als Lehre wurden drei Abstraktionsschichten in <code>brig</code> eingebaut, die die Austauschbarkeit einiger Komponenten erleichtern soll. Diese sind wie folgt:</p>
<ul>
<li>Abstraktionsschicht zwischen <code>brig</code> und <code>ipfs</code>. Jede benötigte <code>ipfs</code>–Funktion erhält eine eigene Funktion im Paket <code>ipfsutil</code>. Sollte sich die Semantik bestimmter Funktionen ändern, so kann dies an zentraler Stelle angepasst werden, auch wenn <code>ipfs</code> selbst bisher nicht sinnvoll zu ersetzen ist.</li>
<li>Abstraktionsschicht zwischen <code>brig</code> und BoltDB. Es wird nicht direkt auf die API von BoltDB zugegriffen. Stattdessen kommt auch hier ein »Wrapper« zum Einsatz, hinter dem auch eine andere Key–Value–Datenbank, der Hauptspeicher oder sogar ein normales Dateisystem stehen können.</li>
<li>Abstraktionsschicht zwischen <code>brig</code> und Transfer–Schicht. Diese wurde zur selben Zeit eingeführt wie das oben genannte MQTT–Experiment. Deshalb konnte MQTT später relativ schnell durch ein eigenes Kommunikationsprotokoll basierend auf <code>ipfs</code> ersetzt werden.</li>
</ul>

<h3 id="beiträge-zu-anderen-projekten"><span class="header-section-number">6.5.2</span> Beiträge zu anderen Projekten</h3>
<p>Im Laufe der Entwicklung wurden einige kleinere Beiträge zu anderen Projekten gemacht. Teilweise auch zu Projekten, die zu diesem Zeitpunkt gar nicht mehr von <code>brig</code> genutzt werden. Diese werden hier der Vollständigkeit halber in umgekehrter chronologischer Reihenfolge aufgelistet:</p>
<ul>
<li><a href="https://github.com/bazil/fuse/pull/152" class="uri">https://github.com/bazil/fuse/pull/152</a>: Option für »<em>AllowNonEmpty</em>« hinzugefügt.</li>
<li><a href="https://github.com/ipfs/go-ipfs/issues/2567" class="uri">https://github.com/ipfs/go-ipfs/issues/2567</a>: Fehler in einer <code>Seek()</code> Funktion von <code>ipfs</code>.</li>
<li><a href="https://github.com/ipfs/go-ipfs-util/pull/1" class="uri">https://github.com/ipfs/go-ipfs-util/pull/1</a>: Konstante für den <em>DefaultHash</em> hinzugefügt.</li>
<li><a href="https://github.com/tang0th/go-ecdh/pull/1" class="uri">https://github.com/tang0th/go-ecdh/pull/1</a>: Änderung kaputter Import–Pfade.</li>
<li><a href="https://github.com/cathalgarvey/go-minilock/issues/8" class="uri">https://github.com/cathalgarvey/go-minilock/issues/8</a>: Crashreport für <em>minilock</em>.</li>
<li><a href="https://github.com/tucnak/climax/pull/3" class="uri">https://github.com/tucnak/climax/pull/3</a>: Gruppierung mehrerer Subkommandos.</li>
<li><a href="https://github.com/chzyer/readline/pull/18" class="uri">https://github.com/chzyer/readline/pull/18</a>: Beispiel für ein zuvor angeregten Passwortprompt hinzugefügt.</li>
<li><a href="https://github.com/ipfs/go-ipfs/pull/1981" class="uri">https://github.com/ipfs/go-ipfs/pull/1981</a>: Erwähnung von <code>IPFS_PATH</code> in der Hilfe.</li>
<li><a href="https://github.com/tsuibin/goxmpp2/pull/1" class="uri">https://github.com/tsuibin/goxmpp2/pull/1</a>: Flexibleres Nachschlagen des SRV–Eintrags.</li>
</ul>
<h1 id="sec:usability"><span class="header-section-number">7</span> Usability</h1>
<p>In diesem Kapitel werden Anforderungen beleuchtet, die <code>brig</code> zu einer für den »Otto–Normal–Nutzer« benutzbaren Software machen soll. Zudem sollen die in Zukunft notwendigen Schritte beschrieben werden, um diese Anforderungen umzusetzen. Dazu gehört unter anderem die Konzeption einer grafischen Oberfläche.</p>
<h2 id="einführung"><span class="header-section-number">7.1</span> Einführung</h2>
<p>Ob eine Bedienoberfläche verständlich ist oder ästhetisch auf den Benutzer wirkt, ist leider sehr subjektiver Natur. Es können nur empirisch Daten gesammelt werden, ob ein gewisser Prozentanteil der Nutzer die Software verständlich und ästhetisch findet. Aus diesem Grund ist der unten gezeigte Vorschlag für eine Bedienoberfläche lediglich ein Konzept unter vielen Möglichkeiten. Der Begriff »Usability« wird dabei gleichbedeutend mit dem deutschen Wort »Gebrauchstauglichkeit« benutzt. Da es aber keine einheitliche Übersetzung des Begriffs gibt, wird der englische Originalbegriff verwendet.</p>
<h2 id="anforderungen-an-die-usability-1"><span class="header-section-number">7.2</span> Anforderungen an die Usability</h2>
<p>Eine besondere Schwierigkeit bei <code>brig</code> ist, dass Sicherheit, Funktionalität und Usability gegeneinander abgewogen werden müssen. Zu viel und zu schnell präsentierte Funktionalität erschwert dem Nutzer den Einstieg in die Software. Zu viele sichtbare Sicherheitsmechanismen schrecken den normalen Nutzer ohne technischen Hintergrund ab. Hingegen werden Nutzer mit technischen Hintergrund tendenziell eher mehr Funktionalität und striktere Sicherheitsmechanismen erwarten.</p>
<p>Es ist daher schwierig, die Anforderung beider Nutzergruppen von einer gemeinsamen Oberfläche erfüllen zu lassen. Deshalb erscheint es sinnvoller mehr als eine Oberfläche anzubieten. Momentan wurde dabei nur zwischen der <em>Kommandozeile</em> (für technisch versierte Nutzer) und einer grafischen Oberfläche, die im Folgenden <code>brig-ui</code> genannt wird, unterschieden.</p>
<p>Für beide Varianten lassen sich trotzdem gemeinsame Anforderungen finden:</p>
<ol style="list-style-type: decimal">
<li>Die Oberfläche muss möglichst immer im Hintergrund bleiben. Nur wenn sie benötigt wird soll der Benutzer sich mir ihr beschäftigen müssen.</li>
<li>Es sollte nur das Minimum an nötigen Informationen angezeigt werden, um den »Cognitive Load« (siehe auch <span class="citation">[21]</span>) des Nutzers zu minimieren.</li>
<li>Die Oberfläche soll einfach installierbar sein. Da Nutzer meist einfach »nur ein Problem« lösen wollen, greifen sie oft zur schnellst möglich installierbaren und damit nutzbaren Variante. Zudem mögen viele Nutzer nicht die Oberfläche, vom eigentlichen, dahinter liegenden Programm unterscheiden können.</li>
<li>Die Oberfläche muss dem Nutzer vertraute Konzepte (Listen, Auswahlmenüs…) und Metaphern (Dateien, Verzeichnisse…) bieten.</li>
<li>Die Oberfläche muss konsistent in ihrer Benutzung sein. Sieht etwas in der Applikation gleich oder ähnlich aus, so muss es auch gleich oder ähnlich funktionieren. Im Umkehrschluss sollen auch konsistent Begriffe wie »Passphrase« statt »Passwort« genutzt werden, um anzuzeigen, dass die Eingabe länger sein soll als ein herkömmliches »Passwort«.</li>
<li>Die Oberfläche muss sich möglichst gut in das System des Benutzers integrieren. Im Falle einer grafischen Oberfläche bedeutet dies die Nutzung einer nativen Desktopapplikation (anstatt einer Webapplikation), die beispielsweise nativ <em>Drag&amp;Drop</em> unterstützt und ein <em>Trayicon</em> anzeigen kann.</li>
<li>Die Oberfläche soll ein möglichst zeitgemäßes Design aufweisen, welches neue Nutzer nicht abschreckt.</li>
<li>Alle verwendeten Texte sollten in die lokale Sprache des Benutzers übersetzt werden.</li>
<li>Die Funktionsweise der Oberfläche soll sich durch Konfiguration an die Bedürfnisse des Benutzers anpassen lassen, aber vernünftige Standardwerte mitbringen.</li>
<li>Die Oberfläche sollte dem Nutzer direkt Feedback geben, ob eine Aktion erfolgreich war. Unwichtige Fehler sollten nach Möglichkeit ignoriert werden, wichtige Fehler sollten Handlungsinstruktionen beinhalten.</li>
</ol>
<p>Diese Anforderungen wurden teilweise von <em>www.usabilitynet.org</em><a href="#fn123" class="footnoteRef" id="fnref123"><sup>123</sup></a> abgeleitet und ergaben sich teilweise nach Betrachtung der existierenden Synchronisationswerkzeuge. Die Liste ist subjektiv und keineswegs komplett. Obwohl beispielsweise <code>syncthing</code> sich als <em>»Easy to use«</em><a href="#fn124" class="footnoteRef" id="fnref124"><sup>124</sup></a> bezeichnet, verletzt es unter anderem die Anforderung <em>2)</em> und präsentiert dem Nutzer in der Hauptansicht die Systemauslastung (siehe fig. 7) und andere Informationen, die in diesem Kontext nicht wichtig sind.</p>
<h2 id="die-kommandozeile"><span class="header-section-number">7.3</span> Die Kommandozeile</h2>
<p>Momentan ist die Kommandozeile <code>brigctl</code> die einzige, implementierte Möglichkeit die gesamte Funktionalität von <code>brig</code> zu nutzen. Die genaue Funktionsweise der Kommandozeile wird in sec. 10 beleuchtet. Beim Design der Optionen und Unterkommandos wurde darauf geachtet, dass <code>git</code>–Nutzern die Benutzung schnell <em>vertraut</em> vorkommt, wo die Konzepte sich ähneln (<code>brig remove/remote</code>). Wo sie sich unterscheiden, wurden bewusst andere Namen gewählt (<code>brig stage</code> statt <code>git add</code> und <code>brig sync</code> statt <code>git pull/push</code>). Das Projekt <code>gitless</code><a href="#fn125" class="footnoteRef" id="fnref125"><sup>125</sup></a> zeigt zudem einige Usability–Verbesserungen an der <code>git</code>–Kommandozeile auf. Einige dieser Ideen könnten für die weitere Entwicklung genutzt werden.</p>
<p>Eine eingebaute Hilfe kann für ein bestimmtes Kommando mit dem Befehl <code>brig help &lt;topic/command&gt;</code> angezeigt werden. Das initiale Anlegen eines Repositories erfordert die Eingabe einer Passphrase mit einer bestimmten Mindestentropie. Wie man in fig. 37 erahnen kann, wird die Entropie »live« bei der Eingabe des Passworts angezeigt, um den Nutzer direkt Feedback zu geben. Momentan wurde die Kommandozeile noch nicht in weitere Sprachen übersetzt, da sie sich genau wie der Rest der Implementierung noch ändern kann. In späteren Versionen könnte zudem ein lokalisiertes Tutorial angeboten werden, welches die wichtigsten Konzepte nach Eingabe von »<code>brig tour</code>« vermittelt.</p>
<a name="fig:pwd-input"></a>
<div class="figure">
<img src="images/6/pwd-input.png" alt="Figure 37: Figure 37. Angabe der Passphrase beim Anlegen eines neuen Repositories." id="fig:pwd-input" style="width:66.0%" />
<p class="caption">Figure 37: Figure 37. Angabe der Passphrase beim Anlegen eines neuen Repositories.</p>
</div>
<p>Eine weitere Verbesserung wäre die Unterstützung von »Shorthashes«. Der Benutzer muss derzeit immer eine volle Prüfsumme angeben (<code>QmSiM3qaUMxCrLiWwVvEeGZTrKUXLD7bULo22WYoGfHwZD</code>), auch wenn meist ein kleiner Präfix (<code>QmSiM3q</code>) davon bereits eindeutig identifizierbar ist. In der Ausgabe von <code>brigctl</code> sollte dann auch möglichst die Präfixvariante bevorzugt werden, um die Ausgabe klein und verständlich zu halten.</p>
<h2 id="grafische-oberfläche"><span class="header-section-number">7.4</span> Grafische Oberfläche</h2>
<p>Für normale Benutzer ist eine grafische Oberfläche unabdingbar. Für die Akzeptanz der Oberfläche ist es wichtig, dass sie dem Benutzer vertraute Konzepte bietet. Daher wird ein großer Teil der Benutzung durch einen normalen Dateisystemordner abgewickelt, der sich kaum von anderen Ordnern unterscheidet. Daher hat die grafische Oberfläche eher die Aufgabe einer Konfigurationsanwendung und eines Einrichtungsassistenten, der nur bei Bedarf aufgerufen wird. Konkret sind die nötigen Aufgabenbereiche wie folgt:</p>
<ul>
<li>Einrichtung und Konfiguration eines neues Repositories.</li>
<li>Oberfläche zur Versionsverwaltung.</li>
<li>Schalter, um zwischen Online- und Offline–Modus zu wechseln.</li>
<li>Hinzufügen und Verwalten von Remotes.</li>
<li>Integrierter Dateibrowser, um Dateien zu verwalten und zu pinnen.</li>
<li>Einstellungen zur Funktionsweise und Sicherheit.</li>
</ul>
<p>Bestehende grafische Oberflächen sind aus Portabilitätsgründen meist web–basiert und fügen sich daher meist nicht optimal in eine Desktopumgebung ein. Daher wurde das nachfolgende Konzept als native Desktopanwendung für den GNOME–Desktop<a href="#fn126" class="footnoteRef" id="fnref126"><sup>126</sup></a> entworfen. Dabei wurde die Oberflächenbibliothek <em>GTK+</em><a href="#fn127" class="footnoteRef" id="fnref127"><sup>127</sup></a> benutzt. Neben den obigen Anforderungen wurde versucht, möglichst alle Regeln der <em>»Gnome Human Interface Guidelines«</em> (GNOME HIG<a href="#fn128" class="footnoteRef" id="fnref128"><sup>128</sup></a>) umzusetzen. Es handelt sich dabei um eine Anleitung des GNOME–Projekts, um den Oberflächenentwurf zu vereinfachen und einheitlich zu gestalten. Offizielle GNOME–Anwendungen müssen diesen Guidelines folgen.</p>
<p><em>GTK+</em> wurde benutzt, weil der Autor sich mit dieser Bibliothek auskennt und bereits eine im Aussehen »ähnliche« Anwendung geschrieben hat, die als Basis für unten stehende Mockups benutzt wurde. Leider bietet <em>GTK+</em> für die Programmiersprache <em>Go</em> noch keine native Unterstützung. Alternativ wäre daher eine Umsetzung, einer Bibliothek wie <em>Gallium</em><a href="#fn129" class="footnoteRef" id="fnref129"><sup>129</sup></a> zu evaluieren. Diese zeigt, vereinfacht gesagt, eine Weboberfläche als Desktopanwendung und integriert auch native Elemente wie ein Trayicon.</p>
<h2 id="mockups-von-brig-ui"><span class="header-section-number">7.5</span> Mockups von <code>brig-ui</code></h2>
<p>In fig. 38 findet sich eine Übersicht über alle Bildschirme der Oberfläche, wobei jeder Bildschirm für eine andere Aufgabe zuständig ist. Jedem Bildschirm gemein ist die sogenannte <em>»Headerbar«</em>, eine etwas breitere Fensterleiste, in der eigene Knöpfe platziert werden können. Auf der linken Seite derselben findet sich ein Schalter, der anzeigt ob man mit dem Netzwerk verbunden ist. Ein Klick auf diesen trennt die Verbindung. Auf der rechten Seite findet sich ein Knopf mit einer Lupe, der die Anwendung in den Suchmodus schaltet. Die Suche ist kontextspezifisch, findet also je nach Bildschirm etwas anderes. Neben dem Suchknopf findet sich ein Knopf mit einem Zahnrad. Bei einem Klick darauf öffnet sich das in fig. 39 gezeigte Menü, von dem aus jeder weitere Bildschirm erreichbar ist. Meist kommt man aber durch das Ausführen bestimmter Aktionen automatisch auf einen anderen Bildschirm, ohne dass man das Menü bemühen muss. Im Folgenden werden die Aufgaben der einzelnen Bildschirme besprochen.</p>
<a name="fig:ui-overview"></a>
<div class="figure">
<img src="images/6/overview.png" id="fig:ui-overview" />
<p class="caption">Figure 38: Figure 38. Übersicht über das GUI–Konzept, bestehend aus fünf Bildschirmen.</p>
</div>
<a name="fig:mockup-menu"></a>
<div class="figure">
<img src="images/6/menu.png" alt="Figure 39: Figure 39. Das Menü hinter dem »Zahnrad«–Knopf." id="fig:mockup-menu" style="width:25.0%" />
<p class="caption">Figure 39: Figure 39. Das Menü hinter dem »Zahnrad«–Knopf.</p>
</div>
<h3 id="anlegen-eines-neuen-repositories"><span class="header-section-number">7.5.1</span> Anlegen eines neuen Repositories</h3>
<a name="fig:mockup-repo"></a>
<div class="figure">
<img src="images/6/view-repo.png" alt="Figure 40: Figure 40. Mockup: Bildschirm zum Anlegen eines Repositories." id="fig:mockup-repo" />
<p class="caption">Figure 40: Figure 40. Mockup: Bildschirm zum Anlegen eines Repositories.</p>
</div>
<p>Dieser Bildschirm taucht beim erstmaligen Starten der grafischen Oberfläche auf, sofern kein vorhandenes <code>brig</code> Repository gefunden werden konnte. Der Bildschirm fragt alle Daten ab, die auch der Befehl »<code>brig init</code>« benötigt. Ein Vorteil der Oberfläche ist dabei, dass dem Nutzer direkt Feedback bei der Eingabe gegeben werden kann. Konkret wird dabei der Nutzername auf formale Korrektheit überprüft und ob bereits ein solcher Name vergeben wurde. Es wird zudem geprüft, ob das Passwort einer bestimmten Mindestentropie entspricht und ob das wiederholte Passwort mit dem ersten übereinstimmt. Dadurch, dass der Nutzer mithilfe der Oberfläche den Anlegeort für das neue Repository auswählt, wird ein fehlerhafter Pfad ausgeschlossen.</p>
<p>In der späteren Entwicklung soll <code>brig</code> auch mit Geräten zur Zweifaktorauthentifizierung (siehe <span class="citation">[27]</span>) wie dem YubiKey<a href="#fn130" class="footnoteRef" id="fnref130"><sup>130</sup></a> zusammenarbeiten. Daher wird am unteren Bildschirmrand eine entsprechende Nachricht angezeigt. Entsprechende Schaltflächen zur Konfiguration werden erst angezeigt, wenn ein angeschlossener YubiKey erkannt wurde.<a href="#fn131" class="footnoteRef" id="fnref131"><sup>131</sup></a></p>
<p>Ein auch im Folgenden häufig verwendetes Designelement ist das Hervorheben einer Aktion als »Empfohlen«. In fig. 40 wird die »Create Repository«–Aktion blau hervorgehoben, um dem Nutzer anzuzeigen, dass dies die naheliegendste Aktion ist, die er vermutlich nehmen wird. Drückt man diese »empfohlene Aktion«, so wird das Repository angelegt und der Hintergrunddienst <code>brigd</code> gestartet. Im Erfolgsfall wird eine Wischanimation zum Remote–Bildschirm hin angezeigt. (siehe sec. 7.5.2).</p>
<h3 id="sec:ui-remotes"><span class="header-section-number">7.5.2</span> Verwalten und Hinzufügen von Remotes</h3>
<a name="fig:mockup-remotes"></a>
<div class="figure">
<img src="images/6/view-remotes.png" alt="Figure 41: Figure 41. Mockup: Verwalten und Hinzufügen von Remotes." id="fig:mockup-remotes" />
<p class="caption">Figure 41: Figure 41. Mockup: Verwalten und Hinzufügen von Remotes.</p>
</div>
<p>In dieser Ansicht kann der Nutzer existierende Remotes verwalten und Neue hinzufügen. Eine Idee, die vom Instant–Messanger <em>Signal</em> übernommen wurde, ist die Einfärbung eines Remotes mit einer bestimmten Farbe. Dies soll dem Nutzer helfen, den Kontakt mit dieser Farbe zu assoziieren und stellt gleichzeitig ein Sicherheitsmechanismus dar, da die Farbe basierend auf der Identitäts–Prüfsumme des Gegenübers gewählt wird. Ändert sich diese, so wird auch eine andere Farbe angezeigt.</p>
<p>Auf der linken Seite des Bildschirms findet sich eine Liste aller bekannten Remotes. Ist die Liste leer, wird dort ein Hinweis angezeigt, dass noch keine Remotes vorhanden sind und man durch die »empfohlene Aktion« unten links ein neues Remote anlegen kann.</p>
<p>Jedes Remote wird durch einen Eintrag in der Liste dargestellt. Das »« oder »« am Anfang indiziert dabei, ob das betreffende Remote online ist. Daneben wird in jedem Eintrag der Name des Remotes und seine Prüfsumme angezeigt. Eventuell wäre hier die alleinige Anzeige des Nutzernamens (<code>Alice</code> statt <code>alice@wonderland.lit/home</code>) benutzerfreundlicher und weniger verwirrend, sofern der Name <code>Alice</code> eindeutig unter den Remotes ist. Auch die Anzeige eines Zeitstempels der letzten Synchronisation wäre denkbar. Zur Rechten jeder Zeile finden sich drei Schaltflächen, die (in dieser Reihenfolge) folgendes bewirken: sofortiges Synchronisieren (Pfeilknopf), Öffnung eines Detailfensters zum entsprechenden Remote und das An- und Ausschalten der automatischen Synchronisation mit diesem Remote. Remotes mit denen automatisch synchronisiert wird, werden mit einem Hintergrund hinterlegt, der kariertem Papier ähnelt. Eine Synchronisation ist nur möglich, wenn <code>brig</code> im Online–Modus ist. Im Suchmodus können die Namen der Remotes zusätzlich durch Angabe eines Stichwortes gefiltert werden.</p>
<p>In der unteren Statusleiste wird zudem in Zahlen zusammengefasst, wie viele Remotes online sind und mit wie vielen Remotes synchronisiert wird. Der Knopf zum Löschen eines Remotes wird nur dann angezeigt, wenn mindestens ein Remote aus der Liste ausgewählt wurde (hellblau hinterlegt).</p>
<p>Die rechte Seite des Bildschirms besteht aus einem segmentierten Kreisdiagramm. Es wird nur angezeigt wenn genau ein Remote ausgewählt ist. Allerdings kann auch die Trennlinie in der Mitte des Bildschirms benutzt werden, um das Diagramm auszublenden, indem es auf die rechte Seite geschoben wird. Das Diagramm selbst zeigt an, welche Teile der synchronisierten Daten das Gegenüber physikalisch bei sich speichert. Die Gesamtmenge wird in der Mitte als Dateigröße gezeichnet. Im Beispiel speichert <code>bob@realworld.org/laptop</code> größtenteils die Dateien aus dem <code>music</code>- und aus dem <code>docs</code>–Ordner. Die Anzeige kann auch durch den Klick auf ein beliebiges Segment verfeinert werden. Dann werden nur noch dieses Segment und seine Untersegmente angezeigt. Ein Klick in die Mitte des Diagramms führt dabei wieder auf die oberste Segmentebene zurück.</p>
<p>Ein gewisses Usability–Problem stellt noch die initiale Authentifizierung dar. Der Dialog, der nach einem Klick auf »<code>Add Remote</code>« erscheint (nicht gezeigt), fragt nur nach den Nutzernamen und der Prüfsumme des Gegenübers. Dies setzt voraus, dass der Nutzer die Prüfsumme kennt, indem beide Teilnehmer sich vorher über einen Seitenkanal ausgetauscht haben. Leider ist der Austausch der Prüfsumme schwierig, da es sich um eine schwer merkbare Zeichenkette handelt. Eine mögliche Lösung für dieses Dilemma wäre die Einführung von QR–Codes (siehe fig. 42), welche die Prüfsumme des Gegenübers visuell enkodieren. Treffen sich beispielsweise zwei Teilnehmer persönlich, so könnten sie ihre Mobiltelefone benutzen, um den QR–Code einzuscannen und zu verifizieren. Auch würde sich der QR–Code eignen, um auf Visitenkarten abgedruckt zu werden.</p>
<a name="fig:qrcode"></a>
<div class="figure">
<img src="images/6/qrcode.png" id="fig:qrcode" style="width:20.0%" />
<p class="caption">Figure 42: Figure 42. Ein typischer QR–Code<a href="#fn132" class="footnoteRef" id="fnref132"><sup>132</sup></a>.</p>
</div>
<h3 id="dateibrowser"><span class="header-section-number">7.5.3</span> Dateibrowser</h3>
<a name="fig:mockup-file-browser"></a>
<div class="figure">
<img src="images/6/view-file-browser.png" alt="Figure 43: Figure 43. Mockup: Bildschirm des Dateibrowsers." id="fig:mockup-file-browser" />
<p class="caption">Figure 43: Figure 43. Mockup: Bildschirm des Dateibrowsers.</p>
</div>
<p>Der Dateibrowser zeigt alle Dateien an, die der jeweilige Synchronisationsteilnehmer verwaltet. Dies entspricht einer grafischen Sicht auf den FUSE–Dateisystemordner. Den Hauptunterschied bilden die zusätzlichen Optionen im Kontextmenü:</p>
<ul>
<li><em>Pin file:</em> Setzt oder entfernt einen Pin für die Datei oder rekursiv für das Verzeichnis.</li>
<li><em>Show History:</em> Wechselt zum Versionsverwaltungsbildschirm und zeigt die Historie der Datei (siehe sec. 7.5.4).</li>
<li><em>Import/Export file:</em> Speichere Datei auf der Festplatte ab. Entspricht <code>brig stage</code> und <code>brig cat</code>.</li>
<li><em>Remove:</em> Entfernt die Datei im <em>Staging–Bereich</em>.</li>
<li><em>New Folder:</em> Entspricht <code>brig mkdir</code>.</li>
<li><em>Open in file browser:</em> Öffnet den Dateibrowser des Systems. Dies ist nützlich wenn komplexere Features benötigt werden.</li>
</ul>
<p>Die Ansicht ist zudem durchsuchbar. Wird ein Teil eines Pfades eingegeben, so werden alle Dateien angezeigt, die dieses Pfadfragment beinhalten. Die Oberfläche ähnelt dabei sehr dem Dateibrowser <em>Nautilus</em><a href="#fn133" class="footnoteRef" id="fnref133"><sup>133</sup></a>, da die selben Widgets zur Anzeige der Dateien benutzt werden.</p>
<h3 id="sec:ui-vcs"><span class="header-section-number">7.5.4</span> Versionsverwaltung</h3>
<p>Dieser Bildschirm bietet dem Nutzer Zugriff auf die eingebaute Versionsverwaltung. Die Ansicht ist zweigeteilt. Auf der linken Seite findet sich eine Liste mit allen bekannten Commits (entspricht etwa <code>brig log</code>). Jede Commitzeile enthält dabei den Index des Commits, der Commit–Message, dem Erstellungsdatum und dem farbig hervorgehobenen Autor. Auf der rechten Seite jeder Zeile findet sich der <em>Checkout</em>–Button, mit dem der aktuelle Stand auf den Stand im ausgewählten Commit zurücksetzbar ist. Unter dem Namen <em>Uncommited Changes</em> findet sich an oberster Stelle zudem immer der <em>Staging Commit</em>. Im linken, unteren Bereich wird zudem eine Statusleiste eingeblendet, in der als empfohlene Aktion das Anlegen eines neuen Commits möglich ist. Diese Aktion wird nur eingeblendet wenn sich <code>HEAD</code> und <code>CURR</code> unterscheiden.</p>
<p>Auf der rechten Seite werden für den aktuell ausgewählten Commit alle darin gemachten Änderungen aufgelistet. Dabei wird für jeden Checkpoint des Commits eine Zeile angezeigt. Diese beinhaltet den Pfadnamen, den Änderungstyp (farbig kodiert) und den Änderungszeitpunkt. Liegt der Änderungszeitpunkt noch nicht lange zurück, so wird er relativ zum aktuellen Zeitpunkt angegeben (»<em>5 minutes ago</em>«). Auf der rechten Seite jeder Zeile finden sich zwei Knöpfe. Der Linke erlaubt den Export der Datei zu einem beliebigen Pfad im Dateisystem im entsprechenden Zustand. Der rechte Knopf setzt im <em>Staging–Commit</em> die entsprechende Datei auf diesen Stand zurück.</p>
<p>Diese Ansicht ist durchsuchbar. Wird ein Pfad eingegeben (im Beipsiel <code>/photos</code>), so werden alle Commits angezeigt, in denen der <code>/photos</code>–Ordner verändert wurde.</p>
<a name="fig:mockup-vcs"></a>
<div class="figure">
<img src="images/6/view-vcs.png" alt="Figure 44: Figure 44. Mockup: Bildschirm zur Versionsverwaltung." id="fig:mockup-vcs" />
<p class="caption">Figure 44: Figure 44. Mockup: Bildschirm zur Versionsverwaltung.</p>
</div>
<h3 id="einstellungen"><span class="header-section-number">7.5.5</span> Einstellungen</h3>
<a name="fig:mockup-settings"></a>
<div class="figure">
<img src="images/6/view-settings.png" alt="Figure 45: Figure 45. Mockup: Bildschirm des Einstellungseditors." id="fig:mockup-settings" />
<p class="caption">Figure 45: Figure 45. Mockup: Bildschirm des Einstellungseditors.</p>
</div>
<p>Über den Einstellungsbildschirm sind alle verfügbaren Einstellungen erreichbar. Die Einstellungen sind in mehrere Kategorien aufgeteilt (hier <em>General</em>, <em>Miscellaneous</em>, und <em>Synchronize</em>). Jedes Einstellungsmerkmal entspricht dabei einer Zeile, die links jeweils eine kurze und eine etwas längere Beschreibung der Einstellung beinhaltet. Rechts findet sich je eine Schaltfläche, die den aktuellen Wert anzeigt und eine Modifikation erlaubt. Dabei erhalten Größenangaben (<em>Soft limit</em>) entsprechend eine Schaltfläche, um eine physikalische Größe einzustellen, während boolesche Werte (<em>Go online by default</em>) einen simplen Aus/An–Schalter erhalten. Enumerationswerte, bei denen es eine genau festgesetzte Menge an Auswahlmöglichkeiten gibt (<em>Which synchronization strategy to choose</em>), zeigen nach einem Klick auf die Schaltfläche ein Auswahlmenü an. In diesem werden alle Möglichkeiten angezeigt, wobei die Standardmöglichkeit mit einem Stern gekennzeichnet wird und die ausgewählte Möglichkeit grau hinterlegt wird.</p>
<p>Die Änderung der Einstellungen muss explizit mit dem (empfohlenen, da blau hervorgehobenen) »Apply«–Knopf bestätigt werden. Wechselt man die Ansicht ohne zu bestätigen, so werden die Änderungen nicht übernommen. Möchte man alle Werte auf »Werkseinstellungen« zurücksetzen, so kann der Nutzer den <em>»Reset to defaults«</em>–Knopf betätigen. Dieser ist rot hervorgehoben, um anzuzeigen, dass es sich hierbei um eine destruktive Operation handelt.</p>
<p>Auch diese Ansicht ist durchsuchbar. Wird ein Stichwort eingegeben, so werden nur diejenigen Zeilen angezeigt, deren kurze oder lange Beschreibung dieses Stichwort enthalten.</p>
<h1 id="sec:evaluation"><span class="header-section-number">8</span> Evaluation</h1>
<p>In diesem Kapitel wird die Implementierung und die dahinter stehende Architektur auf Schwächen untersucht. Es wird gezeigt, was die Software nicht zu leisten vermag und welche eingangs definierten Anforderungen sie (noch) nicht erfüllen kann. Abgeschlossen wird das Kapitel mit verschiedenen Geschwindigkeitsmessungen, sowie einigen Konzepten zur weiteren Entwicklung.</p>
<h2 id="was-brig-nicht-ist"><span class="header-section-number">8.1</span> Was <code>brig</code> <em>nicht</em> ist</h2>
<p><code>brig</code> kann nicht die beste Alternative in allen Bereichen sein. Keine Software kann die sprichwörtliche »eierlegende Wollmilchsau«<a href="#fn134" class="footnoteRef" id="fnref134"><sup>134</sup></a> sein und sollte auch nicht als solche benutzt werden. Insgesamt ist es für folgende Bereiche weniger geeignet:</p>
<p><strong>High Performance:</strong> Besonders im Bereich Effizienz kann es nicht mit hochperformanten Cluster–Dateisystemen wie Ceph<a href="#fn135" class="footnoteRef" id="fnref135"><sup>135</sup></a> oder GlusterFS<a href="#fn136" class="footnoteRef" id="fnref136"><sup>136</sup></a> mithalten. Das liegt besonders an der sicheren Ausrichtung von <code>brig</code>, welche oft Rechenleistung zugunsten von Sicherheit eintauscht (siehe sec. 8.4).</p>
<p><strong>Echtzeitanwendungen:</strong> Schreibt ein Nutzer etwas in eine Datei, so ist diese Änderung nicht augenblicklich anderen Nutzern zugänglich. Selbst wenn Live–Updates (siehe sec. 5.4.2) verfügbar sind, kann <code>brig</code> selbst entscheiden, wann die Änderungen synchronisiert werden.<a href="#fn137" class="footnoteRef" id="fnref137"><sup>137</sup></a> Insbesondere macht es beispielsweise kaum Sinn, SQL–Datenbanken von <code>brig</code> synchronisieren zu lassen. Hierfür gibt es weitaus bessere Alternativen wie <em>CockroachDB</em><a href="#fn138" class="footnoteRef" id="fnref138"><sup>138</sup></a>.</p>
<p><strong>Volle POSIX-Kompatibilität notwendig:</strong> Der <em>POSIX</em>–Standard definiert (unter anderem) eine gemeinsame, standardisierte API, die von vielen (zumeist unixoiden) Betriebssystemen implementiert wird (siehe auch <span class="citation">[5]</span>). Nicht alle Teile dieses Interfaces können von <code>brig</code> umgesetzt werden. So gibt es kaum eine verträgliche Definition von harten und weichen Verlinkungen (<em>Hardlinks</em> und <em>Symbolic Links</em>) für dezentrale Netzwerke. Auch spezielle Dateien wie <em>FIFOs</em> können in diesem Kontext nicht ohne Race–Conditions umgesetzt werden. Entsprechende Operationen werden von <em>FUSE–Layer</em> mit dem <em>POSIX</em>–Fehlercode <code>ENOSYS</code> (»nicht implementiert«) quittiert.</p>
<p><strong>Glaubhafte Abstreitbarkeit:</strong> Auch wenn ein <code>brig</code>–Repository in der geschlossenen Form als sicherer »Datensafe« einsetzbar ist, so bietet <code>brig</code> nicht die Eigenschaft der »glaubhaften Abstreitbarkeit«<a href="#fn139" class="footnoteRef" id="fnref139"><sup>139</sup></a>, die Werkzeuge wie Veracrypt bieten.</p>
<p><strong>Zeilenbasierte Differenzen:</strong> Im Gegensatz zu Versionsverwaltungssystemen wie <code>git</code>, kann <code>brig</code> keine zeilenbasierten Differenzen zwischen zwei Dateien anzeigen, da es nur auf den Metadaten von Dateien arbeitet.</p>
<p><strong>Reiner Speicherdienst auf der Gegenseite:</strong> Auf der Gegenseite muss ein <code>brig</code>–Daemon–Prozess laufen, um mit der Gegenseite zu kommunzieren. Daher können reine Speicherdienste wie <em>Amazon S3</em><a href="#fn140" class="footnoteRef" id="fnref140"><sup>140</sup></a> nicht ohne weiteres als Datenlager benutzt werden. Das kann allerdings leicht umgangen werden, indem der entfernte Speicher lokal gemounted<a href="#fn141" class="footnoteRef" id="fnref141"><sup>141</sup></a> wird, und der <code>brig</code>–Prozess lokal gestartet wird. Werkzeuge wie <code>rsync</code> oder <code>git-annex</code> benötigen lediglich einen <code>ssh</code>–Zugang zum Datenlager und funktionieren daher auch ohne Gegenüber.</p>
<p><strong>Keine starke Ausfallsicherheit:</strong> <code>brig</code> speichert nur ganze Dateien auf <span class="math inline">1</span> bis <span class="math inline"><em>n</em></span> Knoten. Es wird kein <em>Erasure–Enconding</em><a href="#fn142" class="footnoteRef" id="fnref142"><sup>142</sup></a> angewendet, wie beispielsweise <code>Tahoe-LAFS</code> das tut. Damit eine Datei im Falle des Ausfalls eines Knotens wiederherstellbar ist, muss mindestens ein anderer Knoten, die Datei vollständig gespeichert haben, während andere Werkzeuge kleine Blöcke der Dateien redundant auf mehreren Rechnern ablegen. Werden diese beschädigt, können diese sich selbst reparieren oder von anderen Knoten neu übertragen werden. Für die meisten Anwendungszwecke ist aus Sicht des Autors Redundanz auf dem Dateilevel ausreichend.</p>
<p><strong>Embedded Devices:</strong> <code>brig</code> benötigt ein vollständiges Betriebssystem mit Netzwerkanschluss, Hauptspeicher und einer ausreichend starken CPU. Die »unterste Grenze« für einen vernünftigen Betrieb wäre vermutlich ein aktueller Raspberry Pi in Version 3.</p>
<h2 id="erfüllung-der-anforderungen"><span class="header-section-number">8.2</span> Erfüllung der Anforderungen</h2>
<p>Im Folgenden wird die Umsetzung der in sec. 3 aufgelisteten Anforderungen betrachtet. Auf jede Anforderung wird dabei kurz zusammenfassend eingegangen und die Erfüllung wird mit »« (<em>Erfüllt</em>), »« (<em>Teilweise erfüllt</em>) und »« (<em>Überwiegend nicht erfüllt</em>) bewertet.</p>
<h3 id="anforderungen-an-die-integrität-1"><span class="header-section-number">8.2.1</span> Anforderungen an die Integrität</h3>
<p><strong>Entkopplung von Metadaten und Daten</strong> (): Daten und Metadaten sind vollkommen entkoppelt und werden sowohl getrennt gespeichert (<code>ipfs</code> und <em>BoltDB</em>) als auch getrennt behandelt. Die Daten können irgendwo im <code>ipfs</code>–Netzwerk liegen, die Metadaten werden von allen Teilnehmern vorgehalten.</p>
<p><strong>Pinning</strong> (): Es ist möglich, einen Pin zu Dateien und Verzeichnissen hinzuzufügen (<code>brig pin</code>) und wieder zu entfernen (<code>brig pin -u</code>). Allerdings wird dieses Konzept von <code>brig</code> selbst noch sehr simpel behandelt. Neu hinzugefügte Dateien bekommen automatisch einen Pin, die Pins eines Synchronisationspartners werden nicht übernommen. Der Pin von gelöschten Dateien wird entfernt. Es wird allerdings im momentanen Zustand weder eine Speicherquote eingehalten, noch wird der Pin automatisch ab einer bestimmten Versionierungstiefe entfernt.</p>
<p><strong>Langlebigkeit</strong> (): Redundante Speicherung von Dateien ist manuell möglich, aber noch ist keine Anzahl minimaler Kopien einstellbar, die von <code>brig</code> überwacht wird. Eine Veränderung der Datei kann durch Neuberechnung der Prüfsumme überprüft werden.</p>
<p><strong>Verfügbarkeit</strong> (): Lokale Daten sind stets verfügbar. Daten von Synchronisationspartnern sind verfügbar wenn diese online sind. Ein Knoten der automatisch alle Metadaten von mehreren Partnern sammelt scheint technisch machbar (entsprechend dem Nutzer »<code>rabbithole@wonderland</code>« in sec. 5.2.1), ist aber noch nicht implementiert. Problematisch für den Nutzer ist der Umgang mit momentan nicht verfügbaren Dateien. <code>brig</code> selbst hat keine Informationen darüber ob die Datei tatsächlich verfügbar ist, da diese Aufgabe von <code>ipfs</code> übernommen wird. Daher wird dies für den Benutzer erst ersichtlich wenn er versucht die Datei auszulesen. Sollte die Datei nicht verfügbar sein, so wird das Öffnen der Datei eine lange Zeit benötigen und schließlich mit einem Zeitüberschreitungsfehler enden. Hier müsste <code>brig</code> mehr Aufwand betreiben, um den Nutzer dabei zu helfen, nicht zugreifbare Dateien frühzeitig zu erkennen.</p>
<p><strong>Integrität</strong> (): Jede Datei ist in Blöcke aufgeteilt, von denen jeder eine MAC speichert. Mithilfe dieser können absichtliche und unabsichtliche Modifikationen erkannt werden. Eine Integritätsprüfung für Metadaten (beispielsweise eine MAC, die den Store–Inhalt vor der Übertragung absichert) ist allerdings noch nicht implementiert.</p>
<h3 id="anforderungen-an-die-sicherheit-1"><span class="header-section-number">8.2.2</span> Anforderungen an die Sicherheit</h3>
<p><strong>Verschlüsselte Speicherung:</strong> () Jede Datei wird in einem verschlüsselten Container (siehe sec. 5.4.1.1) abgelegt. Der Schlüssel wird momentan zufällig generiert und wird mit den anderen Metadaten zum Synchronisationspartner übertragen.</p>
<p><strong>Verschlüsselte Übertragung:</strong> () Nicht nur <code>ipfs</code>–Verbindungen an sich werden verschlüsselt, auch <code>brig's</code> Transferprotokoll (welches darauf aufsetzt) verschlüsselt die Daten zusätzlich, um sich gegen eventuelle Lücken in <code>ipfs</code> abzusichern.</p>
<p><strong>Authentifizierung:</strong> () Bevor eine Synchronisation stattfinden kann, müssen die Teilnehmer auf beiden Seiten ihr Gegenüber initial authentifizieren. Das geschieht indem sie den Nutzernamen mit der dazugehörigen Identitäts–Prüfsumme über einen sicheren Seitenkanal vergleichen. Da die Prüfsumme fälschungssicher ist, muss es sich um den gewünschten Partner handeln. Nach erfolgreicher initialer Authentifizierung wird der Partner in die Remote–Liste unter seinem Nutzernamen aufgenommen. Bei jedem erneuten Verbindungsaufbau zum Kommunikationspartner wird dieser basierend auf den Informationen in der Remote–Liste authentifiziert.</p>
<p><strong>Identität:</strong> () Als menschenlesbarer Identifikationsbezeichner wird eine modifizierte Form der Jabber–ID eingesetzt. Dieses Format ist gut lesbar und schränkt den Nutzer bei der Namenswahl nicht signifikant ein. Wie in sec. 5.4.3 beschrieben, wird keine zentrale Instanz zur Registrierung benötigt.</p>
<p><strong>Transparenz:</strong> () Die Implementierung steht unter der freien <code>APGLv3</code>–Lizenz. Diese stellt rückwirkend die Freiheit des Quelltextes sicher. Zukünftige Versionen könnten prinzipiell proprietär werden, falls die Entwickler sich dazu entscheiden sollten. Auch wenn das nicht die aktuelle Absicht der Entwickler ist, könnte <code>brig</code> in diesem Fall von der Open–Source–Community weiterentwickelnd werden. Eine Einsicht in den Quelltext oder Beteiligung am Projekt ist durch die Code–Hosting–Plattform <em>GitHub</em> leicht möglich.</p>
<h3 id="anforderungen-an-die-usability-2"><span class="header-section-number">8.2.3</span> Anforderungen an die Usability</h3>
<p><strong>Automatische Versionierung:</strong> () Eine Versionierung von Dateien ist gegeben, die vergleichbar mit <code>git</code> ist und umfangreicher als die, der meisten existierenden Werkzeuge. Momentan wird (hardkodiert) alle 15 Minuten ein automatisierter Commit gemacht (falls Änderungen vorlagen). Wie bereits oben beschrieben, wurde allerdings noch keine Quota implementiert, weshalb viele Änderungen an großen Dateien schnell sehr viel Speicherplatz benötigen werden.</p>
<p><strong>Portabilität:</strong> () Bei der Entwicklung wurde bei der Auswahl der Bibliotheken auf leichte Portierbarkeit zu anderen Systemen geachtet. Getestet und eingesetzt wurde die Software bisher nur auf einem Linux–System. Prinzipiell sollte sie auf anderen unixoiden Systemen lauffähig sein. Die volle Portierung auf Windows ist problematischer, da dort FUSE nicht lauffähig ist. Dabei gäbe es entweder die Möglichkeit eine Implementierung für das ähnliche, rein Windows–komaptible <em>Dokany</em><a href="#fn143" class="footnoteRef" id="fnref143"><sup>143</sup></a> zu liefern oder einen WebDAV<a href="#fn144" class="footnoteRef" id="fnref144"><sup>144</sup></a> Server zu implementieren. Bei letzterer Option würde <code>brigd</code> als WebDAV–Server fungieren, der von Windows und anderen Betriebssystemen als Dateisystem eingehängt werden kann. Noch schwieriger wird der Einsatz von <code>brig</code> auf mobilen Plattformen. Dort ist <em>Go</em> momentan nur bedingt einsetzbar<a href="#fn145" class="footnoteRef" id="fnref145"><sup>145</sup></a>. Sollte es einsetzbar werden, müsste eine eigene grafische Oberfläche implementiert werden, um <code>brig</code> beispielsweise auf einem Android–Smartphone nutzen zu können.</p>
<p><strong>Einfache Installation:</strong> () Auf unixoiden Betriebssystemen ist die Installation sehr einfach (siehe auch sec. 10.1). Die einzige Abhängigkeit von <code>brig</code> ist <em>Go</em>. Im späteren Projektverlauf können für die meistgenutzten Plattformen und Architekturen auch fertige Binärdateien angeboten werden.</p>
<p><strong>Keine künstlichen Limitierungen:</strong> () Durch den FUSE–Layer wird ein ganz normaler Systemordner bereitgestellt. Bis auf den lokalen Festplattenspeicher hat dieser keine zusätzlichen Limitierungen. Der einzige Unterschied für den Benutzer ist, dass die darin gespeicherten Daten entweder gar keinen Speicherplatz brauchen oder (durch das Verschlüsselungsformat) geringfügig größer sind als die eigentliche Datei. Durch die Versionierung benötigen zudem alte Kopien zusätzlichen Speicherplatz.</p>
<p><strong>Generalität:</strong> () <code>brig</code> ist mit denen im Punkt »Portabilität« genannten Einschränkungen auf allen Rechnern lauffähig und macht keine Annahmen zum Dateisystem oder zur Hardware auf der es läuft. Momentan sind allerdings alle Nutzer, mit denen synchronisiert werden soll, gezwungen <code>brig</code> zu nutzen. Dies betrifft auch Nutzer, mit denen nur eine einzelne Datei geteilt werden soll. Ein »HTTPS–Gateway«, mit dem einzelne Dateien veröffentlicht werden können, wurde noch nicht implementiert.</p>
<p><strong>Stabilität:</strong> () Die momentane Implementierung ist vergleichsweise instabil und bräuchte mehr Testfälle, um ein gewisses Vertrauen in die Stabilität der Software herzustellen. Welchen Umfang die Testsuite momentan hat, kann in sec. 8.3 nachgelesen werden.</p>
<p><strong>Effizienz:</strong> () <code>brig</code> ist schnell genug, um auf einem typischen Arbeitsrechner eine lokale Full–HD Filmdatei vom FUSE–Dateisystem aus abzuspielen. Details zu der Geschwindigkeit finden sich in sec. 8.4. Besonders im FUSE–Dateisystem sind noch einige Optimierungsmöglichkeiten vorhanden, welche die Gesamteffizienz steigern können.</p>
<h2 id="sec:testsuite"><span class="header-section-number">8.3</span> Stand der Testsuite</h2>
<p>Obwohl die Testsuite im momentanen Zustand zu klein ist, existieren für die meisten Pakete bereits Unittests. Insgesamt gibt es derzeit 26 Dateien, die Tests beinhalten, in denen sich 56 einzelne Unittests befinden. Diese versuchen immer möglichst kleine Teile der Codebasis anzusprechen, um die Fehlersuche zu erleichtern. So wird für viele Tests ein <em>Mock</em>–Store in einem temporären Verzeichnis angelegt oder es wird ein temporäres <code>ipfs</code>–Repository angelegt anstatt diese Arbeit den Quelltext hinter »<code>brig init</code>« erledigen zu lassen. Diese Methode hilft zusätzlich, um den Quelltext allgemein und austauschbar zu halten.</p>
<p>Noch existieren keine Zahlen, was die Testabdeckung angeht. Diese machen aus Sicht des Autors zum jetzigen Zeitpunkt auch noch keinen Sinn, da sich die Implementierung noch stark verändern wird. In Zukunft sollte die »Coverage« aber ein wichtiges Instrument werden, um nicht getesteten Quelltext aufzuspüren.</p>
<h2 id="sec:benchmarks"><span class="header-section-number">8.4</span> Benchmarks</h2>
<p>Die Umsetzung von sauberen Benchmarks ist schwierig, da <code>brig</code> genau wie andere Synchronisationswerkzeuge ein sehr komplexes System ist, dessen Effizienz von einer Vielzahl von Faktoren abhängt. Grundsätzlich ist es schwierig, die Gesamteffizienz eines Systems sinnvoll zu messen, da folgende Komponenten sich von System zu System drastisch unterscheiden können:</p>
<ul>
<li>Hauptspeicher und Prozessor.</li>
<li>Speichermedium und Netzwerklatenz.</li>
<li>Betriebssystem und verwendeter Scheduler.</li>
<li>Spezielle Befehlserweiterungssätze<a href="#fn146" class="footnoteRef" id="fnref146"><sup>146</sup></a>.</li>
</ul>
<h3 id="aufbau"><span class="header-section-number">8.4.1</span> Aufbau</h3>
<p>Aus diesem Grund wird im Folgenden rein die lokale Effizienz beim Hinzufügen einer Datei in Megabyte pro Sekunde untersucht. Alle Benchmarks werden direkt im Hauptspeicher ausgeführt, es erfolgen keine Festplattenzugriffe. Möglich wird das durch den Einsatz eines <code>ramfs</code><a href="#fn147" class="footnoteRef" id="fnref147"><sup>147</sup></a>, welches ein temporäres Dateisystem bereitstellt, in dem alle Dateien direkt im Hauptspeicher geschrieben und gelesen werden. Dadurch ist der Prozessor<a href="#fn148" class="footnoteRef" id="fnref148"><sup>148</sup></a> der ausschlaggebende Faktor bei der Effizienz in diesem Benchmark, da ausreichend Hauptspeicher vorhanden war.</p>
<p>Als Eingabedateien wurden zwei unterschiedliche Datensätze genommen:</p>
<ul>
<li>Eine schlecht komprimierbare Filmdatei<a href="#fn149" class="footnoteRef" id="fnref149"><sup>149</sup></a>.</li>
<li>Ein gut komprimierbarer Textkorpus in deutscher Sprache<a href="#fn150" class="footnoteRef" id="fnref150"><sup>150</sup></a>.</li>
</ul>
<p>Aus beiden Dateien werden jeweils zehn kleinere Dateien durch Abschneiden hergestellt. Diese sind jeweils 1, 2, 4, 8, 16, 32, 64, 128, 256 und 512 MB groß und werden in das <code>ramfs</code> gelegt. Es entstehen also insgesamt 20 kleinere Dateien. Im <code>ramfs</code> wird ebenfalls ein <code>brig</code>–Repository und ein <code>ipfs</code>–Repository angelegt. Zudem wird im <code>ramfs</code> noch ein FUSE–Dateisystem, basierend auf dem <code>brig</code>–Repository, angelegt.</p>
<p>Basierend auf diesen Eingabedateien werden für beide Datensätze folgende Zeitmessungen erhoben:</p>
<ul>
<li>Lesen mit/ohne Dekompression und mit/ohne Entschlüsselung.</li>
<li>Schreiben mit/ohne Kompression und mit/ohne Verschlüsselung.</li>
<li>Lesen direkt von <code>ipfs</code> mit/ohne Entschlüsselung plus Dekompression.</li>
<li>Schreiben direkt zu <code>ipfs</code> mit/ohne Verschlüsselung plus Kompression.</li>
<li>Hinzufügen der Datei über <code>brig stage</code>.</li>
<li>Ausgabe der Datei mit <code>brig cat</code> und über das FUSE–Dateisystem mit <code>cat</code>.</li>
</ul>
<p>Als Grunddurchsatz (»Baseline«) wird zusätzlich gemessen wie lange ein direktes Kopieren der Datei im <code>ramfs</code> dauert. Zur Kompression wurde immer der <em>Snappy</em>–Algorithmus verwendet. <em>LZ4</em> zeigt ähnliche Eigenschaften, ist aber stets etwas langsamer. Zur Verschlüsselung wird <em>ChaCha20</em> eingesetzt. Das ebenfalls unterstützte <em>AES256</em> im GCM–Modus war ebenfalls immer etwas langsamer.</p>
<p>Die untenstehenden Ergebnisse wurden halbautomisch mit einem Shellskript erhoben und mit einem Python–Skript, mithilfe der <code>pygal</code><a href="#fn151" class="footnoteRef" id="fnref151"><sup>151</sup></a>–Bibliothek, in Plots gerendert. Beide Skripte finden sich in sec. 12.</p>
<h3 id="ergebnisse"><span class="header-section-number">8.4.2</span> Ergebnisse</h3>
<p>Die Plots nutzen kubische Interpolation zwischen den einzelnen Messpunkten. Die Zeitachse ist zudem logarithmisch aufgetragen, um den linearen Zusammenhang zwischen den Achsen zu verdeutlichen. Insgesamt wurden vier Plots erstellt. Zwei für jede Eingabedatenmenge (Filmdatei und Textkorpus) und dafür jeweils ein Plot für das Schreiben und Lesen dieser Eingabedaten.</p>
<a name="fig:plot-movie-write"></a>
<div class="figure">
<img src="images/7/movie_write.png" id="fig:plot-movie-write" style="width:95.0%" />
<p class="caption">Figure 46: Figure 46. Schreiboperationen auf der Datei <code>movie.mp4</code></p>
</div>
<a name="fig:plot-movie-read"></a>
<div class="figure">
<img src="images/7/movie_read.png" id="fig:plot-movie-read" style="width:95.0%" />
<p class="caption">Figure 47: Figure 47. Leseoperationen auf der Datei <code>movie.mp4</code></p>
</div>
<a name="fig:plot-archive-write"></a>
<div class="figure">
<img src="images/7/archive_write.png" id="fig:plot-archive-write" style="width:95.0%" />
<p class="caption">Figure 48: Figure 48. Schreiboperationen auf der Datei <code>archive.tar</code></p>
</div>
<a name="fig:plot-archive-read"></a>
<div class="figure">
<img src="images/7/archive_read.png" id="fig:plot-archive-read" style="width:95.0%" />
<p class="caption">Figure 49: Figure 49. Leseoperationen auf der Datei <code>archive.tar</code></p>
</div>
<p>Insgesamt können folgende Konklusionen aus den Ergebnissen gezogen werden:</p>
<ul>
<li>Der Lese/Schreib–Durchsatz bleibt unabhängig von der Dateigröße größtenteils konstant.</li>
<li>»<code>brig stage</code>« hat gegenüber »<code>ipfs add</code>« mit Verschlüsselung und Kompression einen geringen Overhead durch die interne Programmlogik. Dieser steigt aber bei einer größeren Datenmenge nicht weiter an (siehe fig. 46 und fig. 48).</li>
<li>Ähnliches lässt sich zu »<code>brig cat</code>« und »<code>ipfs add</code>« feststellen (siehe fig. 47 und fig. 49).</li>
<li>Kompression und Dekompression ist stets weniger ressourcenaufwändig als Verschlüsselung und Entschlüsselung. Ob an der Implementierung etwas verbessert werden kann, muss separat untersucht werden.</li>
<li>Der Zugriff über das FUSE–Dateisystem (<span class="math inline">12.8</span> MB/s) ist verglichen mit <code>brig cat</code> (<span class="math inline">85</span> MB/s) deutlich langsamer. Die Gründe hierfür liegen vermutlich weniger an FUSE an sich, als an der aktuellen, ineffizienten Implementierung.</li>
<li>Die Messergebnisse bis 8MB sind noch relativ stark von Messungenauigkeiten beeinträchtigt. Erst bei höheren Datenmengen werden die Ergebnisse repräsentativ.</li>
</ul>
<p>Als Fazit lässt sich sagen, dass viel Optimierungspotenzial vorhanden ist, auch wenn die momentanen Durchsatzraten für viele Anwendungsfälle ausreichend sind. In vielen Szenarios werden zudem nicht die lokalen Dateioperationen der Flaschenhals sein, sondern die Übertragung über das Netzwerk.</p>
<h2 id="zukünftige-erweiterungen"><span class="header-section-number">8.5</span> Zukünftige Erweiterungen</h2>
<p>Abschließend sollen noch einige mögliche Erweiterungsmöglichkeiten der momentanen Implementierung besprochen werden. Diese werden erst angegangen, sobald der momentane Prototyp stabilisiert, dokumentiert und veröffentlicht wurde. Die folgenden Ideen sind also noch in der Konzeptionsphase. Unterteilt wird die Auflistung in Verbesserungen an der existierenden Implementierung (welche vergleichsweise einfach umsetzbar sind), sowie konzeptuelle Erweiterungen (welche typischerweise weitgehendere Änderungen erfordern).</p>
<h3 id="sec:verbesserungen"><span class="header-section-number">8.5.1</span> Verbesserungen an der Implementierung</h3>
<p><strong>Kompression basierend auf MIME–Type:</strong> Kompression lohnt sich nicht bei allen Dateiformaten. Gut komprimieren lassen sich Dateien mit Textinhalten (wie XML–Dateien) oder allgemein Daten mit sich wiederholenden Mustern darin. Schlecht komprimieren lassen sich hingegen bereits komprimierte Bilder, Videos und Archivdateien. Es wäre sinnvoll, basierend auf dem MIME–Type<span class="citation">[12]</span> einen geeigneten Kompressionsalgorithmus auszuwählen. Textdateien könnten so beispielsweise mit dem speicherplatzeffizienteren <em>LZ4</em> komprimiert werden, größere Dateien mit dem schnelleren <em>Snappy</em>. Multimediadateien könnten von der Kompression ausgenommen werden. Der MIME–Type kann dabei in vielen Fällen automatisiert durch das Lesen der ersten Bytes einer Datei erkannt werden. Entsprechender Code existiert bereits<a href="#fn152" class="footnoteRef" id="fnref152"><sup>152</sup></a>, wird aber noch nicht eingesetzt.</p>
<p><strong>Integritätsprüfung:</strong> Wie in sec. 3 beschrieben, können Daten auf der Festplatte sich ohne Zutun des Nutzers verändern. Dieser Datenverlust ist nicht nur aus Sicht der fehlenden Information kritisch, sondern führt auch dazu, dass die Datei sich möglicherweise nicht mehr synchronisieren lässt, da bei einer Übertragung festgestellt werden würde, dass die Datei sich unerwartet verändert hat. An dieser Stelle könnte ein »<code>brig fsck</code>«–Kommando ansetzen, welches jede gespeichert Datei neu von <code>ipfs</code> liest und die Prüfsumme neu berechnet. Treten Diskrepanzen auf, so kann versucht werden, den fehlerhaften Block aus alten Versionsständen oder von einem Synchronisationspartner zu beziehen. Diese Funktionalität könnte auch direkt in <code>ipfs</code> eingebaut werden. Auch könnte eine solche Reparaturfunktion die BoltDB von <code>brig</code> auf Konsistenz prüfen und nötigenfalls und falls möglich reparieren. Im Gegensatz zu <code>git</code> sollten bei <code>brig</code> keine unerreichbaren Referenzen mehr im MDAG entstehen. Trotzdem könnte ein Programm wie »<code>brig gc</code>« einen <em>Garbage–Collector</em> laufen lassen, der solche Referenzen aufspüren und bereinigen kann. Diese würden auf Programmfehler hindeuten. Weiterhin könnte dieses Kommando genutzt werden, um <code>ipfs gc</code> zu starten.</p>
<p><strong>Nutzung eines existierenden OpenPGP–Schlüssels:</strong> Momentan wird beim Anlegen eines Repositories ein neues RSA–Schlüsselpaar generiert. Viele Nutzer haben aber bereits ein Schlüsselpaar in Form eines OpenPGP–Schlüsselpaars oder eines SSH–Schlüsselpaars. Diese könnten beim Anlegen des Repositories importiert werden. Sollte das Repository neu angelegt werden müssen, so kann der existierende Schlüssel in einem gängigen Format exportiert werden. Es muss allerdings darauf geachtet werden, dass keine zwei Repositories dasselbe Schlüsselpaar benutzen, da dies von <code>ipfs</code> nicht vorgesehen ist. Auch hier könnte die Funktionalität in <code>ipfs</code> direkt eingebaut werden.</p>
<p><strong>Update Mechanismus:</strong> Sicherheitskritische Software wie <code>brig</code> sollte möglichst aktuell gehalten werden, um Sicherheitslücken schnell schließen zu können. Wie ein solcher Mechanismus im Detail aussehen könnte, zeigt die Arbeit von Herrn Piechula (siehe <span class="citation">[27]</span>).</p>
<p><strong>HTTPS–Gateway:</strong> Wie in fig. 10 gezeigt könnte <code>brig</code> als Webserver fungieren, der eine Schnittstelle zum »normalen« Internet bildet. Dieser könnte alle Dateien in einem speziellen Verzeichnis (beispielsweise mit dem Namen <code>/Public</code>) nach außen über einen Link zugreifbar machen. Dies hätte den Vorteil, dass bestimmte Dateien von anonymen Nutzern direkt zugegriffen werden können, ohne dass diese zu einem zentralen Dienst im Internet hochgeladen werden müssen. Voraussetzung dazu ist, dass ein Rechner von »außen« (also vom Internet) aus zugreifbar ist. Möglich wäre auch die Implementierung eines Passwortschutzes, um den Zugriff auf die Dateien zusätzlich abzusichern. Die Verbindung kann dabei durch HTTPS abgesichert werden. Dies benötigt auf Seite des Webservers ein gültiges TLS–Zertifikat. Mittlerweile gibt es dafür automatisierte Dienste wie <em>LetsEncrypt</em><a href="#fn153" class="footnoteRef" id="fnref153"><sup>153</sup></a>. Der in <em>Go</em> geschriebene Webserver <code>caddy</code><a href="#fn154" class="footnoteRef" id="fnref154"><sup>154</sup></a> beherrscht bereits das automatische Besorgen eines <em>LetsEncrypt</em>–Zertifikats.</p>
<p><strong>Hooking Mechanismus:</strong> Um die Erweiterbarkeit von <code>brig</code> zu gewährleisten, könnte <code>brigd</code> seinen Clients Benachrichtigungen mitgeben, sofern sich diese dafür registrieren. Dieser würde den jeweiligen Client mitteilen wenn sich eine Datei geändert hat, gelöscht wurde oder Ähnliches. Auch Statistiken wie die aktuelle Speicherplatzauslastung könnten über diese Schnittstelle realisiert werden.</p>
<p><strong>Packfiles:</strong> Mehrere Dateien könnten zu einem gemeinsamen, komprimierten <em>Pack</em> zusammengeschlossen werden, um Speicherplatz zu sparen. Für eine besonders effiziente Kompression können einzelne Versionen einer Datei zusammengepackt werden. Diese unterscheiden sich oft nur in einzelnen Blöcken und es wäre aus Sicht der Speichereffizienz ungünstig, diese redundant zu speichern. Wie in fig. 50 gezeigt, können immer kleine Blöcke (beispielsweise 16 Kilobyte) von beispielsweise vier Dateien genommen werden und zu einem größeren Block (hier 64 Kilobyte) zusammengefasst werden. Diese großen Blöcke haben den Vorteil, dass sie viel redundante Informationen speichern, wenn sich dieser Block in den einzelnen Versionsständen nicht signifikant geändert hat. Kompressionsalgorithmen wie <em>Snappy</em> arbeiten auf 64 Kilobyte Blöcken<a href="#fn155" class="footnoteRef" id="fnref155"><sup>155</sup></a>, daher kann ein solcher Block relativ platzsparend komprimiert werden. Das Prinzip lässt sich auch auf mehr als die Versionen einer Datei erweitern. Mittels einer Heuristik können Dateien ausgewählt werden, die ähnlich groß sind und auch diese gemeinsam gepackt werden.</p>
<p>Bei kleinen Dateien (<span class="math inline">&lt;64</span> KB) ist bereits das Packen zu einer gemeinsamen Datei vorteilhaft, da diese mit weniger Overhead und effizienterer Kompression gepackt werden können. Die <em>Packfiles</em> von <code>git</code> nutzen einen anderen Ansatz, indem nur Deltas in den einzelnen Archiven gespeichert werden. Dies wäre bei Dateien möglicherweise auch für <code>brig</code> eine valide Herangehensweise und bleibt zu evaluieren.</p>
<p>Es wäre also möglich Speicherplatz im Tausch gegen Rechenzeit zu sparen, indem zwischen <code>ipfs</code> und <code>brig</code> noch eine Abstraktionsschicht eingebaut wird, die intelligent Dateien in <em>Packs</em> verpackt und zugreifbar macht. Die Implementierung dieses Konzeptes hätte zu viel Zeit in Anspruch genommen, weswegen hier weitere Arbeiten ansetzen könnten.</p>
<p><strong>Atomarität und Transaktionen:</strong> In der momentanen Implementierung ist bei einem Ausfall von <code>brigd</code> (beispielsweise durch einen Absturz oder Stromausfall) nicht sichergestellt, dass eine Aktion (wie <code>MakeCommit()</code>) vollständig, atomar abgelaufen ist. Auch wenn die jeweilige Aktion von der API aus durch Locks atomar ist, wird im momentanen Zustand kein Rollback bei Fehlern ausgeführt. BoltDB an sich unterstützt atomare Transaktionen, aber durch die Abstraktion von der konkreten Datenbank werden mehrere kleine Transaktionen nicht zu einer zusammenhängenden, großen Transaktion zusammengefasst. Da aber die Datenbank austauschbar bleiben soll, muss von der Abstraktionsschicht eine Möglichkeit implementiert werden, zurückspulbare Transaktionen zu starten. Dazu dürfen Modifikationen an der Datenbank nicht direkt ausgeführt werden, sondern müssen in einem »Journal«<a href="#fn156" class="footnoteRef" id="fnref156"><sup>156</sup></a> zusammengefasst werden. Dieses kann dann in einer einzigen, atomaren Datenbank–Transaktion zusammengefasst werden.</p>
<a name="fig:stride"></a>
<div class="figure">
<img src="images/7/stride.png" id="fig:stride" />
<p class="caption">Figure 50: Figure 50. Beispielhaftes Packen von vier einzelnen Versionständen.</p>
</div>
<h3 id="konzeptuelle-verbesserungen"><span class="header-section-number">8.5.2</span> Konzeptuelle Verbesserungen</h3>
<p><strong>Zugriffsrechte:</strong> <code>brig</code> unterscheidet im jetzigen Konzept nicht zwischen lesbaren, schreibbaren oder ausführbaren Dateien. Auch gibt es keinen Besitzer oder eine Gruppenzugehörigkeit der Datei. Die einzigen Dateiattribute bilden momentan die Größe und der letzte Änderungszeitpunkt. Aus diesem Grund bewirkt der Aufruf von »<code>chmod</code>« auf eine Datei im FUSE–Dateisystem nichts. Es muss nicht das System von Unix übernommen werden, allerdings wären die Informationen über den Eigentümer wichtig, um selektive Synchronisation zu implementieren. Dabei könnte eine Nutzergruppe angelegt werden. Nur die Nutzer, die dieser Gruppe angehören, können dann Dateien und Verzeichnisse einsehen, die auch dieser Gruppe zugeordnet sind.</p>
<p><strong>Automatische Synchronisation:</strong> Änderungen müssen explizit synchronisiert werden. Um eine Dropbox–ähnliche Funktionalität zu erreichen, sollte eine neue Option eingeführt werden: »<code>brig sync --auto bob@wonderland.lit</code>«. Dabei wird zuerst regulär mit <em>Bob</em> synchronisiert. Im Anschluss wird der Knoten von <em>Bob</em> angewiesen, <em>Alice</em> alle Änderungen auf seiner Seite sofort zu schicken. <em>Alice</em> empfängt diese und ändert ihre eigenen Dateien im Staging–Bereich, um die Änderung nachzuahmen.</p>
<p><strong>Schlagwortbasiertes Dateisystem:</strong> <code>brig</code> arbeitet momentan rein als hierarchisches Dateisystem. Einzelne Knoten des MDAG werden also vom Nutzer mittels Pfad zugegriffen. Eine Erweiterung dazu könnte die Einführung eines schlagwortbasierten Ansatzes (ähnlich zu Tagsistant<a href="#fn157" class="footnoteRef" id="fnref157"><sup>157</sup></a>) sein, welcher es möglich macht, die Menge aller Dateien semantisch durchsuchbar zu machen. Dateien und Verzeichnisse können vom Nutzer mit einem Schlagwort versehen werden (<code>brig tag &lt;path&gt; [&lt;tag&gt;...]</code>). Im FUSE–Dateisystem könnte das Konzept durch die Einführung eines speziellen Ordners (beispielsweise <code>/tags</code>) eingeführt werden. Dieser würde alle definierten Schlagworte als Ordner beinhalten. Unter jedem Schlagwortordner werden alle entsprechend verschlagworteten Dateien angezeigt.</p>
<p><strong>Auto–Discovery anderer Nutzer:</strong> Momentan kann <code>brig</code> einen anderen Nutzer nur finden, wenn man seinen Nutzernamen kennt. Eine »unscharfe« Suche nach Benutzernamen wäre praktisch, ist aber aufgrund der dezentralen Natur von <code>brig</code> schwer umzusetzen. Machbar erscheint aber die automatische Erkennung von anderen <code>brig</code>–Nutzern »in der Nähe« (also im selben, lokalen Netzwerk). Für diesen Anwendungsfall würde sich das <em>Zeroconf–Protokoll</em><a href="#fn158" class="footnoteRef" id="fnref158"><sup>158</sup></a> eignen. Auch diese Funktionalität ließe sich eventuell direkt in <code>ipfs</code> integrieren.</p>
<p><strong>In–Memory Laden des Repositores:</strong> Beim Starten von <code>brigd</code> werden einige sensible Dateien im Repository entschlüsselt. Solange <code>brigd</code> läuft bleiben diese auch lesbar und werden erst wieder verschlüsselt, wenn <code>brigd</code> sich beendet. Dies ist problematisch, wenn ein Angreifer in Besitz einzelner Dateien des Repositories kommen kann. Auch werden die Dateien nicht verschlüsselt, wenn <code>brigd</code> unvermittelt abstürzt und unsauber beendet wird. Schöner wäre eine reine Entschlüsselung der Daten im Hauptspeicher. Änderungen werden direkt in verschlüsselter Form wieder zurückgeschrieben.</p>
<p><strong>Intelligenteres Key–Management:</strong> In der momentanen Implementierung werden alle Schlüssel in den Metadaten der Dateien gelagert. Die Metadaten werden als Ganzes zum Synchronisationspartner übertragen. Hier wäre entweder eine Trennung von den Metadaten (und damit gesonderte Übertragung) sinnvoll oder eine Schlüsselhierarchie, bei denen der eigentliche Schlüssel beispielsweise noch mit einem Gruppenschlüssel verschlüsselt wird. Siehe auch <span class="citation">[27]</span> für weitere Details.</p>
<p><strong>Anonymisierung:</strong> Eine Anonymisierung des Datenverkehrs ist momentan nicht implementiert. Angreifer können zwar den Datenverkehr nicht mitlesen, doch können sie durchaus feststellen, welche Partner miteinander kommunizieren. In manchen Fällen kann dies bereits eine wichtige Information für einen Angreifer sein. Abhilfe könnte die Nutzung des Tor–Netzwerks<a href="#fn159" class="footnoteRef" id="fnref159"><sup>159</sup></a> schaffen. Die einzelnen Knoten würden dabei nicht direkt miteinander kommunizieren, sondern schicken ihren Datenverkehr, verpackt in mehrere verschlüsselte Schichten, über mehre Knoten des Tor–Netzwerks. Diese Funktionalität muss direkt in <code>ipfs</code> implementiert werden. Entsprechende Überlegungen scheinen auf <code>ipfs</code>–Seite bereits zu existieren<a href="#fn160" class="footnoteRef" id="fnref160"><sup>160</sup></a>.</p>
<h1 id="sec:fazit"><span class="header-section-number">9</span> Fazit</h1>
<h2 id="zusammenfassung-1"><span class="header-section-number">9.1</span> Zusammenfassung</h2>
<p>Es wurde ein neuer, interdisziplinärer Ansatz für ein Dateisynchronisationssystem vorgestellt, der viele bestehende Ideen in einem stimmigen Konzept vereint. Eine funktionierende, quelloffene und für alle zugängliche Implementierung wurde vorgestellt und dokumentiert. Die anfangs gestellten Anforderungen konnte im Großen und Ganzen umgesetzt werden, auch wenn die Implementierung den Konzepten etwas nachsteht. Letztlich ist eine solide Basis für weitere Entwicklungen entstanden, die in absehbarer Zeit einem größeren Publikum präsentiert werden kann. Eine Abgrenzung zu anderen, existierenden Werkzeugen ergibt sich vor allem dadurch, dass die technischen Internas von <code>brig</code> vergleichsweise leicht verständlich sind und auch von fortgeschrittenen Nutzern verstanden werden können. Das Ziel, Usability für eine breite Masse zu bieten, konnte mangels grafischer Oberfläche noch nicht erreicht werden. Das Ziel eine sichere Basis zu schaffen konnte hingegen umgesetzt werden. Die Effizienz ist steigerungsfähig, sollte aber für viele Anwendungszwecke ausreichend sein.</p>
<h2 id="selbstkritik"><span class="header-section-number">9.2</span> Selbstkritik</h2>
<p>Wie in sec. 8 diskutiert, ist noch Verbesserungspotenzial vorhanden. In Retrospektive hätte man sich stärker auf die Kernfunktionalität der Software und die zugrunde liegenden Konzepte konzentrieren müssen. Zusatzmodule wie Verschlüsselung sind wichtig, hätten aber auch zu späteren Zeitpunkten nachgerüstet werden können.</p>
<p>Es wurde viel Zeit darauf verwandt, Konzepte in Quelltext zu gießen, die letztlich keine Anwendung fanden oder nicht aufgingen. Das lässt sich bei großen Projekten kaum vermeiden, aber das Testen neuer Konzepte hätte auch mittels »unsauberer« Lösungen funktioniert. Hätte man die Software beispielsweise, nach Unix–Philosophie (wie <code>git</code>), als Sammlung kleiner Werkzeuge konzipiert, hätte man diese kurzzeitig mit einer Skriptsprache wie <code>bash</code> zusammenschließen können, um Probleme in den eigenen Ideen aufzudecken.</p>
<p>Obwohl der zeitliche Rahmen aufgrund der Suche nach Investoren, dem zeitgleichen Abschließen des Studiums und privaten Problem sehr eng war, ist mit <code>brig</code> eine erstaunlich flexible Idee entstanden, von der wir glauben, dass sie wirklich nützlich ist und die Welt etwas verbessern könnte.</p>
<a name="fig:xkcd-standards"></a>
<div class="figure">
<img src="images/8/xkcd-standards.png" alt="Figure 51: Figure 51. Ist »brig« letztlich nur ein weiterer Standard?" id="fig:xkcd-standards" style="width:55.0%" />
<p class="caption">Figure 51: Figure 51. Ist »brig« letztlich nur ein weiterer Standard?<a href="#fn161" class="footnoteRef" id="fnref161"><sup>161</sup></a></p>
</div>
<h2 id="offene-fragen"><span class="header-section-number">9.3</span> Offene Fragen</h2>
<p>Besonders fraglich ist wie gut das System in der Praxis funktioniert und auf größere Nutzermengen skaliert. Da <code>brig</code> von technisch versierten Nutzern entwickelt wurde, ist es auch fraglich wie gut verständlich es für neue, unerfahrenere Benutzer ist. Aus Sicht der Usability gibt es noch einige technische und konzeptuelle Probleme:</p>
<ul>
<li>Keine grafische Oberfläche, nur Kommandozeile.</li>
<li>Initiale Authentifizierung von Hand nötig.</li>
<li>Partner muss online sein, um mit ihm synchronisieren zu können.</li>
<li>Noch keine automatische »Echtzeit«–Synchronisation.</li>
</ul>
<p>Eine Veröffentlichung lohnt sich erst, wenn obige Punkte ansatzweise gelöst worden sind.</p>
<h3 id="beziehung-zum-ipfsprojekt"><span class="header-section-number">9.3.1</span> Beziehung zum <code>ipfs</code>–Projekt</h3>
<p>Momentan wird <code>brig</code> vollkommen separat von <code>ipfs</code> entwickelt. Das hat vor allem den Grund, dass zu Anfang des Projektes die Richtung der Entwicklung noch nicht klar war. Die komplette Separation als eigenes Projekt, macht es deutlich einfacher mit verschiedenen Konzepten zu experimentieren. In Zukunft spricht jedoch nichts dagegen Teile von <code>brig</code>, sofern sie allgemein nützlich sind, auch dem <code>ipfs</code>–Projekt anzubieten und dort zu integrieren. Eine Zusammenarbeit wäre für beide Seiten vorteilhaft, da mehr Entwickler sich mit dem Quelltext befassen können und die dazugehörigen Konzepte aufeinander abstimmen können. Von <code>ipfs</code>–Seite scheint eine Zusammenarbeit gern gesehen zu sein:</p>
<blockquote>
<p><em>Yeah we want to get to this too and would love to support your efforts. I’d request that you consider contributing directly to go-ipfs since much of what you want we want too.</em></p>
<p>— <em>Juan Benet</em>, Kernentwickler von <code>ipfs</code><a href="#fn162" class="footnoteRef" id="fnref162"><sup>162</sup></a></p>
</blockquote>
<p>Konkret wären folgende Module von <code>brig</code> für <code>ipfs</code> interessant:</p>
<ul>
<li>Das Verschlüsselungsformat.</li>
<li>Das Kompressionsformat.</li>
<li>Teile des Datenmodells, insbesondere die <code>Commit</code>–Struktur und Versionsverwaltung.</li>
<li>Die Implementierung eines beschreibbaren FUSE–Dateisystems<a href="#fn163" class="footnoteRef" id="fnref163"><sup>163</sup></a>.</li>
</ul>
<h3 id="zukunft-der-autoren"><span class="header-section-number">9.3.2</span> Zukunft der Autoren</h3>
<p>Fraglich ist auch wie die Zukunft von <code>brig</code> aussieht, nachdem die vorliegende Arbeit abgeschlossen wurde. Leider konnte für die weitere Förderung des Projektes kein Sponsor verpflichtet werden. Trotz Motivation der Autoren wird <code>brig</code> daher in der näheren Zukunft als Hobbyprojekt weitergeführt. Durch die private Situation beider Autoren wird die Entwicklung sich daher leider verlangsamen.</p>
<h3 id="veröffentlichung-der-software"><span class="header-section-number">9.3.3</span> Veröffentlichung der Software</h3>
<p>Nichtsdestotrotz ist es unser Ziel bis spätestens Mitte des Jahres 2017 <code>brig</code> auf einen Stand zu bringen, den man der Open–Source–Community präsentieren kann. Bevor es so weit ist, ist nicht nur Feinschliff an der bestehenden Software nötig, sondern es muss auch leicht zugängliche Dokumentation geschrieben werden und die Software für verschiedene Betriebssysteme gepackt werden.</p>
<p>Folgende Plattformen erscheinen uns für eine Präsentation der Software geeignet:</p>
<ul>
<li>Bei einem »Linux Tag« (Beispielsweise der »Linux Info Tag« in Augsburg<a href="#fn164" class="footnoteRef" id="fnref164"><sup>164</sup></a>). Dort wäre eine detaillierte Präsentation vor Publikum mit direktem Feedback möglich.</li>
<li>Kleineres Forum mit technisch versierten Nutzern; beispielsweise ein Forum für fortgeschrittene Linux–User. Dort könnte auch eine Paketierung der Software angesprochen werden.</li>
<li>Größere Newsportale wie <em>reddit</em>. Diese werden von einem sehr breiten Publikum besucht.</li>
</ul>
<p>Alle drei Möglichkeiten könnten auch zusammen in dieser Reihenfolge genutzt werden. Bei der Veröffentlichung sollte explizit angemerkt werden, dass sich Internas noch ändern können falls dazu Anlass bestehen sollte.</p>
<p>Auch wenn die Arbeit an <code>brig</code> persönlich sehr kräftezehrend war, haben wir eine Menge dabei gelernt. Es stecken eine Menge guter Ideen in der Software und aus unserer Sicht ist alleine die Zeit der limitierende Faktor, um <code>brig</code> zu einem Produkt zu machen, dass mehr als ein »Standard« (im Sinne von fig. 51) unter Vielen ist.</p>
<p></p>
<h1 id="sec:benutzerhandbuch"><span class="header-section-number">10</span> Anhang: Benutzerhandbuch</h1>
<p>Die Funktionalität des <code>brig</code>–Prototypen ist im momentanen Zustand nur über eine Kommandozeilenanwendung erreichbar. Die Hilfe dieser Anwendung wird unten gezeigt. Im Folgenden werden die einzelnen zur Verfügung stehenden Optionen und Kommandos erklärt. Daneben wird auch eine Anleitung zur Installation gegeben und es werden Ratschläge zur optimalen Nutzung gegeben. Die Software ist zu diesem Zeitpunkt bei Weitem noch nicht stabil genug für den alltäglichen Einsatz. Es muss mit Abstürzen und Fehlern gerechnet werden.</p>
<div class="sourceCode" id="lst:brig-help"><table class="sourceCode bash numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
</pre></td><td class="sourceCode"><pre><code class="sourceCode bash"><span class="ex">NAME</span>:
   <span class="ex">brig</span> - Secure and dezentralized file synchronization

<span class="ex">USAGE</span>:
   <span class="ex">brig</span> [global options] command [command options] [arguments...]

<span class="ex">VERSION</span>:
   <span class="ex">v0.1.0-alpha+cd50f68</span> [buildtime: 2016-07-28T12:55:29+0000]

<span class="ex">COMMANDS</span>:
   <span class="ex">ADVANCED</span> COMMANDS:
     <span class="ex">daemon</span> Manually run the daemon process

   <span class="ex">MISC</span> COMMANDS:
     <span class="ex">config</span> Access, list and modify configuration values
     <span class="fu">mount</span>  Mount a brig repository

   <span class="ex">REPOSITORY</span> COMMANDS:
     <span class="ex">init</span>    Initialize an empty repository
     <span class="ex">open</span>    Open an encrypted repository
     <span class="ex">close</span>   Close an encrypted repository
     <span class="bu">history</span> Show the history of the given brig file
     <span class="ex">pin</span>     Pin a file locally to this machine
     <span class="ex">net</span>     Query and modify network status
     <span class="ex">remote</span>  Remote management.
     <span class="fu">sync</span>    Synchronize with other peers.

   <span class="ex">VERSION</span> CONTROL COMMANDS:
     <span class="ex">status</span>   Print which file are in the staging area
     <span class="fu">diff</span>     Show what changed between two commits
     <span class="ex">log</span>      Show all commits in a certain range
     <span class="ex">commit</span>   Print which file are in the staging area
     <span class="ex">checkout</span> Checkout an old version of a file or a commit

   <span class="ex">WORKING</span> COMMANDS:
     <span class="ex">tree</span>     List files in a tree
     <span class="fu">ls</span>       List files
     <span class="fu">mkdir</span>    Create an empty directory
     <span class="ex">stage</span>    Transer file into brig<span class="kw">`</span><span class="ex">s</span> control
     <span class="ex">unstage</span>  Reset file to last known version
     <span class="fu">rm</span>       Remove the file and optionally old versions of it
     <span class="fu">mv</span>       Move a specific file
     <span class="fu">cat</span>      Concatenates a file

<span class="ex">GLOBAL</span> OPTIONS:
   <span class="ex">--nodaemon</span>, -n       Don<span class="kw">`</span>t run the daemon
   <span class="ex">--password</span> value,    Supply user password
   <span class="ex">--path</span> value         Path of the repository (default: <span class="st">&quot;.&quot;</span>) [<span class="va">$BRIG_PATH</span>]
   <span class="ex">--help</span>, -h           show help
   <span class="ex">--version</span>, -v        print the version</code></pre></td></tr></table></div>
<h2 id="sec:installation"><span class="header-section-number">10.1</span> Installation</h2>
<p><code>Brig</code> kann momentan nur aus den Quellen installiert werden. Zudem wurde der Prototyp nur auf Linux Systemen<a href="#fn165" class="footnoteRef" id="fnref165"><sup>165</sup></a> getestet, sollte aber prinzipiell auch unter <em>Mac OS X</em> funktionieren. Die Installation aus den Quellen ist in beiden Fällen vergleichsweise einfach und besteht aus maximal zwei Schritten:</p>
<p><strong>Installation von Go:</strong> Falls noch nicht geschehen, muss der <em>Go</em>–Compiler und die mitgelieferte Standardbibliothek installiert werden. Dazu kann in Linux Distribution der mitgelieferte Paketmanager genutzt werden. Unter Arch Linux ist der Befehl etwa »<code>pacman -S go</code>« unter Debian/Ubuntu »<code>apt-get install golang</code>«. In allen anderen Fällen kann ein Installationspaket von <code>golang.org</code><a href="#fn166" class="footnoteRef" id="fnref166"><sup>166</sup></a> heruntergeladen werden. Ist <em>Go</em> installiert, muss noch der Pfad definiert werden, in dem alle <em>Go</em>–Quellen landen. Dazu ist das Setzen der Umgebungsvariable <code>GOPATH</code> und eventuell auch <code>GOROOT</code> nötig:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">$ <span class="fu">mkdir</span> ~/go
$ <span class="bu">export</span> <span class="va">GOPATH=</span>~/go
$ <span class="bu">export</span> <span class="va">GOBIN=</span>~/go/bin
$ <span class="bu">export</span> <span class="va">PATH=$PATH</span>:~/go/bin</code></pre></div>
<p>Die letzten drei <code>export</code> Kommandos sollte man in eine Datei wie <code>.bashrc</code> einfügen, um zu gewährleisten, dass die Umgebungsvariablen in jeder Sitzung erneut gesetzt werden.</p>
<p><strong>Übersetzen der Quellen:</strong> Ist <em>Go</em> installiert, kann mittels des <code>go get</code>–Werkzeugs <code>brig</code> heruntergeladen und kompiliert werden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">go</span> get github.com/disorganizer/brig</code></pre></div>
<p>Nach erfolgreicher Ausführung (kann je nach Rechner zwischen etwa einer bis zehn Minuten dauern) sollte ein »<code>brig</code>«–Kommando auf der Kommandozeile verfügbar sein. Ohne weitere Argumente sollte das Kommando den oben stehenden Hilfetext produzieren.</p>
<h3 id="crosscompiling"><span class="header-section-number">10.1.1</span> Cross–Compiling</h3>
<p>Sobald eine erste öffentliche Version von <code>brig</code> veröffentlicht wurde, sollen für die populärsten Plattformen vorgebaute Binärdateien angeboten werden. Um von einem einzigen Host–System aus Binärdateien für andere Plattformen zu erstellen, kann der <em>Go</em>–Compiler mittels der Umgebungsvariablen <code>GOOS</code> und <code>GOARCH</code> dafür konfiguriert werden. <code>GOOS</code> steuert dabei, die Zielplattform (z.B. <em>linux</em> oder <em>windows</em>), <code>GOARCH</code> hingegen steuert die Zielarchitektur der CPU (<code>arm</code>, <code>386</code>, <code>amd64</code>). Folgendes Shellskript kann daher genutzt werden, um für einen Großteil der Plattformen jeweils eine Binärdatei zu erzeugen:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="co">#!/bin/sh</span>
<span class="va">PLATFORMS=(</span> linux darwin windows <span class="va">)</span>
<span class="va">ARCHS=(</span> 386 amd64 arm <span class="va">)</span>
<span class="va">OUTDIR=</span>/tmp/brig-binaries

<span class="fu">mkdir</span> -p <span class="st">&quot;</span><span class="va">$OUTDIR</span><span class="st">&quot;</span>
<span class="bu">cd</span> <span class="st">&quot;</span><span class="va">$GOPATH</span><span class="st">/src/github.com/disorganizer/brig&quot;</span> <span class="kw">||</span> <span class="bu">exit</span> 1

<span class="kw">for</span> <span class="ex">platform</span> in <span class="st">&quot;</span><span class="va">${PLATFORMS[@]}</span><span class="st">&quot;</span><span class="kw">;</span> <span class="kw">do</span>
    <span class="kw">for</span> <span class="fu">arch</span> in <span class="st">&quot;</span><span class="va">${ARCHS[@]}</span><span class="st">&quot;</span><span class="kw">;</span> <span class="kw">do</span>
        <span class="bu">printf</span> <span class="st">&quot;## Building %s-%s\n&quot;</span> <span class="va">$platform</span> <span class="va">$arch</span>
        <span class="bu">export</span> <span class="va">GOARCH=$arch</span>; <span class="bu">export</span> <span class="va">GOOS=$platform</span>

        <span class="co"># This calls `go install` with some extras:</span>
        <span class="fu">make</span> <span class="kw">||</span> <span class="bu">exit</span> 2
        <span class="fu">cp</span> <span class="va">$GOBIN</span>/brig <span class="st">&quot;</span><span class="va">$OUTDIR</span><span class="st">/brig-</span><span class="va">$platform</span><span class="st">-arch&quot;</span>
    <span class="kw">done</span>
<span class="kw">done</span></code></pre></div>
<h2 id="grundlegende-benutzung"><span class="header-section-number">10.2</span> Grundlegende Benutzung</h2>
<p>Die Bedienung von <code>brig</code> ist an das Versionsverwaltungssystem <code>git</code> angelehnt. Genau wie dieses, bietet <code>brig</code> für jede Unterfunktionalität ein einzelnes Subkommando an. Damit <code>git</code>–Nutzer die Bedienung leichter fällt, wurden viele Subkommandos ähnlich benannt, wenn sie in etwa dasselbe tun. So löschen sowohl <code>git rm</code>, als auch <code>brig rm</code> Dateien aus dem Repository.</p>
<h3 id="eingebaute-hilfe"><span class="header-section-number">10.2.1</span> Eingebaute Hilfe</h3>
<p>Neben diesem Dokument und der eingebauten Hilfe gibt es im Moment keine weitere Dokumentation zu den vorgestellten Kommandos. Die eingebaute Hilfe kann entweder allgemein über <code class="sourceCode bash"><span class="ex">brig</span> help</code> aufgerufen werden (produziert dieselbe Ausgabe, wie die eingangs gezeigte Hilfe) oder für ein spezifisches Subkommando mittels <code class="sourceCode bash"><span class="ex">brig</span> help <span class="op">&lt;</span>subcommand<span class="op">&gt;</span></code>. Beispiel für <code class="sourceCode bash"><span class="ex">brig</span> help rm</code>:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="ex">NAME</span>:
   <span class="ex">brig</span> rm - Remove the file and optionally old versions of it.

<span class="ex">USAGE</span>:
   <span class="ex">brig</span> rm [command options] <span class="op">&lt;</span>file<span class="op">&gt;</span> [--recursive<span class="kw">|</span><span class="ex">-r</span>]

<span class="ex">CATEGORY</span>:
   <span class="ex">WORKING</span> COMMANDS

<span class="ex">DESCRIPTION</span>:
   <span class="ex">Remove</span> a spcific file or directory

<span class="ex">OPTIONS</span>:
   <span class="ex">--recursive</span>, -r  Remove directories recursively</code></pre></div>
<h3 id="anlegen-eines-repositories-brig-init"><span class="header-section-number">10.2.2</span> Anlegen eines Repositories (<code>brig init</code>)</h3>
<p>Alle von <code>brig</code> verwalteten Dateien werden in einem einzigen <em>Repository</em> verwaltet. Dies speichert alle Daten und die dazugehörigen Metadaten in einer Ordnerhierarchie. Um <code>brig</code> zu nutzen, muss daher zuerst ein Repository angelegt werden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="bu">export</span> <span class="va">BRIG_PATH=</span>/tmp/alice
$ <span class="ex">brig</span> init alice@wonderland.lit/desktop</code></pre></div>
<p>Der Nutzer wird um die Eingabe einer Passphrase gebeten. Die Formulierung <em>Passphrase</em> ist dabei bewusst anstatt dem Wort <em>Passwort</em> gewählt, da eine gewisse Mindestentropie Voraussetzung zur erfolgreichen Eingabe ist. Die Komplexität wird dabei von der <code>zxcvbn</code>–Bibliothek überprüft<a href="#fn167" class="footnoteRef" id="fnref167"><sup>167</sup></a>. Welche Kriterien es dabei anwendet, kann in <span class="citation">[27]</span> nachgeschlagen werden.</p>
<p>Nach wiederholter, erfolgreicher Eingabe der Passphrase wird ein Schlüsselpaar generiert, und die in fig. 35 gezeigte Verzeichnisstruktur angelegt.</p>
<h3 id="dateien-hinzufügen-löschen-und-verschieben-brig-stagermmv"><span class="header-section-number">10.2.3</span> Dateien hinzufügen, löschen und verschieben (<code>brig stage/rm/mv</code>)</h3>
<p>Wurde ein Repository angelegt, können einzelne Dateien oder rekursiv ganze Verzeichnisse hinzugefügt werden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="bu">cd</span> <span class="va">$BRIG_PATH</span>
$ <span class="ex">brig</span> stage ~/photos/cat.png
<span class="ex">/cat.png</span>
$ <span class="ex">brig</span> stage ~/music/knorkator/
<span class="ex">/knorkator</span></code></pre></div>
<p>Das Hinzufügen größerer Verzeichnisse nimmt etwas Zeit in Anspruch, da die Dateien jeweils komprimiert, verschlüsselt und eine Prüfsumme berechnet werden muss.</p>
<hr />
<p><em>Anmerkung:</em> Zum Ausführen dieser Kommandos muss man entweder im Ordner des <code>brig</code>–Repositories sein oder in einem Unterordner. Andernfalls wird <code>brig</code> eine Meldung wie diese ausgeben:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="ex">10.08.2016</span>/17:<span class="ex">33</span>:11 I: Unable to find repo in path or any parents: <span class="st">&quot;/home/sahib&quot;</span>
<span class="ex">10.08.2016</span>/17:<span class="ex">33</span>:11 W: Could not load config: open .brig/config:
                       <span class="ex">No</span> such file or directory
<span class="ex">10.08.2016</span>/17:<span class="ex">33</span>:11 W: Falling back on config defaults...</code></pre></div>
<p>Oft genug reichen die Standardwerte der Konfiguration aus, damit der Befehl korrekt funktioniert. Alternativ kann auch die Umgebungsvariable <code>BRIG_PATH</code> wie oben gezeigt gesetzt werden, um von überall im Dateisystem das Kommando absetzen zu können.</p>
<hr />
<p>Die hinzugefügten Dateien werden von <code>brig</code> einem virtuellen Wurzelknoten »<code>/</code>« hinzugefügt (<code>/cat.png</code>), anstatt den vollen Pfad zu erhalten (<code>~/photos/cat.png</code>) — letzterer hätte nach der Synchronisation auf andere Rechner keine sinnvolle Bedeutung mehr. Dieses Prinzip wird auch ersichtlich bei Benutzung von <code class="sourceCode bash"><span class="ex">brig</span> ls</code>:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> ls
<span class="ex">105</span> MB  4 seconds ago   /
<span class="ex">2.1</span> MB  4 seconds ago   /photos/
<span class="ex">2.1</span> MB  5 seconds ago   /photos/cat.png
<span class="ex">103</span> MB  4 seconds ago   /knorkator/
 <span class="ex">99</span> MB  4 seconds ago   /knorkator/hasenchartbreaker/
<span class="ex">7.9</span> MB  1 minute ago    /knorkator/hasenchartbreaker/01 Ich bin ein ganz besondrer Mann.mp3
<span class="ex">...</span></code></pre></div>
<p>Möchte man den Inhalt einer Datei von <code>brig</code> wieder ausgeben lassen, so übergibt man den Pfad an das <code>cat</code>–Subkommando<a href="#fn168" class="footnoteRef" id="fnref168"><sup>168</sup></a>:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> cat /photos/cat.png <span class="op">&gt;</span> some-cat.png
$ <span class="ex">open</span> ./some-cat.png  <span class="co"># Öffnet die Datei in einem Bildbetrachter.</span></code></pre></div>
<p>Da <code class="sourceCode bash"><span class="ex">brig</span> cat</code> die Datei als kontinuierlichen Datenstrom ausgibt, ist es möglich größere Dateien wie Filme ohne Zwischendatei direkt anzuzeigen:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> cat /movies/big-buck-bunny.mov <span class="kw">|</span> <span class="ex">mpv</span> -  <span class="co"># Zeige Film mit `mpv`</span></code></pre></div>
<p>Auch die üblichen Unix–Kommandos zum Anlegen von Verzeichnissen, sowie dem Löschen und Verschieben von Dateien sind verfügbar:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="co"># Anmerkung: Der vordere &#39;/&#39; kann auch nach Belieben weggelassen werden.</span>
$ <span class="ex">brig</span> mkdir seen-movies
$ <span class="ex">brig</span> mv movies/big-buck-bunny.mov seen-movies/
$ <span class="ex">brig</span> rm seen-movies/big-buck-bunny.mov
$ <span class="ex">brig</span> tree</code></pre></div>
<h3 id="nutzung-des-fusedateisystems-brig-mountunmount"><span class="header-section-number">10.2.4</span> Nutzung des FUSE–Dateisystems (<code>brig mount/unmount</code>)</h3>
<p>Die bisherige Nutzung von <code>brig</code> erinnert an <code>git</code> und ist für alltägliche Aufgaben eher aufwendig und nicht kompatibel mit existierenden Dateimanagern. Leichter wäre es für den Benutzer wenn er seine gewohnten Anwendungen einfach weiterverwenden könnte. Das ist mit dem <em>FUSE</em>–Dateisystem möglich. Zur Verwendung muss das Dateisystem »gemounted« werden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="fu">mkdir</span> /tmp/alice-mount
$ <span class="ex">brig</span> mount /tmp/alice-mount</code></pre></div>
<p>Dies erstellt in <code>/tmp/alice-mount</code> einen speziellen Ordner, mit den bisher hinzugefügten Dateien:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="fu">ls</span> /tmp/alice-mount
<span class="ex">photos</span>  movies  knorkator</code></pre></div>
<p>Es können wie gewohnt Dateien editiert werden, gelöscht und neu angelegt werden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="fu">gimp</span> /tmp/alice-mount/photos/cat.png
$ <span class="fu">cp</span> ~/dog.png /tmp/alice-mount/photos
$ <span class="fu">rm</span> /tmp/alice/photos/dog.png</code></pre></div>
<p>Das Erstellen mehrere Mounts an verschiedenen Pfaden ist möglich. Eine Modifikation in dem einen Ordner wird stets auch im anderen Ordner angezeigt.</p>
<h3 id="versionsverwaltung-brig-statuscommitlogcheckout"><span class="header-section-number">10.2.5</span> Versionsverwaltung (<code>brig status/commit/log/checkout</code>)</h3>
<p>Alle genanten Operationen werden von <code>brig</code> im Hintergrund aufgezeichnet und versioniert. Dabei muss zwischen <em>Checkpoints</em> und <em>Commits</em> unterschieden werden. Erstere beschreiben eine atomare Änderung an einer Datei (also ob sie hinzugefügt, gelöscht, modifiziert oder verschoben wurde). Ein <em>Commit</em> fasst mehrere <em>Checkpoints</em> zu einem gemeinsamen, logischen Paket zusammen. Ähnlich wie bei <code>git</code>, gibt es zudem einen <em>Staging</em>–Bereich, der aus den <em>Checkpoints</em> besteht, die noch in keinem <em>Commit</em> verpackt worden sind. Ein wichtiger Unterschied zu <code>git</code> ist allerdings, dass <code>brig</code> auch automatisiert (in einem konfigurierten Zeitintevall) <em>Commits</em> erstellen kann. Diese dienen dann eher als Sicherungspunkte eines Repositories, beziehungsweise <em>Snapshots</em> wie in vielen Backup–Programmen und weniger als zusammenhängende Einheit logischer Änderungen.</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> status
<span class="ex">Changes</span> by alice@wonderland.lit/desktop:

  <span class="ex">Added</span>:
        <span class="ex">photos/kitten.png</span>
  <span class="ex">Removed</span>:
        <span class="ex">photos/dog.png</span>
  <span class="ex">Moved</span>:
        <span class="ex">cat.png</span> -<span class="op">&gt;</span> photos/cat.png</code></pre></div>
<p>Die gemachten Änderungen können mit dem <code>commit</code>–Unterkommando in einem <em>Commit</em> verpackt werden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> commit -m <span class="st">&#39;Moved my cat photos to the right place.&#39;</span>
<span class="ex">3</span> changes committed</code></pre></div>
<p>Die Nachricht, die man mittels <code>-m (--message)</code> angegeben hat beschreibt, was in diesem <em>Commit</em> passiert ist und taucht später als hilfreiche Beschreibung im <code>log</code> auf. Man kann diese Nachricht auch weglassen, was <code>brig</code> dazu veranlasst eine automatische <em>Commit</em>–Nachricht zu verfassen:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> stage ~/garfield-small.png /photos/garfield.png
$ <span class="ex">brig</span> commit
<span class="ex">1</span> change committed</code></pre></div>
<p>Die gemachten <em>Commits</em> lassen sich mittels des <code>log</code>–Unterkommandos anzeigen:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="co"># Zeige alle gemachten Commits an (Prüfsummen wegen Überlänge gekürzt)</span>
$ <span class="ex">brig</span> log
<span class="ex">QmNLei78zW</span> by alice, Initial commit
<span class="ex">QmPtprCMpd</span> by alice, Moved cat photos to the right place.
<span class="ex">QmZNJPSbTE</span> by alice, Update on 2016-08-11 15:33:37.651 +0200 CEST</code></pre></div>
<p>Die <em>Checkpoints</em> einer einzelnen Datei zeigt der <code>history</code>–Befehl:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> history photos/cat.png
<span class="ex">/photos/cat.png</span>
 <span class="ex">+--</span> Checkpoint <span class="co">#2 (moved by alice@jabber.nullcat.de/laptop)</span>
 <span class="kw">|</span>   <span class="ex">+-</span> Hash: Qma2Uquo9bMyuRZ7Fw1oQ1v68Vm7hpCYLRsrQXoLFpZVoK
 <span class="kw">|</span>   <span class="ex">+-</span> What: /cat.png -<span class="op">&gt;</span> /photos/cat.png
 <span class="kw">|</span>   \<span class="ex">_</span> Date: 2016-08-11 15:24:39.993907482 +0200 CEST
 \<span class="ex">--</span> Checkpoint <span class="co">#1 (added by alice@jabber.nullcat.de/laptop)</span>
     <span class="kw">|</span><span class="ex">-</span> Hash: Qma2Uquo9bMyuRZ7Fw1oQ1v68Vm7hpCYLRsrQXoLFpZVoK
     \<span class="ex">_</span> Date: 2016-08-11 15:24:15.301565687 +0200 CEST</code></pre></div>
<p>Hat man Änderungen an einer Datei gemacht und möchte diese wieder auf den letzten sauberen Stand zurücksetzen, so kann man den Befehl <code>stage</code>–Befehl benutzen:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="co"># Setze /photos/cat.png auf den letzten Stand im staging commit zurück.</span>
$ <span class="ex">brig</span> unstage /photos/cat.png</code></pre></div>
<p>Möchte man tiefer in die Vergangenheit zurück springen, so kann der <code>checkout</code>–Befehl genutzt werden. Dieser stellt entweder einen früheren Dateibaum wieder her oder setzt ein Datei oder Verzeichnis auf eine frühere Version zurück:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="co"># Setze den Stand auf den Commit QmNLei78zW zurück:</span>
$ <span class="ex">brig</span> checkout QmNLei78zW
<span class="co"># Setze nur eine einzelne Datei auf den Stand in Commit QmNLei78zW zurück:</span>
$ <span class="ex">brig</span> checkout QmNLei78zW -- /photos/cat.png</code></pre></div>
<h3 id="verwalten-von-synchronisationspartnern-brig-remote"><span class="header-section-number">10.2.6</span> Verwalten von Synchronisationspartnern (<code>brig remote</code>)</h3>
<p>Um seine Dateien mit anderen Teilnehmern zu teilen, müssen diese erst einmal <code>brig</code> bekannt gemacht werden und vom Nutzer authentifiziert werden. Für diese Aufgabe bietet <code>brig</code> das <code>remote</code>–Unterkommando. Jedes Repository hat dabei eine eindeutige »Identität«, welches es im Netzwerk eindeutig identifiziert. Diese besteht aus einer Prüfsumme, und einem menschenlesbaren Nutzernamen. Für das eigene Repository kann er folgendermaßen angezeigt werden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> remote self
<span class="ex">QmZyhL3VAAr35a9msSyhW4zfLPnx9Jn4gMSyMQR5VCBFnx</span> online alice@wonderland.lit/desktop</code></pre></div>
<p>Das Hinzufügen eines anderen Nutzers erfordert beide Werte: Sowohl sein Nutzername, als auch die kryptografische Prüfsumme, der ihn eindeutig identifiziert. Kennt man den Namen seines Kommunikationspartners, so kann <code>brig</code> alle Teilnehmer im Netzwerk mit diesen Namen abfragen. Im Beispiel möchte <code>alice</code> nun auch ein <code>brig</code>–Repository auf ihren Laptop einrichten und auf ihren Arbeitsrechner dieses als Partner eintragen:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> remote locate alice@wonderland.lit/laptop
<span class="ex">QmVszFHVNj6UYuPybU3rVXG5L6Jm6TVcvHi2ucDaAubfss</span>
<span class="ex">QmNwr8kJrnQdjwupCDLs2Fv8JknjWD7esrF81QDKT2Q2g6</span></code></pre></div>
<p>Für gewöhnlich taucht hier nur eine Prüfsumme auf, in diesem Fall muss zwischen zwei verschiedenen Identitäten gewählt werden. Mindestens eine davon könnte theoretisch ein Betrüger sein, der nur den Nutzernamen <em>alice@wonderland.lit/laptop</em> verwendet. In diesem Fall ist es nötig über einen Seitenkanal direkt Kontakt mit der Person aufzunehmen, mit der man synchronisieren will und darüber die Identität abzugleichen. Ein möglicher Seitenkanal wäre ein Telefonanruf, E–Mail oder auch ein Instant–Messanger. Hat man festgestellt was die richtige Identität ist, kann man sie seiner Kontaktliste hinzufügen:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> remote add alice@wonderland.lit/laptop \
        QmVszFHVNj6UYuPybU3rVXG5L6Jm6TVcvHi2ucDaAubfss</code></pre></div>
<p>Falls man nur den Teil hinter dem »<code>@</code>« kennt (also die <em>Domain</em>), so können auch alle Identitäten mit dieser Domain aufgelistet werden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> remote locate -d wonderland.lit
<span class="ex">QmZyhL3VAAr35a9msSyhW4zfLPnx9Jn4gMSyMQR5VCBFnx</span>
<span class="ex">QmVszFHVNj6UYuPybU3rVXG5L6Jm6TVcvHi2ucDaAubfss</span>
<span class="ex">QmNwr8kJrnQdjwupCDLs2Fv8JknjWD7esrF81QDKT2Q2g6</span></code></pre></div>
<p>Das Unterkommando »<code>brig remote list</code>« zeigt alle verfügbaren Kontakte an und ob diese online sind:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> remote list
<span class="ex">QmZyhL3VAAr35a9msSyhW4zfLPnx9Jn4gMSyMQR5VCBFnx</span> online alice@wonderland.lit/laptop</code></pre></div>
<p>Das Löschen eines Kontakts ist mit <code class="sourceCode bash"><span class="ex">brig</span> remote remove <span class="op">&lt;</span>username<span class="op">&gt;</span></code> möglich und wird nicht weiter demonstriert.</p>
<h3 id="synchronisieren-brig-sync"><span class="header-section-number">10.2.7</span> Synchronisieren (<code>brig sync</code>)</h3>
<p><em>Anmerkung zur</em> <code>git</code> <em>Analogie:</em> Es ist bei <code>brig</code> nicht nötig eine gemeinsame Synchronisations–Vergangenheit zu haben. Es wird rein auf Dateiebene synchronisiert. Mit anderen Worten: Konflikte entstehen nur dann wenn mehre Teilnehmern unterschiedliche Checkpoints für einen einzelnen Pfad einbringen. Sollten trotzdem Konflikte auftreten, wird für jede Konfliktdatei eine weitere Datei gespeichert, die mit dem Suffix <code>.&lt;owner&gt;.conflict</code> versehen wird. Hat also beispielsweise <em>Alice</em> und <em>Bob</em> eine Datei namens <code>/photos/cat.png</code> und beide haben sie modifiziert, so wird eine Synchronisation mit Alice dazu führen, dass Bob seine eigene Version <code>/photos/cat.png</code> behält, aber eine weitere Datei namens <code>/photos/cat.png.bob.conflict</code> erhält.</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> sync alice@wonderland.lit/laptop
<span class="ex">No</span> conflicts.
$ <span class="ex">brig</span> sync bob
<span class="ex">Conflict</span>: /photos/cat.png -<span class="op">&gt;</span> /photos/cat.png.bob.conflict</code></pre></div>
<h3 id="dateien-pinnen-brig-pin"><span class="header-section-number">10.2.8</span> Dateien pinnen (<code>brig pin</code>)</h3>
<p>Ist man beispielsweise mit dem Zug unterwegs, so kann ein Pfad »gepinnt« werden, um sicherzustellen dass er lokal verfügbar ist:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> pin /movies/swiss-army-man.mkv</code></pre></div>
<p>Benötigt man später wieder den Speicherplatz, so kann die Datei wieder »unpinned« werden. <code>brig</code> wird diese Datei nach einiger Zeit aus dem lokalen Zwischenspeicher entfernen, sofern ein Platzmangel vorherrscht:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> unpin /movies/swiss-army-man.mkv</code></pre></div>
<h3 id="konfiguration-brig-config"><span class="header-section-number">10.2.9</span> Konfiguration (<code>brig config</code>)</h3>
<p><code>brig</code> bietet momentan wenige Optionen, um das Verhalten der Software nach seinen Wünschen einzustellen. Ein Überblick über die verfügbaren Optionen liefert das Unterkommando <code class="sourceCode bash"><span class="ex">brig</span> config list</code>:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> config list
<span class="ex">daemon</span>:
  <span class="ex">port</span>: 6666                        <span class="co"># Der Port von brigd.</span>
<span class="ex">ipfs</span>:
  <span class="ex">path</span>: /tmp/alice/.brig/ipfs       <span class="co"># Pfad zum IPFS-Store</span>
  <span class="ex">swarmport</span>: 4001                   <span class="co"># Port des IPFS Swarm</span>
<span class="ex">repository</span>:
  <span class="ex">id</span>: alice@wonderland.lit/desktop  <span class="co"># Nutzer-ID</span></code></pre></div>
<p>Das verwendete Format zur Speicherung und Anzeige entspricht dem YAML–Format. Einzelne Werte können auch direkt angezeigt werden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> config get repository.id
<span class="ex">alice@wonderland.lit/desktop</span></code></pre></div>
<p>Möchte man die Werte editieren, so können diese einzeln gesetzt werden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> config set daemon.port 7777</code></pre></div>
<h2 id="fortgeschrittene-nutzung"><span class="header-section-number">10.3</span> Fortgeschrittene Nutzung</h2>
<p>Die obigen Befehle reichen für die alltägliche Benutzung von <code>brig</code> aus. Es gibt einige weitere Befehle, die besonders für technisch versierte Nutzer und Entwickler interessant sind.</p>
<h3 id="repository-öffnen-und-schließen-brig-openclose"><span class="header-section-number">10.3.1</span> Repository öffnen und schließen (<code>brig open/close</code>)</h3>
<p>Um ein Repository als <em>Datentresor</em> zu nutzen, kann mit dem <code>close</code>–Unterkommando der <code>brigd</code>–Daemon heruntergefahren werden. Danach ist das Repository nur mit der erneuten Eingabe eines Passwortes zugreifbar. Das kann nützlich sein, um Fremdzugriff auch bei physikalischer Abwesenheit am Rechner zu verhindern.</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> close
<span class="co"># ...Nach einiger Zeit ohne Internetzugang:</span>
$ <span class="ex">brig</span> open
<span class="ex">Password</span>: **********</code></pre></div>
<p>Ein explizites <code>brig open</code> ist bei normaler Benutzung nicht nötig. Jedes Kommando, das von <code>brigd</code> abhängt, versucht diesen zu starten, wenn der Daemon nicht erreichbar ist. Dazu fragt es wie <code class="sourceCode bash"><span class="ex">brig</span> open</code> auch nach dem Passphrase. Das <code>open</code>–Unterkommando ist allerdings nützlich für Skriptdateien, wenn der Passwort–Prompt an einer erwarteten Stelle auftauchen soll.</p>
<h3 id="status-von-brigd-brig-daemon"><span class="header-section-number">10.3.2</span> Status von <code>brigd</code> (<code>brig daemon</code>)</h3>
<p>Das <code>daemon</code>–Unterkommando bietet einige Optionen, um den Status von <code>brigd</code> zu überprüfen und zu verändern. Um zu überprüfen ob <code>brigd</code> läuft, kann das <code>ping</code>–Unterkommando genutzt werden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> daemon ping
<span class="co">#01 127.0.0.1:33024 =&gt; 127.0.0.1:6668: OK (517.310422ms)</span>
<span class="co">#02 127.0.0.1:33024 =&gt; 127.0.0.1:6668: OK (522.751µs)</span>
<span class="ex">...</span></code></pre></div>
<p>Das <code>wait</code>–Unterkommando wartet bis <code>brigd</code> verfügbar ist und Kommandos entgegen nehmen kann. Das ist für Skripte nützlich, die darauf warten müssen ohne Passwort–Prompt normale <code>brig</code>–Kommandos abzusetzen:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="bu">echo</span> <span class="st">&#39;Waiting for brig to start...&#39;</span>
$ <span class="ex">brig</span> daemon wait
$ <span class="bu">echo</span> <span class="st">&#39;Available! You can execute brig commands now.&#39;</span></code></pre></div>
<p>Auch das Starten und Beenden von <code>brigd</code> ist mit diesem Unterkommando direkt möglich:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> daemon quit    <span class="co"># Momentan selbe Funktion wie `brig close`</span>
$ <span class="ex">brig</span> daemon launch  <span class="co"># Momentan selbe Funktion wie `brig open`</span></code></pre></div>
<h3 id="netzwerkstatus-brig-net"><span class="header-section-number">10.3.3</span> Netzwerkstatus (<code>brig net</code>)</h3>
<p>Das <code>net</code>–Unterkommando bietet die Möglichkeit sich vom Netzwerk zu trennen und wieder zu verbinden:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> net status
<span class="fu">true</span>
$ <span class="ex">brig</span> net offline
$ <span class="ex">brig</span> net status
<span class="fu">false</span>
$ <span class="ex">brig</span> net online
<span class="fu">true</span></code></pre></div>
<h3 id="debugging-brig-debug"><span class="header-section-number">10.3.4</span> Debugging (<code>brig debug</code>)</h3>
<p>Unter dem <code>debug</code>–Unterkommando finden sich einige Hilfsmittel, um die internen Abläufe von <code>brig</code> nachvollziehen zu können:</p>
<ul>
<li><code>brig debug export</code>: Exportiert den aktuellen Metadatenindex auf <code>stdout</code>.</li>
<li><code>brig debug import</code>: Importiert die serialisierte Version eines Metadatenindex.</li>
</ul>
<h3 id="softwareversion-anzeigen-brig-version"><span class="header-section-number">10.3.5</span> Software–Version anzeigen (<code>brig version</code>)</h3>
<p>Die Versionsnummer von <code>brig</code> folgt den Prinzipien des <em>Semantic Versioning</em><a href="#fn169" class="footnoteRef" id="fnref169"><sup>169</sup></a> (in der Version 2.0). Das Format entspricht dabei »<code>v&lt;MAJOR&gt;.&lt;MINOR&gt;.&lt;PATCH&gt;[-&lt;TAG&gt;][+&lt;REV&gt;]</code>«, wobei die Platzhalter folgende Bedeutung haben:</p>
<ul>
<li><code>MAJOR</code>: Oberste Versionsnummer. Wird nur bei inkompatiblen Änderungen inkrementiert.</li>
<li><code>MINOR</code>: Wird bei Erweiterungen inkrementiert, welche nicht die Kompatibilität beeinflussen.</li>
<li><code>PATCH</code>: Wird bei Berichtigung einzelner Fehler jeweils einmal inkrementiert.</li>
<li><code>TAG</code>: Optional. Weist spezielle Entwicklungsstände wie <code>alpha</code>, <code>beta</code>, <code>final</code> etc. aus.</li>
<li><code>REV</code>: Optional. Falls bei Kompilierzeit verfügbar, der aktuelle <code>git</code>–HEAD.</li>
</ul>
<p>Nach der eigentlichen Versionsnummer wird zusätzlich zur Information der Kompilierzeitpunkt angezeigt:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="ex">brig</span> -v
<span class="ex">v0.1.0-alpha+cd50f68</span> [buildtime: 2016-07-28T12:55:29+0000]</code></pre></div>
<h1 id="sec:data-model"><span class="header-section-number">11</span> Anhang: Protokolldefinitionen</h1>
<h2 id="internes-datenmodell-von-brig"><span class="header-section-number">11.1</span> Internes Datenmodell von <code>brig</code></h2>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c">syntax = <span class="st">&quot;proto3&quot;</span>;
package brig.store;
option go_package = <span class="st">&quot;wire&quot;</span>;

<span class="co">///////////// VERSION CONTROL STRUCTURES ///////////</span>

message Author {
  string name = <span class="dv">1</span>;
  string hash = <span class="dv">2</span>;
}

<span class="co">// Optional merge information for merge commits</span>
message Merge {
    string with = <span class="dv">1</span>;
    bytes hash = <span class="dv">2</span>;
}

message Checkpoint {
  <span class="co">// Link to the node id:</span>
  uint64 id_link = <span class="dv">1</span>;
  bytes hash = <span class="dv">2</span>;
  uint64 index = <span class="dv">3</span>;
  int32 change = <span class="dv">4</span>;
  string author = <span class="dv">5</span>;
}

<span class="co">// History is the history of a file:</span>
message History {
    repeated Checkpoint hist = <span class="dv">1</span> [packed=false];
}

message CheckpointLink {
  uint64 id_link = <span class="dv">1</span>;
  uint64 index = <span class="dv">2</span>;
}

<span class="co">// Commits is an ordered list of commits</span>
message Commits {
    repeated Commit commits = <span class="dv">1</span>;
}

<span class="co">// Ref is a pointer to a single commit</span>
message Ref {
    string name = <span class="dv">1</span>;
    bytes hash = <span class="dv">2</span>;
}

<span class="co">////////////// NODE BASICS /////////////</span>

<span class="co">// Might be extended with more esoteric types in the future.</span>
<span class="kw">enum</span> NodeType {
  UNKNOWN = <span class="dv">0</span>;
  FILE = <span class="dv">1</span>;
  DIRECTORY = <span class="dv">2</span>;
  COMMIT = <span class="dv">3</span>;
}

<span class="co">// An Object is a container for a file, a directory or a Ref.</span>
message Node {
  <span class="co">// Type of this node (see above)</span>
  NodeType type = <span class="dv">1</span>;
  <span class="co">// Global identifier of this node, since hash and path</span>
  <span class="co">// might change sometimes.</span>
  uint64 ID = <span class="dv">2</span>;

  <span class="co">// Size of the node in bytes:</span>
  uint64 node_size = <span class="dv">3</span>;

  <span class="co">// Timestamp formated as RFC 3339</span>
  bytes mod_time = <span class="dv">4</span>;

  <span class="co">// Hash of the node as multihash:</span>
  bytes hash = <span class="dv">5</span>;

  <span class="co">// Name of this node (i.e. path element)</span>
  string name = <span class="dv">6</span>;

  <span class="co">// Path must only be filled when exported to a client.</span>
  <span class="co">// It may not be used internally and is not saved to the kv-store.</span>
  string path = <span class="dv">7</span>;

  <span class="co">// Individual types:</span>
  File file = <span class="dv">8</span>;
  Directory directory = <span class="dv">9</span>;
  Commit commit = <span class="dv">10</span>;
}

<span class="co">// Just a collection of nodes:</span>
message Nodes {
  repeated Node nodes = <span class="dv">1</span>;
}

<span class="co">////////////// CONCRETE NODES /////////////</span>

message File {
  <span class="co">// Path to parent directory</span>
  string parent = <span class="dv">1</span>;

  <span class="co">// Key of this file:</span>
  bytes key = <span class="dv">2</span>;
}

message Directory {
  <span class="co">// Path to parent object:</span>
  string parent = <span class="dv">1</span>;

  <span class="co">// Directory contents (hashtable contents [name =&gt; link]):</span>
  repeated bytes links = <span class="dv">2</span>;
  repeated string names = <span class="dv">3</span>;
}

<span class="co">// Commit is a bag of changes, either automatically done or by the user.</span>
message Commit {
  <span class="co">// Hash of the parent commit:</span>
  bytes parent = <span class="dv">1</span>;

  <span class="co">// Commit message:</span>
  string message = <span class="dv">2</span>;

  <span class="co">// Author of this commit:</span>
  Author author = <span class="dv">3</span>;

  <span class="co">// Hash to the root tree:</span>
  bytes root = <span class="dv">4</span>;

  <span class="co">// List of checkpoints (one per file):</span>
  repeated CheckpointLink changeset = <span class="dv">5</span>;

  <span class="co">// Merge information if this is a merge commit.</span>
  Merge merge = <span class="dv">6</span>;

  <span class="co">// Checkpoints stored in the commit.</span>
  <span class="co">// This is only used when exported to the client,</span>
  <span class="co">// it is not stored in the kv-store.</span>
  repeated Checkpoint checkpoints = <span class="dv">7</span>;
}

<span class="co">//////////// EXPORT/IMPORT DATA //////////////</span>

<span class="co">// Store is the exported form of a store.</span>
message Store {
  <span class="co">// The boltdb format.</span>
  bytes boltdb = <span class="dv">1</span>;
}</code></pre></div>
<h2 id="sec:rpc-proto"><span class="header-section-number">11.2</span> Protokoll zwischen zwei Knoten</h2>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c">syntax = <span class="st">&quot;proto3&quot;</span>;
package brig.transfer;
option go_package = <span class="st">&quot;wire&quot;</span>;

import <span class="st">&quot;store.proto&quot;</span>;

<span class="kw">enum</span> RequestType {
    INVALID = <span class="dv">0</span>;
    FETCH = <span class="dv">1</span>;
    STORE_VERSION = <span class="dv">2</span>;
    UPDATE_FILE = <span class="dv">3</span>;
}

message Request {
    RequestType req_type = <span class="dv">1</span>;
    int64 ID = <span class="dv">2</span>;
    int64 nonce = <span class="dv">3</span>;
}

message StoreVersionResponse {
    int32 version = <span class="dv">1</span>;
}

message FetchResponse {
    brig.store.Store store = <span class="dv">1</span>;
}

message Response {
    RequestType req_type = <span class="dv">1</span>;
    int64 ID = <span class="dv">2</span>;
    int64 nonce = <span class="dv">3</span>;
    string error = <span class="dv">4</span>;

    StoreVersionResponse store_version_resp = <span class="dv">5</span>;
    FetchResponse fetch_resp = <span class="dv">6</span>;
}</code></pre></div>
<h1 id="sec:appendix-benchmarks"><span class="header-section-number">12</span> Anhang: Benchmark–Skripte</h1>
<h2 id="benchmark.sh"><span class="header-section-number">12.1</span> <code>benchmark.sh</code></h2>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="co">#!/bin/sh</span>

<span class="fu">rm</span> data/ipfs -rf
<span class="bu">export</span> <span class="va">IPFS_PATH=</span>./data/ipfs
<span class="bu">export</span> <span class="va">BRIG_PATH=</span>./data/brig
<span class="ex">ipfs</span> init


<span class="kw">function</span><span class="fu"> time_it()</span> <span class="kw">{</span>
    <span class="va">ts=$(</span><span class="fu">date</span> +%s%N<span class="va">)</span>
    <span class="va">$*</span>
    <span class="va">tt=$((</span>(<span class="va">$(</span><span class="fu">date</span> +%s%N<span class="va">)</span> - <span class="va">$ts</span>)/1000000<span class="va">))</span>
    <span class="op">&gt;&amp;2</span> <span class="bu">echo</span> <span class="st">&quot;Time taken: </span><span class="va">$tt</span><span class="st">&quot;</span>

<span class="kw">}</span>

<span class="kw">function</span><span class="fu"> create_ramfs()</span> <span class="kw">{</span>
    <span class="fu">mkdir</span> -p data
    <span class="fu">sudo</span> mount -t ramfs -o size=2G ramfs data
    <span class="fu">sudo</span> chmod 0777 data
    <span class="fu">sudo</span> chown -R sahib:users data
<span class="kw">}</span>

<span class="kw">function</span><span class="fu"> copy_sized()</span> <span class="kw">{</span>
    <span class="bu">echo</span> <span class="st">&quot;Copying </span><span class="va">$3</span><span class="st"> MB of </span><span class="va">$1</span><span class="st"> to </span><span class="va">$2</span><span class="st">&quot;</span>
    <span class="fu">dd</span> if=<span class="st">&quot;</span><span class="va">$1</span><span class="st">&quot;</span> of=<span class="st">&quot;</span><span class="va">$2</span><span class="st">&quot;</span> bs=1M count=<span class="st">&quot;</span><span class="va">$3</span><span class="st">&quot;</span> status=none
<span class="kw">}</span>

<span class="co">##### write functions:</span>

<span class="kw">function</span><span class="fu"> compress_to_ipfs()</span> <span class="kw">{</span>
    <span class="ex">./main</span> -f -a <span class="va">$2</span> <span class="va">$3</span> -s -c <span class="va">$1</span> <span class="kw">|</span> <span class="ex">ipfs</span> add -q <span class="op">&gt;</span> /dev/null
<span class="kw">}</span>

<span class="kw">function</span><span class="fu"> compress_single()</span> <span class="kw">{</span>
    <span class="ex">./main</span> -f -D -a <span class="va">$2</span> <span class="va">$3</span> -c <span class="va">$1</span>
<span class="kw">}</span>

<span class="kw">function</span><span class="fu"> add_to_ipfs()</span> <span class="kw">{</span>
    <span class="ex">ipfs</span> add -q <span class="va">$1</span>
<span class="kw">}</span>

<span class="kw">function</span><span class="fu"> baseline_write()</span> <span class="kw">{</span>
    <span class="ex">time_it</span> cat <span class="va">$1</span> <span class="op">&gt;</span> /dev/null
<span class="kw">}</span>

<span class="co">##### read functions:</span>

<span class="kw">function</span><span class="fu"> compress_to_ipfs_and_read()</span> <span class="kw">{</span>
    <span class="va">HASH=$(</span><span class="ex">./main</span> -f -a <span class="va">$2</span> <span class="va">$3</span> -s -c <span class="va">$1</span> <span class="kw">|</span> <span class="ex">ipfs</span> add -q<span class="va">)</span>
    <span class="ex">ipfs</span> cat <span class="va">$HASH</span> <span class="kw">|</span> <span class="ex">time_it</span> ./main -f -a <span class="va">$2</span> <span class="va">$3</span> -d <span class="va">$1</span>.<span class="va">$2</span>
<span class="kw">}</span>

<span class="kw">function</span><span class="fu"> compress_single_and_read()</span> <span class="kw">{</span>
    <span class="ex">./main</span> -f -a <span class="va">$2</span> <span class="va">$3</span> -c <span class="va">$1</span>
    <span class="ex">time_it</span> ./main -f -a <span class="va">$2</span> <span class="va">$3</span> -d <span class="va">$1</span>.<span class="va">$2</span>
<span class="kw">}</span>

<span class="kw">function</span><span class="fu"> add_to_ipfs_and_read()</span> <span class="kw">{</span>
    <span class="va">HASH=</span><span class="kw">`</span><span class="ex">ipfs</span> add -q <span class="va">$1</span><span class="kw">`</span>
    <span class="ex">time_it</span> ipfs cat <span class="va">$HASH</span> <span class="op">&gt;</span> /dev/null
<span class="kw">}</span>

<span class="kw">function</span><span class="fu"> baseline_read()</span> <span class="kw">{</span>
    <span class="ex">time_it</span> dd if=<span class="va">$1</span> of=/dev/null bs=4M status=none
<span class="kw">}</span>

<span class="co"># Init:</span>
<span class="ex">create_ramfs</span>
<span class="va">size=</span>1
<span class="kw">for</span> <span class="ex">i</span> in <span class="kw">`</span><span class="fu">seq</span> 10<span class="kw">`;</span> <span class="kw">do</span>
    <span class="ex">copy_sized</span> <span class="st">&quot;input/movie.mp4&quot;</span> <span class="st">&quot;data/movie_</span><span class="va">$size</span><span class="st">&quot;</span> <span class="va">$size</span>
    <span class="ex">copy_sized</span> <span class="st">&quot;input/archive.tar&quot;</span> <span class="st">&quot;data/archive_</span><span class="va">$size</span><span class="st">&quot;</span> <span class="va">$size</span>
    <span class="va">size=$(</span><span class="fu">expr</span> <span class="va">$size</span> <span class="dt">\*</span> 2<span class="va">)</span>
<span class="kw">done</span>

<span class="kw">function</span><span class="fu"> sample()</span> <span class="kw">{</span>
    <span class="bu">echo</span> <span class="st">&quot;=== </span><span class="va">$*</span><span class="st">&quot;</span>
    <span class="bu">local</span> <span class="va">size=</span>1
    <span class="kw">for</span> <span class="ex">i</span> in <span class="kw">`</span><span class="fu">seq</span> 10<span class="kw">`;</span> <span class="kw">do</span>
        <span class="va">$1</span> <span class="st">&quot;data/archive_</span><span class="va">$size</span><span class="st">&quot;</span> <span class="va">$2</span> <span class="va">$3</span> <span class="va">$4</span> <span class="va">$5</span> <span class="va">$6</span>
        <span class="va">size=$(</span><span class="fu">expr</span> <span class="va">$size</span> <span class="dt">\*</span> 2<span class="va">)</span>
    <span class="kw">done</span>

    <span class="fu">rm</span> data/*.<span class="va">$2</span> -f
<span class="kw">}</span>

<span class="ex">sample</span> baseline_read
<span class="ex">sample</span> add_to_ipfs
<span class="ex">sample</span> compress_single_and_read snappy
<span class="ex">sample</span> compress_single_and_read none -e
<span class="ex">sample</span> compress_single_and_read snappy -e
<span class="ex">sample</span> compress_to_ipfs snappy
<span class="ex">sample</span> compress_to_ipfs snappy -e

<span class="kw">function</span><span class="fu"> create_brig_repo()</span> <span class="kw">{</span>
    <span class="ex">pkill</span> -9 brig
    <span class="fu">rm</span> data/brig -rf
    <span class="ex">brig</span> -x ThiuJ9wesh --nodaemon init alice@jabber.nullcat.de/laptop
    <span class="ex">brig</span> -x ThiuJ9wesh daemon launch <span class="op">2&gt;</span>/dev/null <span class="kw">&amp;</span>
    <span class="bu">echo</span> <span class="st">&quot;...waiting for daemon to catch up...&quot;</span>
    <span class="fu">sleep</span> 5
    <span class="ex">fusermount</span> -u data/mount
    <span class="fu">mkdir</span> -p data/mount
    <span class="ex">brig</span> mount data/mount
<span class="kw">}</span>


<span class="ex">create_brig_repo</span>
<span class="va">size=</span>1
<span class="kw">for</span> <span class="ex">i</span> in <span class="kw">`</span><span class="fu">seq</span> 10<span class="kw">`;</span> <span class="kw">do</span>
    <span class="ex">time_it</span> brig stage <span class="st">&quot;data/archive_</span><span class="va">$size</span><span class="st">&quot;</span>
    <span class="ex">time_it</span> brig cat <span class="st">&quot;archive_</span><span class="va">$size</span><span class="st">&quot;</span> /dev/null
    <span class="ex">time_it</span> dd if=<span class="st">&quot;data/mount/archive_</span><span class="va">$size</span><span class="st">&quot;</span> of=/dev/null bs=4M status=none
    <span class="va">size=$(</span><span class="fu">expr</span> <span class="va">$size</span> <span class="dt">\*</span> 2<span class="va">)</span>
<span class="kw">done</span></code></pre></div>
<h2 id="plot_results.sh"><span class="header-section-number">12.2</span> <code>plot_results.sh</code></h2>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co">#!/usr/bin/env python3</span>
<span class="co">#encoding: utf8</span>

BASELINE_TIME <span class="op">=</span> [<span class="dv">3</span>, <span class="dv">7</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">22</span>, <span class="dv">32</span>, <span class="dv">58</span>, <span class="dv">114</span>, <span class="dv">201</span>]

<span class="co"># movie write</span>

MOVIE_COMPRESS_SINGLE <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">12</span>, <span class="dv">30</span>, <span class="dv">50</span>, <span class="dv">102</span>, <span class="dv">220</span>, <span class="dv">359</span>, <span class="dv">744</span>]
MOVIE_ENCRYPT_SINGLE <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">16</span>, <span class="dv">19</span>, <span class="dv">31</span>, <span class="dv">89</span>, <span class="dv">194</span>, <span class="dv">367</span>, <span class="dv">692</span>, <span class="dv">1417</span>, <span class="dv">2926</span>, <span class="dv">5727</span>]
MOVIE_ENCRYPT_PLUS_COMPRESS <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">9</span>, <span class="dv">25</span>, <span class="dv">45</span>, <span class="dv">108</span>, <span class="dv">234</span>, <span class="dv">401</span>, <span class="dv">794</span>, <span class="dv">1668</span>, <span class="dv">3417</span>, <span class="dv">6900</span>]
MOVIE_TILL_IPFS <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">20</span>, <span class="dv">51</span>, <span class="dv">86</span>, <span class="dv">208</span>, <span class="dv">428</span>, <span class="dv">821</span>, <span class="dv">1650</span>, <span class="dv">3227</span>, <span class="dv">6473</span>, <span class="dv">12943</span>]
MOVIE_IPFS_RAW <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">59</span>, <span class="dv">84</span>, <span class="dv">100</span>, <span class="dv">152</span>, <span class="dv">221</span>, <span class="dv">378</span>, <span class="dv">648</span>, <span class="dv">1223</span>, <span class="dv">2328</span>, <span class="dv">4625</span>]
MOVIE_BRIG_ADD <span class="op">=</span>  <span class="op">\</span>
    [<span class="dv">338</span>, <span class="dv">363</span>, <span class="dv">397</span>, <span class="dv">495</span>, <span class="dv">634</span>, <span class="dv">1279</span>, <span class="dv">2629</span>, <span class="dv">4028</span>, <span class="dv">7239</span>, <span class="dv">13910</span>]

PLOT_MOVIE_WRITE <span class="op">=</span> {
    <span class="st">&#39;short&#39;</span>: <span class="st">&#39;movie_write.svg&#39;</span>,
    <span class="co">&#39;title&#39;</span>: <span class="st">&#39;Throughput of encryption, compression and stacked (movie.mp4)&#39;</span>,
    <span class="co">&#39;names&#39;</span>: [
        (<span class="st">&#39;baseline&#39;</span>, BASELINE_TIME),
        (<span class="st">&#39;only compress&#39;</span>, MOVIE_COMPRESS_SINGLE),
        (<span class="st">&#39;only encrypt&#39;</span>, MOVIE_ENCRYPT_SINGLE),
        (<span class="st">&#39;encrypt/compress&#39;</span>, MOVIE_ENCRYPT_PLUS_COMPRESS),
        (<span class="st">&#39;ipfs add&#39;</span>, MOVIE_IPFS_RAW),
        (<span class="st">&#39;ipfs add/encrypt/zip&#39;</span>, MOVIE_TILL_IPFS),
        (<span class="st">&#39;brig stage&#39;</span>, MOVIE_BRIG_ADD),
    ]
}

<span class="co"># movie read</span>

MOVIE_DECOMPRESS <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">82</span>, <span class="dv">825</span>, <span class="dv">928</span>, <span class="dv">1202</span>, <span class="dv">1221</span>, <span class="dv">1244</span>, <span class="dv">2213</span>, <span class="dv">3236</span>, <span class="dv">5282</span>, <span class="dv">22059</span>]
MOVIE_DECRYPT <span class="op">=</span>  <span class="op">\</span>
    [<span class="dv">85</span>, <span class="dv">110</span>, <span class="dv">126</span>, <span class="dv">171</span>, <span class="dv">234</span>, <span class="dv">376</span>, <span class="dv">738</span>, <span class="dv">1414</span>, <span class="dv">2693</span>, <span class="dv">6229</span>]
MOVIE_IPFS_CAT_AND_DECRYPT_DECOMPRESS <span class="op">=</span>  <span class="op">\</span>
    [<span class="dv">105</span>, <span class="dv">118</span>, <span class="dv">137</span>, <span class="dv">194</span>, <span class="dv">290</span>, <span class="dv">481</span>, <span class="dv">892</span>, <span class="dv">1692</span>, <span class="dv">3121</span>, <span class="dv">6303</span>]
MOVIE_IPFS_CAT <span class="op">=</span>  <span class="op">\</span>
    [<span class="dv">75</span>, <span class="dv">89</span>, <span class="dv">109</span>, <span class="dv">136</span>, <span class="dv">192</span>, <span class="dv">321</span>, <span class="dv">582</span>, <span class="dv">1059</span>, <span class="dv">2019</span>, <span class="dv">3956</span>]
MOVIE_BRIG_CAT <span class="op">=</span>  <span class="op">\</span>
    [<span class="dv">331</span>, <span class="dv">355</span>, <span class="dv">375</span>, <span class="dv">471</span>, <span class="dv">637</span>, <span class="dv">972</span>, <span class="dv">1888</span>, <span class="dv">2887</span>, <span class="dv">4005</span>, <span class="dv">6932</span>]
MOVIE_FUSE_CAT <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">147</span>, <span class="dv">245</span>, <span class="dv">464</span>, <span class="dv">760</span>, <span class="dv">1598</span>, <span class="dv">2783</span>, <span class="dv">6009</span>, <span class="dv">11861</span>, <span class="dv">24226</span>, <span class="dv">50311</span>]

PLOT_MOVIE_READ <span class="op">=</span> {
    <span class="st">&#39;short&#39;</span>: <span class="st">&#39;movie_read.svg&#39;</span>,
    <span class="co">&#39;title&#39;</span>: <span class="st">&#39;Throughput of decryption, decompression &amp; more (movie.mp4)&#39;</span>,
    <span class="co">&#39;names&#39;</span>: [
        (<span class="st">&#39;baseline&#39;</span>, BASELINE_TIME),
        (<span class="st">&#39;only decompress&#39;</span>, MOVIE_DECOMPRESS),
        (<span class="st">&#39;only decrypt&#39;</span>, MOVIE_DECRYPT),
        (<span class="st">&#39;both&#39;</span>, MOVIE_IPFS_CAT_AND_DECRYPT_DECOMPRESS),
        (<span class="st">&#39;ipfs cat&#39;</span>, MOVIE_IPFS_CAT),
        (<span class="st">&#39;brig cat&#39;</span>, MOVIE_BRIG_CAT),
        (<span class="st">&#39;fuse cat&#39;</span>, MOVIE_FUSE_CAT),
    ]
}

<span class="co"># =====================</span>

<span class="co"># Archive write</span>
ARCHIVE_COMPRESS_SINGLE <span class="op">=</span>  <span class="op">\</span>
    [<span class="dv">6</span>, <span class="dv">15</span>, <span class="dv">21</span>, <span class="dv">45</span>, <span class="dv">73</span>, <span class="dv">157</span>, <span class="dv">329</span>, <span class="dv">551</span>, <span class="dv">1251</span>, <span class="dv">3003</span>]
ARCHIVE_ENCRYPT_SINGLE <span class="op">=</span>  <span class="op">\</span>
    [<span class="dv">16</span>, <span class="dv">34</span>, <span class="dv">40</span>, <span class="dv">91</span>, <span class="dv">204</span>, <span class="dv">343</span>, <span class="dv">694</span>, <span class="dv">1437</span>, <span class="dv">2879</span>, <span class="dv">5667</span>]
ARCHIVE_ENCRYPT_PLUS_COMPRESS <span class="op">=</span>  <span class="op">\</span>
    [<span class="dv">18</span>, <span class="dv">16</span>, <span class="dv">50</span>, <span class="dv">99</span>, <span class="dv">181</span>, <span class="dv">304</span>, <span class="dv">671</span>, <span class="dv">1257</span>, <span class="dv">2904</span>, <span class="dv">6701</span>]
ARCHIVE_TILL_IPFS <span class="op">=</span>  <span class="op">\</span>
    [<span class="dv">9</span>, <span class="dv">33</span>, <span class="dv">74</span>, <span class="dv">146</span>, <span class="dv">307</span>, <span class="dv">533</span>, <span class="dv">992</span>, <span class="dv">1978</span>, <span class="dv">4498</span>, <span class="dv">10492</span>]
ARCHIVE_IPFS_RAW <span class="op">=</span>  <span class="op">\</span>
    [<span class="dv">75</span>, <span class="dv">87</span>, <span class="dv">111</span>, <span class="dv">154</span>, <span class="dv">205</span>, <span class="dv">346</span>, <span class="dv">666</span>, <span class="dv">1209</span>, <span class="dv">2357</span>, <span class="dv">4616</span>]
ARCHIVE_BRIG_ADD <span class="op">=</span>  <span class="op">\</span>
    [<span class="dv">325</span>, <span class="dv">350</span>, <span class="dv">380</span>, <span class="dv">423</span>, <span class="dv">546</span>, <span class="dv">926</span>, <span class="dv">1455</span>, <span class="dv">2749</span>, <span class="dv">5380</span>, <span class="dv">12683</span>]

PLOT_ARCHIVE_WRITE <span class="op">=</span> {
    <span class="st">&#39;short&#39;</span>: <span class="st">&#39;archive_write.svg&#39;</span>,
    <span class="co">&#39;title&#39;</span>: <span class="st">&#39;Throughput of encryption, compression and stacked (archive.tar)&#39;</span>,
    <span class="co">&#39;names&#39;</span>: [
        (<span class="st">&#39;baseline&#39;</span>, BASELINE_TIME),
        (<span class="st">&#39;only compress&#39;</span>, ARCHIVE_COMPRESS_SINGLE),
        (<span class="st">&#39;only encrypt&#39;</span>, ARCHIVE_ENCRYPT_SINGLE),
        (<span class="st">&#39;encrypt/compress&#39;</span>, ARCHIVE_ENCRYPT_PLUS_COMPRESS),
        (<span class="st">&#39;ipfs add&#39;</span>, ARCHIVE_IPFS_RAW),
        (<span class="st">&#39;ipfs add/encrypt/zip&#39;</span>, ARCHIVE_TILL_IPFS),
        (<span class="st">&#39;brig stage&#39;</span>, ARCHIVE_BRIG_ADD),
    ]
}

ARCHIVE_DECOMPRESS <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">84</span>, <span class="dv">82</span>, <span class="dv">96</span>, <span class="dv">108</span>, <span class="dv">133</span>, <span class="dv">182</span>, <span class="dv">271</span>, <span class="dv">467</span>, <span class="dv">957</span>, <span class="dv">2100</span>]
ARCHIVE_DECRYPT <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">99</span>, <span class="dv">91</span>, <span class="dv">125</span>, <span class="dv">153</span>, <span class="dv">233</span>, <span class="dv">381</span>, <span class="dv">676</span>, <span class="dv">1342</span>, <span class="dv">2525</span>, <span class="dv">4990</span>]
ARCHIVE_IPFS_CAT_AND_DECRYPT_DECOMPRESS <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">110</span>, <span class="dv">115</span>, <span class="dv">137</span>, <span class="dv">181</span>, <span class="dv">254</span>, <span class="dv">392</span>, <span class="dv">698</span>, <span class="dv">1406</span>, <span class="dv">2644</span>, <span class="dv">5163</span>]
ARCHIVE_IPFS_CAT <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">76</span>, <span class="dv">91</span>, <span class="dv">95</span>, <span class="dv">130</span>, <span class="dv">202</span>, <span class="dv">330</span>, <span class="dv">573</span>, <span class="dv">1077</span>, <span class="dv">2033</span>, <span class="dv">3904</span>]
ARCHIVE_BRIG_CAT <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">349</span>, <span class="dv">341</span>, <span class="dv">354</span>, <span class="dv">402</span>, <span class="dv">517</span>, <span class="dv">715</span>, <span class="dv">1093</span>, <span class="dv">1928</span>, <span class="dv">3160</span>, <span class="dv">5961</span>]
ARCHIVE_FUSE_CAT <span class="op">=</span> <span class="op">\</span>
    [<span class="dv">104</span>, <span class="dv">231</span>, <span class="dv">319</span>, <span class="dv">688</span>, <span class="dv">956</span>, <span class="dv">2817</span>, <span class="dv">5078</span>, <span class="dv">9613</span>, <span class="dv">18996</span>, <span class="dv">42485</span>]

PLOT_ARCHIVE_READ <span class="op">=</span> {
    <span class="st">&#39;short&#39;</span>: <span class="st">&#39;archive_read.svg&#39;</span>,
    <span class="co">&#39;title&#39;</span>: <span class="st">&#39;Throughput of decryption, decompression &amp; more (archive.tar)&#39;</span>,
    <span class="co">&#39;names&#39;</span>: [
        (<span class="st">&#39;baseline&#39;</span>, BASELINE_TIME),
        (<span class="st">&#39;only decompress&#39;</span>, ARCHIVE_DECOMPRESS),
        (<span class="st">&#39;only decrypt&#39;</span>, ARCHIVE_DECRYPT),
        (<span class="st">&#39;both&#39;</span>, ARCHIVE_IPFS_CAT_AND_DECRYPT_DECOMPRESS),
        (<span class="st">&#39;ipfs cat&#39;</span>, ARCHIVE_IPFS_CAT),
        (<span class="st">&#39;brig cat&#39;</span>, ARCHIVE_BRIG_CAT),
        (<span class="st">&#39;fuse cat&#39;</span>, ARCHIVE_FUSE_CAT),
    ]
}

<span class="im">import</span> pygal
<span class="im">import</span> pygal.style


<span class="kw">def</span> render_plot(data, logarithmic<span class="op">=</span><span class="va">False</span>):
    line_chart <span class="op">=</span> pygal.Line(
        legend_at_bottom<span class="op">=</span><span class="va">True</span>,
        logarithmic<span class="op">=</span>logarithmic,
        style<span class="op">=</span>pygal.style.LightSolarizedStyle,
        interpolate<span class="op">=</span><span class="st">&#39;cubic&#39;</span>
    )
    line_chart.title <span class="op">=</span> data[<span class="st">&#39;title&#39;</span>]
    line_chart.x_labels <span class="op">=</span> [<span class="st">&#39;</span><span class="sc">{}</span><span class="st"> MB&#39;</span>.<span class="bu">format</span>(<span class="dv">2</span> <span class="op">**</span> idx) <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">10</span>)]
    line_chart.x_title <span class="op">=</span> <span class="st">&quot;Input size in MB&quot;</span>
    line_chart.y_title <span class="op">=</span> <span class="st">&quot;Time in milliseconds&quot;</span>
    <span class="cf">for</span> name, points <span class="kw">in</span> data[<span class="st">&#39;names&#39;</span>]:
        line_chart.add(name, points)

    line_chart.render_to_file(data[<span class="st">&#39;short&#39;</span>])


render_plot(PLOT_MOVIE_WRITE, logarithmic<span class="op">=</span><span class="va">True</span>)
render_plot(PLOT_MOVIE_READ, logarithmic<span class="op">=</span><span class="va">True</span>)
render_plot(PLOT_ARCHIVE_WRITE, logarithmic<span class="op">=</span><span class="va">True</span>)
render_plot(PLOT_ARCHIVE_READ, logarithmic<span class="op">=</span><span class="va">True</span>)</code></pre></div>
<h1 id="sec:cd-content"><span class="header-section-number">13</span> Anhang: Inhalt des Datenträgers</h1>
<p>Der Datenträger zu dieser Arbeit enthält folgende Dateien und Verzeichnisse:</p>
<hr />
<ul>
<li><code>./brig/</code>: Enthält das <code>git</code>–Repository von <code>brig</code> zum Abgabezeitpunkt (<code>git-rev</code>: <code>fa9bb63</code>).</li>
<li><code>./brig-vendor/</code>: Enthält ein <code>git</code>–Repository mit allen Abhängigkeiten zu <code>brig</code>.</li>
<li><code>./brig-thesis/</code>: Die Quellen, die zum Erzeugen des vorliegenden Dokuments nötig sind.</li>
<li><code>./thesis.pdf</code>: Das vorliegende Dokument im PDF–Format.</li>
<li><code>./thesis-twoside.pdf</code>: Eine Version von <code>thesis.pdf</code>, die sich für beidseitigen Druck eignet.</li>
<li><code>./html-thesis/</code>: HTML–Version des vorliegenden Dokuments.</li>
<li><code>README.txt</code>: Der Inhalt dieser Seite in Textform.</li>
</ul>
<hr />
<p>Diese Arbeit ist zudem online in einer rudimentären HTML–Version und als PDF verfügbar:</p>
<ul>
<li><em>HTML, einseitig:</em> <a href="https://disorganizer.github.io/brig-thesis/brig/html/index.html" class="uri">https://disorganizer.github.io/brig-thesis/brig/html/index.html</a></li>
<li><em>PDF:</em> <a href="https://disorganizer.github.io/brig-thesis/brig/thesis.pdf" class="uri">https://disorganizer.github.io/brig-thesis/brig/thesis.pdf</a></li>
</ul>
<p>Alle Diagramme wurden mit dem Online–Diagrammeditor <em>Lucidchart</em> gezeichnet, welcher für Studenten kostenlos nutzbar ist. Die eigentliche Arbeit wurde mit dem Editor »<code>neovim</code><a href="#fn170" class="footnoteRef" id="fnref170"><sup>170</sup></a>« in <em>Pandoc–Markdown</em> verfasst und mittels »<code>pandoc</code>« zu  kompiliert. Dies wurde schließlich mit dem <code>pdfTeX</code>–Backend zum vorliegenden Dokument gewandelt.</p>
<h1 id="literaturverzeichnis" class="unnumbered">Literaturverzeichnis</h1>
<div id="refs" class="references">
<div id="ref-go_programming_language">
<p>[1] Alan A. A. Donovan, B.W.K. 2015. <em>The go programming language</em>. Addison-Wesley.</p>
</div>
<div id="ref-baumgart2007s">
<p>[2] Baumgart, I. and Mies, S. 2007. S/kademlia: A practicable approach towards secure key-based routing. <em>Parallel and distributed systems, 2007 international conference on</em> (2007), 1–8.</p>
</div>
<div id="ref-bellare2000authenticated">
<p>[3] Bellare, M. and Namprempre, C. 2000. Authenticated encryption: Relations among notions and analysis of the generic composition paradigm. <em>International conference on the theory and application of cryptology and information security</em> (2000), 531–545.</p>
</div>
<div id="ref-benet2014ipfs">
<p>[4] Benet, J. 2014. Ipfs-content addressed, versioned, p2p file system. <em>arXiv preprint arXiv:1407.3561</em>. (2014).</p>
</div>
<div id="ref-1999standard">
<p>[5] Board, I.-S.S. ed. 1999. <em>IEEE standard for information technology-portable operating system interface (posix)-part 1: System application program interface (api)- amendment d: Additional real time extensions [c language]</em>.</p>
</div>
<div id="ref-borg2015syncthing">
<p>[6] Borg, J. 2015. SyncThing: Block exchange protocol (2015).</p>
</div>
<div id="ref-wiki:brotli">
<p>[7] Brotli — wikipedia, die freie enzyklopädie: 2016. <em><a href="https://de.wikipedia.org/w/index.php?title=Brotli&amp;oldid=154905741" class="uri">https://de.wikipedia.org/w/index.php?title=Brotli&amp;oldid=154905741</a></em>.</p>
</div>
<div id="ref-conway1963design">
<p>[8] Conway, M.E. 1963. Design of a separable transition-diagram compiler. <em>Communications of the ACM</em>. 6, 7 (1963), 396–408.</p>
</div>
<div id="ref-cox2005file">
<p>[9] Cox, R. and Josephson, W. 2005. File synchronization with vector time pairs. (2005).</p>
</div>
<div id="ref-douceur2002reclaiming">
<p>[10] Douceur, J.R., Adya, A., Bolosky, W.J., Simon, P. and Theimer, M. 2002. Reclaiming space from duplicate files in a serverless distributed file system. <em>Distributed computing systems, 2002. proceedings. 22nd international conference on</em> (2002), 617–624.</p>
</div>
<div id="ref-statistaDownload">
<p>[11] Durchschnittliche verbindungsgeschwindigkeit der internetanschlüsse in deutschland vom 3. quartal 2007 bis zum 1. quartal 2016 (in kbit/s): 2016. <em><a href="https://de.statista.com/statistik/daten/studie/416534/umfrage/durchschnittliche-internetgeschwindigkeit-in-deutschland" class="uri">https://de.statista.com/statistik/daten/studie/416534/umfrage/durchschnittliche-internetgeschwindigkeit-in-deutschland</a></em>.</p>
</div>
<div id="ref-freed1996multipurpose">
<p>[12] Freed, N. and Borenstein, N. 1996. <em>Multipurpose internet mail extensions (mime) part two: Media types</em>.</p>
</div>
<div id="ref-freedman2004democratizing">
<p>[13] Freedman, M.J., Freudenthal, E. and Mazieres, D. 2004. Democratizing content publication with coral. <em>NSDI</em> (2004), 18–18.</p>
</div>
<div id="ref-karp1987efficient">
<p>[14] Karp, R.M. and Rabin, M.O. 1987. Efficient randomized pattern-matching algorithms. <em>IBM Journal of Research and Development</em>. 31, 2 (1987), 249–260.</p>
</div>
<div id="ref-lin2010secure">
<p>[15] Lin, H.-Y. and Tzeng, W.-G. 2010. A secure decentralized erasure code for distributed networked storage. <em>IEEE transactions on Parallel and Distributed Systems</em>. 21, 11 (2010), 1586–1594.</p>
</div>
<div id="ref-wiki:lz4">
<p>[16] LZ4 — wikipedia, die freie enzyklopädie: 2016. <em><a href="https://de.wikipedia.org/w/index.php?title=LZ4&amp;oldid=155946163" class="uri">https://de.wikipedia.org/w/index.php?title=LZ4&amp;oldid=155946163</a></em>.</p>
</div>
<div id="ref-statistaFragOS">
<p>[17] Marktanteile der führenden betriebssystemversionen weltweit von januar 2009 bis juli 2016: 2016. <em><a href="https://de.statista.com/statistik/daten/studie/157902/umfrage/marktanteil-der-genutzten-betriebssysteme-weltweit-seit-2009" class="uri">https://de.statista.com/statistik/daten/studie/157902/umfrage/marktanteil-der-genutzten-betriebssysteme-weltweit-seit-2009</a></em>.</p>
</div>
<div id="ref-everyday_crypto">
<p>[18] Martin, K.M. 2012. <em>Everyday cryptography</em>. Oxford University Press.</p>
</div>
<div id="ref-maymounkov2002kademlia">
<p>[19] Maymounkov, P. and Mazieres, D. 2002. Kademlia: A peer-to-peer information system based on the xor metric. <em>International workshop on peer-to-peer systems</em> (2002), 53–65.</p>
</div>
<div id="ref-nir2015chacha20">
<p>[20] Nir, Y. and Langley, A. 2015. <em>ChaCha20 and poly1305 for ietf protocols</em>.</p>
</div>
<div id="ref-oviatt2006human">
<p>[21] Oviatt, S. 2006. Human-centered design meets cognitive load theory: Designing interfaces that help people think. <em>Proceedings of the 14th acm international conference on multimedia</em> (2006), 871–880.</p>
</div>
<div id="ref-percival2015scrypt">
<p>[22] Percival, C. and Josefsson, S. 2015. The scrypt password-based key derivation function. (2015).</p>
</div>
<div id="ref-peer2peer">
<p>[23] Peter Mahlmann, C.S. 2007. <em>Peer–to–Peer–Netzwerke</em>. eXamen.press.</p>
</div>
<div id="ref-xmpp">
<p>[24] Peter Saint–Andre, R.T., Kevin Smith 2009. <em>XMPP: THe definitive guide</em>. O’Reilly.</p>
</div>
<div id="ref-pike2009go">
<p>[25] Pike, R. 2009. The Go Programming Language. <em>Talk given at Google’s Tech Talks</em>. (2009).</p>
</div>
<div id="ref-quintard2012towards">
<p>[26] Quintard, J. 2012. <em>Towards a worldwide storage infrastructure</em>. University of Cambridge.</p>
</div>
<div id="ref-cpiechula">
<p>[27] Sicherheitskonzepte und Evaluation dezentraler Dateisynchronisationssysteme am Beispiel »brig«: 2016.</p>
</div>
<div id="ref-wiki:snappy">
<p>[28] Snappy (datenkompressionssoftware) — wikipedia, die freie enzyklopädie: 2015. <em><a href="https://de.wikipedia.org/w/index.php?title=Snappy_(Datenkompressionssoftware)&amp;oldid=149622998" class="uri">https://de.wikipedia.org/w/index.php?title=Snappy_(Datenkompressionssoftware)&amp;oldid=149622998</a></em>.</p>
</div>
<div id="ref-suzuki2006birthday">
<p>[29] Suzuki, K., Tonien, D., Kurosawa, K. and Toyota, K. 2006. Birthday paradox for multi-collisions. <em>International conference on information security and cryptology</em> (2006), 29–40.</p>
</div>
<div id="ref-szydlo2004merkle">
<p>[30] Szydlo, M. 2004. Merkle tree traversal in log space and time. <em>International conference on the theory and applications of cryptographic techniques</em> (2004), 541–554.</p>
</div>
<div id="ref-pike2001security">
<p>[31] The Good, the Bad, and the Ugly: The Unix Legacy: 2001. <em><a href="http://herpolhode.com/rob/ugly.pdf" class="uri">http://herpolhode.com/rob/ugly.pdf</a></em>.</p>
</div>
<div id="ref-git">
<p>[32] Valentin Haenel, J.P. 2011. <em>Git - verteile versionsverwaltung für code und dokumente</em>. open source Press.</p>
</div>
<div id="ref-wiki:zooko">
<p>[33] Zookos dreieck — wikipedia, die freie enzyklopädie: 2015. <em><a href="https://de.wikipedia.org/w/index.php?title=Zookos_Dreieck&amp;oldid=145190860" class="uri">https://de.wikipedia.org/w/index.php?title=Zookos_Dreieck&amp;oldid=145190860</a></em>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Eine Filehosting–Software für den Heimgebrauch; siehe auch <a href="https://owncloud.org" class="uri">https://owncloud.org</a><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Quelle: xkcd (<a href="https://xkcd.com/949" class="uri">https://xkcd.com/949</a>)<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Siehe auch: <a href="https://motherboard.vice.com/read/the-interplanetary-file-system-wants-to-create-a-permanent-web" class="uri">https://motherboard.vice.com/read/the-interplanetary-file-system-wants-to-create-a-permanent-web</a><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Mehr Informationen unter: <a href="https://whispersystems.org" class="uri">https://whispersystems.org</a><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Zwischen 1 bis 5 Millionen Installationen im PlayStore (<a href="https://play.google.com/store/apps/details?id=org.thoughtcrime.securesms&amp;hl=de" class="uri">https://play.google.com/store/apps/details?id=org.thoughtcrime.securesms&amp;hl=de</a>)<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>Mehr Informationen unter: <a href="https://de.wikipedia.org/wiki/Signal_(Software)#Kritik" class="uri">https://de.wikipedia.org/wiki/Signal_(Software)#Kritik</a><a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Offizielles GitHub Repository: <a href="http://github.com/disorganizer/brig" class="uri">http://github.com/disorganizer/brig</a><a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>Ein dezentrales Versionsverwaltungssystem; siehe auch: <a href="https://git-scm.com" class="uri">https://git-scm.com</a><a href="#fnref8">↩</a></p></li>
<li id="fn9"><p><a href="https://de.wikipedia.org/wiki/Apache_Subversion" class="uri">https://de.wikipedia.org/wiki/Apache_Subversion</a><a href="#fnref9">↩</a></p></li>
<li id="fn10"><p><a href="https://de.wikipedia.org/wiki/Concurrent_Versions_System" class="uri">https://de.wikipedia.org/wiki/Concurrent_Versions_System</a><a href="#fnref10">↩</a></p></li>
<li id="fn11"><p>Voller Lizenztext unter: <a href="http://www.gnu.org/licenses/agpl-3.0.de.html" class="uri">http://www.gnu.org/licenses/agpl-3.0.de.html</a><a href="#fnref11">↩</a></p></li>
<li id="fn12"><p>Siehe auch: <a href="http://dsg.hs-augsburg.de" class="uri">http://dsg.hs-augsburg.de</a><a href="#fnref12">↩</a></p></li>
<li id="fn13"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/Overlay-Netz" class="uri">https://de.wikipedia.org/wiki/Overlay-Netz</a><a href="#fnref13">↩</a></p></li>
<li id="fn14"><p>Siehe auch: <a href="https://en.wikipedia.org/wiki/UDP_hole_punching" class="uri">https://en.wikipedia.org/wiki/UDP_hole_punching</a><a href="#fnref14">↩</a></p></li>
<li id="fn15"><p>Bildet einen Datensatz beliebiger Länge auf eine kurze Prüfsumme mit fixer Länge ab. Eine Rückrechnung von der Prüfsumme zum ursprünglichen Datensatz ist theoretisch möglich, aber extrem rechenaufwendig. Kleine Änderungen der Eingabe, erzeugen eine gänzlich andere Prüfsumme. Siehe auch: <a href="https://de.wikipedia.org/wiki/Hashfunktion" class="uri">https://de.wikipedia.org/wiki/Hashfunktion</a><a href="#fnref15">↩</a></p></li>
<li id="fn16"><p>Typischerweise sorgen auch vorgeschaltete <em>Caching Proxies</em> wie <code>Squid</code> (<a href="https://de.wikipedia.org/wiki/Squid" class="uri">https://de.wikipedia.org/wiki/Squid</a>) dafür, dass Dateien nicht zigmal heruntergeladen werden.<a href="#fnref16">↩</a></p></li>
<li id="fn17"><p>Eine Technik, um ein Dateisystem im Userspace zu implementieren. Dem Nutzer kann dadurch ein normaler Ordner mit beliebigen Daten als Dateien präsentiert werden.<a href="#fnref17">↩</a></p></li>
<li id="fn18"><p>Siehe auch: <a href="https://infinit.sh/open-source" class="uri">https://infinit.sh/open-source</a><a href="#fnref18">↩</a></p></li>
<li id="fn19"><p>Beispielsweise mit Dropbox: <a href="https://infinit.sh/documentation/comparison/dropbox" class="uri">https://infinit.sh/documentation/comparison/dropbox</a><a href="#fnref19">↩</a></p></li>
<li id="fn20"><p>Siehe auch: <a href="https://bazil.org" class="uri">https://bazil.org</a><a href="#fnref20">↩</a></p></li>
<li id="fn21"><p>Der Entwickler von <code>bazil</code> Tommi Virtanen betreut auch dankenswerterweise die FUSE–Bindings für <em>Go</em>, die auch <code>brig</code> nutzt.<a href="#fnref21">↩</a></p></li>
<li id="fn22"><p>Siehe auch: <a href="https://tahoe-lafs.org/trac/tahoe-lafs" class="uri">https://tahoe-lafs.org/trac/tahoe-lafs</a><a href="#fnref22">↩</a></p></li>
<li id="fn23"><p>Siehe auch: <a href="http://www.xtreemfs.org" class="uri">http://www.xtreemfs.org</a><a href="#fnref23">↩</a></p></li>
<li id="fn24"><p>Siehe auch: <a href="https://lizardfs.com/" class="uri">https://lizardfs.com/</a><a href="#fnref24">↩</a></p></li>
<li id="fn25"><p>Siehe auch: <a href="http://moosefs.org/" class="uri">http://moosefs.org/</a><a href="#fnref25">↩</a></p></li>
<li id="fn26"><p>Siehe auch: <a href="https://restic.github.io" class="uri">https://restic.github.io</a><a href="#fnref26">↩</a></p></li>
<li id="fn27"><p>Mehr Informationen unter <a href="https://nacl.cr.yp.to/secretbox.html" class="uri">https://nacl.cr.yp.to/secretbox.html</a><a href="#fnref27">↩</a></p></li>
<li id="fn28"><p>Siehe <a href="https://en.wikipedia.org/wiki/Comparison_of_file_synchronization_software" class="uri">https://en.wikipedia.org/wiki/Comparison_of_file_synchronization_software</a><a href="#fnref28">↩</a></p></li>
<li id="fn29"><p>Mehr Informationen unter <a href="https://de.wikipedia.org/wiki/EncFS" class="uri">https://de.wikipedia.org/wiki/EncFS</a><a href="#fnref29">↩</a></p></li>
<li id="fn30"><p>Mehr Informationen zum Keyserver unter <a href="https://www.boxcryptor.com/de/technischer-\%C3\%BCberblick\#anc09">https://www.boxcryptor.com/de/technischer-\%C3\%BCberblick\#anc09</a><a href="#fnref30">↩</a></p></li>
<li id="fn31"><p><a href="https://www.dropbox.com/de/help/137" class="uri">https://www.dropbox.com/de/help/137</a><a href="#fnref31">↩</a></p></li>
<li id="fn32"><p>Siehe auch: <a href="http://blog.bittorrent.com/2016/03/17/%CE%BCtp2-the-evolution-of-an-enterprise-grade-protocol">http://blog.bittorrent.com/2016/03/17/%CE%BCtp2-the-evolution-of-an-enterprise-grade-protocol</a><a href="#fnref32">↩</a></p></li>
<li id="fn33"><p><a href="https://infinit.sh/documentation/comparison/bsync" class="uri">https://infinit.sh/documentation/comparison/bsync</a><a href="#fnref33">↩</a></p></li>
<li id="fn34"><p>Bildquelle: <a href="http://code.178.is/git-annex-is-magic/git-annex-assistant2.png" class="uri">http://code.178.is/git-annex-is-magic/git-annex-assistant2.png</a><a href="#fnref34">↩</a></p></li>
<li id="fn35"><p>Webpräsenz: <a href="https://git-annex.branchable.com/" class="uri">https://git-annex.branchable.com/</a><a href="#fnref35">↩</a></p></li>
<li id="fn36"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/OpenPGP" class="uri">https://de.wikipedia.org/wiki/OpenPGP</a><a href="#fnref36">↩</a></p></li>
<li id="fn37"><p>Mehr Informationen hier: <a href="https://librevault.com" class="uri">https://librevault.com</a><a href="#fnref37">↩</a></p></li>
<li id="fn38"><p>Beispielsweise <code>git</code>–ähnliche Versionierung und die Möglichkeit auf alle Daten zuzugreifen, aber nur wenige physikalisch zu speichern. Hierzu später mehr.<a href="#fnref38">↩</a></p></li>
<li id="fn39"><p>Siehe auch <a href="https://owncloud.org" class="uri">https://owncloud.org</a>, bzw. dessen Fork <em>Nextcloud</em> <a href="https://nextcloud.com" class="uri">https://nextcloud.com</a><a href="#fnref39">↩</a></p></li>
<li id="fn40"><p>Der Durchschnitt im Jahr 2016 beträgt bereits etwa 14 Mbit/s. Quelle: Statista, <span class="citation">[11]</span>.<a href="#fnref40">↩</a></p></li>
<li id="fn41"><p>Ein Prüfsummenalgorithmus der SHA-2 Familie. Siehe auch: <a href="https://de.wikipedia.org/wiki/SHA-2" class="uri">https://de.wikipedia.org/wiki/SHA-2</a><a href="#fnref41">↩</a></p></li>
<li id="fn42"><p>Auch als <em>Bitrot</em> bekannt, siehe <a href="https://en.wikipedia.org/wiki/Data_degradation" class="uri">https://en.wikipedia.org/wiki/Data_degradation</a><a href="#fnref42">↩</a></p></li>
<li id="fn43"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/Globale_%C3%9Cberwachungs-_und_Spionageaff%C3%A4re">https://de.wikipedia.org/wiki/Globale_%C3%9Cberwachungs-_und_Spionageaff%C3%A4re</a><a href="#fnref43">↩</a></p></li>
<li id="fn44"><p>Webseite: <a href="https://www.pidgin.im" class="uri">https://www.pidgin.im</a><a href="#fnref44">↩</a></p></li>
<li id="fn45"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/Btrfs" class="uri">https://de.wikipedia.org/wiki/Btrfs</a><a href="#fnref45">↩</a></p></li>
<li id="fn46"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/ZFS_(Dateisystem)" class="uri">https://de.wikipedia.org/wiki/ZFS_(Dateisystem)</a><a href="#fnref46">↩</a></p></li>
<li id="fn47"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/Regressionstest" class="uri">https://de.wikipedia.org/wiki/Regressionstest</a><a href="#fnref47">↩</a></p></li>
<li id="fn48"><p>Siehe auch: <a href="https://en.wikipedia.org/wiki/Content_addressable_network" class="uri">https://en.wikipedia.org/wiki/Content_addressable_network</a><a href="#fnref48">↩</a></p></li>
<li id="fn49"><p>Mehr Informationen unter <a href="https://de.wikipedia.org/wiki/Magnet-Link" class="uri">https://de.wikipedia.org/wiki/Magnet-Link</a><a href="#fnref49">↩</a></p></li>
<li id="fn50"><p>Mehr Informationen in der Dokumentation unter: <a href="https://github.com/ipfs/specs/tree/master/libp2p" class="uri">https://github.com/ipfs/specs/tree/master/libp2p</a><a href="#fnref50">↩</a></p></li>
<li id="fn51"><p>Voraussetzung hierfür ist allerdings, dass der <code>ipfs</code>–Daemon vorher gestartet wurde und ein Repository mittels <code>ipfs init</code> erzeugt wurde.<a href="#fnref51">↩</a></p></li>
<li id="fn52"><p>Mehr Informationen unter: <a href="https://github.com/multiformats/multihash" class="uri">https://github.com/multiformats/multihash</a><a href="#fnref52">↩</a></p></li>
<li id="fn53"><p><a href="https://de.wikipedia.org/wiki/Base58" class="uri">https://de.wikipedia.org/wiki/Base58</a><a href="#fnref53">↩</a></p></li>
<li id="fn54"><p>Der Garbage–Collector kann auch manuell mittels <code>ipfs repo gc</code> von der Kommandozeile aufgerufen werden.<a href="#fnref54">↩</a></p></li>
<li id="fn55"><p>Siehe auch <a href="https://de.wikipedia.org/wiki/Garbage_Collection" class="uri">https://de.wikipedia.org/wiki/Garbage_Collection</a><a href="#fnref55">↩</a></p></li>
<li id="fn56"><p>Siehe auch die Erklärung hier: <a href="https://medium.com/@ConsenSys/an-introduction-to-ipfs-9bba4860abd0#.t6mcryb1r" class="uri">https://medium.com/@ConsenSys/an-introduction-to-ipfs-9bba4860abd0#.t6mcryb1r</a><a href="#fnref56">↩</a></p></li>
<li id="fn57"><p>Diskussion der Entwickler hier: <a href="https://github.com/ipfs/notes/issues/23" class="uri">https://github.com/ipfs/notes/issues/23</a><a href="#fnref57">↩</a></p></li>
<li id="fn58"><p>Offizielle Projektdokumentation von <code>git</code>: <a href="https://git-scm.com/doc" class="uri">https://git-scm.com/doc</a><a href="#fnref58">↩</a></p></li>
<li id="fn59"><p>Zitat von Linus Torvalds. Siehe auch: <a href="https://git-scm.com/docs/git.html" class="uri">https://git-scm.com/docs/git.html</a><a href="#fnref59">↩</a></p></li>
<li id="fn60"><p>Mehr Details unter: <a href="https://gist.github.com/masak/2415865" class="uri">https://gist.github.com/masak/2415865</a><a href="#fnref60">↩</a></p></li>
<li id="fn61"><p><a href="https://git.wiki.kernel.org/index.php/GitSvnComparison#Smaller%20Space%20Requirements">https://git.wiki.kernel.org/index.php/GitSvnComparison#Smaller%20Space%20Requirements</a><a href="#fnref61">↩</a></p></li>
<li id="fn62"><p>Siehe auch: <a href="https://git-scm.com/book/be/v2/Git-Internals-Packfiles" class="uri">https://git-scm.com/book/be/v2/Git-Internals-Packfiles</a><a href="#fnref62">↩</a></p></li>
<li id="fn63"><p>Siehe unter anderem: <a href="https://www.schneier.com/blog/archives/2005/02/sha1_broken.html" class="uri">https://www.schneier.com/blog/archives/2005/02/sha1_broken.html</a><a href="#fnref63">↩</a></p></li>
<li id="fn64"><p>Siehe auch: <a href="http://ericsink.com/vcbe/html/cryptographic_hashes.html" class="uri">http://ericsink.com/vcbe/html/cryptographic_hashes.html</a><a href="#fnref64">↩</a></p></li>
<li id="fn65"><p>Mehr zum Thema unter: <a href="https://lwn.net/Articles/370907" class="uri">https://lwn.net/Articles/370907</a><a href="#fnref65">↩</a></p></li>
<li id="fn66"><p><a href="https://git.wiki.kernel.org/index.php/GitFaq#Why_does_Git_not_.22track.22_renames.3F" class="uri">https://git.wiki.kernel.org/index.php/GitFaq#Why_does_Git_not_.22track.22_renames.3F</a><a href="#fnref66">↩</a></p></li>
<li id="fn67"><p><a href="https://git-annex.branchable.com/direct_mode" class="uri">https://git-annex.branchable.com/direct_mode</a><a href="#fnref67">↩</a></p></li>
<li id="fn68"><p><a href="https://git.wiki.kernel.org/index.php/GitFaq#Can_I_add_empty_directories.3F" class="uri">https://git.wiki.kernel.org/index.php/GitFaq#Can_I_add_empty_directories.3F</a><a href="#fnref68">↩</a></p></li>
<li id="fn69"><p><em>Branches</em> dienen bei <code>git</code> dazu, um einzelne Features oder Fixes separat entwickeln zu können.<a href="#fnref69">↩</a></p></li>
<li id="fn70"><p>So ist es bei <code>git</code> relativ einfach möglich in den sogenannten <em>Detached HEAD</em> Modus zu kommen, in dem durchaus Daten verloren gehen können. Siehe auch: <a href="http://gitfaq.org/articles/what-is-a-detached-head.html" class="uri">http://gitfaq.org/articles/what-is-a-detached-head.html</a><a href="#fnref70">↩</a></p></li>
<li id="fn71"><p>Streng genommen ist dies bei <code>git</code> auch nicht nötig, allerdings sehr unüblich.<a href="#fnref71">↩</a></p></li>
<li id="fn72"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/Inode" class="uri">https://de.wikipedia.org/wiki/Inode</a><a href="#fnref72">↩</a></p></li>
<li id="fn73"><p>Es wird nicht zwischen der Änderung eines einzelnen Bytes oder der gesamten Datei unterschieden wie bei <code>git</code>.<a href="#fnref73">↩</a></p></li>
<li id="fn74"><p>Selbstkritik des <code>git</code>–Projekts: <a href="https://git.wiki.kernel.org/index.php/GitFaq#Why_is_.22git_rm.22_not_the_inverse_of_.22git_add.22.3F" class="uri">https://git.wiki.kernel.org/index.php/GitFaq#Why_is_.22git_rm.22_not_the_inverse_of_.22git_add.22.3F</a><a href="#fnref74">↩</a></p></li>
<li id="fn75"><p>So ist es bei <code>git</code> relativ einfach möglich in den sogenannten <em>Detached HEAD</em> Modus zu kommen, in dem durchaus Daten verloren gehen können. Siehe auch: <a href="http://gitfaq.org/articles/what-is-a-detached-head.html" class="uri">http://gitfaq.org/articles/what-is-a-detached-head.html</a><a href="#fnref75">↩</a></p></li>
<li id="fn76"><p>Siehe auch: <a href="https://en.wikipedia.org/wiki/Private_peer-to-peer" class="uri">https://en.wikipedia.org/wiki/Private_peer-to-peer</a><a href="#fnref76">↩</a></p></li>
<li id="fn77"><p>Typischerweise würde ein solches Repository in einem Rechenzentrum liegen, oder auf einem privaten Server.<a href="#fnref77">↩</a></p></li>
<li id="fn78"><p>Siehe <a href="https://www.dropbox.com/help/36" class="uri">https://www.dropbox.com/help/36</a><a href="#fnref78">↩</a></p></li>
<li id="fn79"><p><a href="https://git-scm.com/book/be/v2/Git-Internals-Transfer-Protocols" class="uri">https://git-scm.com/book/be/v2/Git-Internals-Transfer-Protocols</a><a href="#fnref79">↩</a></p></li>
<li id="fn80"><p>Die Form des serialisierten Export–Formats ist nicht weiter interessant und kann im Anhang sec. 11 eingesehen werden (Message: <em>Store</em>).<a href="#fnref80">↩</a></p></li>
<li id="fn81"><p>Mehr Details zur <code>git</code>–Implementierung hier: <a href="https://git-scm.com/book/uz/v2/Git-Internals-Packfiles" class="uri">https://git-scm.com/book/uz/v2/Git-Internals-Packfiles</a><a href="#fnref81">↩</a></p></li>
<li id="fn82"><p>Tatsächlich gibt es derzeit keine ausführbaren Dateien mit diesen Namen. Die Bezeichnungen <code>brigctl</code> und <code>brigd</code> dienen lediglich der Veranschaulichung.<a href="#fnref82">↩</a></p></li>
<li id="fn83"><p>Mehr Informationen unter: <a href="https://developers.google.com/protocol-buffers" class="uri">https://developers.google.com/protocol-buffers</a><a href="#fnref83">↩</a></p></li>
<li id="fn84"><p>Siehe auch: <a href="https://en.wikipedia.org/wiki/Unix_domain_socket" class="uri">https://en.wikipedia.org/wiki/Unix_domain_socket</a><a href="#fnref84">↩</a></p></li>
<li id="fn85"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/Magische_Zahl_(Informatik)" class="uri">https://de.wikipedia.org/wiki/Magische_Zahl_(Informatik)</a><a href="#fnref85">↩</a></p></li>
<li id="fn86"><p>Siehe auch: <a href="https://nacl.cr.yp.to/secretbox.html" class="uri">https://nacl.cr.yp.to/secretbox.html</a><a href="#fnref86">↩</a></p></li>
<li id="fn87"><p>Rein technisch ist es auch andersherum möglich, aber aufgrund der prinzipbedingten, hohen Entropie von verschlüsselten Texten wären in dieser Reihenfolge die Kompressionsraten sehr gering.<a href="#fnref87">↩</a></p></li>
<li id="fn88"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/Remote_Procedure_Call" class="uri">https://de.wikipedia.org/wiki/Remote_Procedure_Call</a><a href="#fnref88">↩</a></p></li>
<li id="fn89"><p>Implementiert als eigene Bibliothek »libp2p«: <a href="https://github.com/libp2p/go-libp2p" class="uri">https://github.com/libp2p/go-libp2p</a><a href="#fnref89">↩</a></p></li>
<li id="fn90"><p>Siehe auch: <a href="https://github.com/multiformats/multistream" class="uri">https://github.com/multiformats/multistream</a><a href="#fnref90">↩</a></p></li>
<li id="fn91"><p>Diese Grafik ist eine Aufbereitung von: <a href="https://github.com/libp2p/go-libp2p/tree/master/p2p/net" class="uri">https://github.com/libp2p/go-libp2p/tree/master/p2p/net</a><a href="#fnref91">↩</a></p></li>
<li id="fn92"><p>Mehr Details unter: <a href="https://de.wikipedia.org/wiki/Jabber_Identifier" class="uri">https://de.wikipedia.org/wiki/Jabber_Identifier</a><a href="#fnref92">↩</a></p></li>
<li id="fn93"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/UTF-8" class="uri">https://de.wikipedia.org/wiki/UTF-8</a><a href="#fnref93">↩</a></p></li>
<li id="fn94"><p>Siehe auch: <a href="http://unicode.org/versions/corrigendum1.html" class="uri">http://unicode.org/versions/corrigendum1.html</a><a href="#fnref94">↩</a></p></li>
<li id="fn95"><p>Siehe auch: <a href="http://www.unicode.org/reports/tr15/\#Norm_Forms" class="uri">http://www.unicode.org/reports/tr15/\#Norm_Forms</a><a href="#fnref95">↩</a></p></li>
<li id="fn96"><p>Benötigt das <code>multihash</code> Werkzeug: <a href="https://github.com/multiformats/go-multihash/tree/master/multihash" class="uri">https://github.com/multiformats/go-multihash/tree/master/multihash</a><a href="#fnref96">↩</a></p></li>
<li id="fn97"><p><a href="https://de.wikipedia.org/wiki/Web_of_Trust" class="uri">https://de.wikipedia.org/wiki/Web_of_Trust</a><a href="#fnref97">↩</a></p></li>
<li id="fn98"><p>So wurde beispielsweise der unsichere ECB–Betriebsmodus für Blockchiffren absichtlich weggelassen: <a href="https://github.com/golang/go/issues/5597" class="uri">https://github.com/golang/go/issues/5597</a><a href="#fnref98">↩</a></p></li>
<li id="fn99"><p>Siehe dazu: <a href="https://golang.org/wiki/Mobile" class="uri">https://golang.org/wiki/Mobile</a><a href="#fnref99">↩</a></p></li>
<li id="fn100"><p>Siehe auch: <a href="https://blog.golang.org/go-fmt-your-code" class="uri">https://blog.golang.org/go-fmt-your-code</a><a href="#fnref100">↩</a></p></li>
<li id="fn101"><p>Ein Packprogramm für Binärdateien. Mehr Informationen unter <a href="http://upx.sourceforge.net" class="uri">http://upx.sourceforge.net</a><a href="#fnref101">↩</a></p></li>
<li id="fn102"><p><a href="http://labix.org/gopkg.in" class="uri">http://labix.org/gopkg.in</a><a href="#fnref102">↩</a></p></li>
<li id="fn103"><p>Eigenes Repository für verwendete Bibliotheken: <a href="https://github.com/disorganizer/brig-vendor" class="uri">https://github.com/disorganizer/brig-vendor</a><a href="#fnref103">↩</a></p></li>
<li id="fn104"><p><a href="https://github.com/AlDanial/cloc" class="uri">https://github.com/AlDanial/cloc</a><a href="#fnref104">↩</a></p></li>
<li id="fn105"><p><a href="https://godoc.org/github.com/disorganizer/brig" class="uri">https://godoc.org/github.com/disorganizer/brig</a><a href="#fnref105">↩</a></p></li>
<li id="fn106"><p><a href="https://golang.org/doc/effective_go.html" class="uri">https://golang.org/doc/effective_go.html</a><a href="#fnref106">↩</a></p></li>
<li id="fn107"><p>Also eine Datenbank, die ohne eigenen Datenbankserver funktioniert.<a href="#fnref107">↩</a></p></li>
<li id="fn108"><p>MIT–Lizensiert; Webseite: <a href="https://github.com/boltdb/bolt" class="uri">https://github.com/boltdb/bolt</a><a href="#fnref108">↩</a></p></li>
<li id="fn109"><p>Auch Radix–Baum genannt. Speichert gemeinsame Präfixe nur einmal und eignet sich daher gut, um bei vielen Pfaden Speicher zu sparen. Siehe auch: <a href="https://de.wikipedia.org/wiki/Patricia-Trie" class="uri">https://de.wikipedia.org/wiki/Patricia-Trie</a><a href="#fnref109">↩</a></p></li>
<li id="fn110"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/Filesystem_in_Userspace" class="uri">https://de.wikipedia.org/wiki/Filesystem_in_Userspace</a><a href="#fnref110">↩</a></p></li>
<li id="fn111"><p><a href="https://github.com/bazil/fuse" class="uri">https://github.com/bazil/fuse</a><a href="#fnref111">↩</a></p></li>
<li id="fn112"><p>Siehe Wikipedia für eine Liste: <a href="https://de.wikipedia.org/wiki/Liste_der_Linux-Systemaufrufe" class="uri">https://de.wikipedia.org/wiki/Liste_der_Linux-Systemaufrufe</a><a href="#fnref112">↩</a></p></li>
<li id="fn113"><p><a href="https://de.wikipedia.org/wiki/YAML" class="uri">https://de.wikipedia.org/wiki/YAML</a><a href="#fnref113">↩</a></p></li>
<li id="fn114"><p><a href="https://neovim.io" class="uri">https://neovim.io</a><a href="#fnref114">↩</a></p></li>
<li id="fn115"><p><a href="https://github.com/Masterminds/glide" class="uri">https://github.com/Masterminds/glide</a><a href="#fnref115">↩</a></p></li>
<li id="fn116"><p><a href="https://github.com/alecthomas/gometalinter" class="uri">https://github.com/alecthomas/gometalinter</a><a href="#fnref116">↩</a></p></li>
<li id="fn117"><p><a href="https://r-n-d.informatik.hs-augsburg.de:8080/brig/brig" class="uri">https://r-n-d.informatik.hs-augsburg.de:8080/brig/brig</a><a href="#fnref117">↩</a></p></li>
<li id="fn118"><p>Mehr Informationen hier: <a href="http://semver.org" class="uri">http://semver.org</a><a href="#fnref118">↩</a></p></li>
<li id="fn119"><p><a href="https://de.wikipedia.org/wiki/Extensible_Messaging_and_Presence_Protocol" class="uri">https://de.wikipedia.org/wiki/Extensible_Messaging_and_Presence_Protocol</a><a href="#fnref119">↩</a></p></li>
<li id="fn120"><p><a href="https://de.wikipedia.org/wiki/Off-the-Record_Messaging" class="uri">https://de.wikipedia.org/wiki/Off-the-Record_Messaging</a><a href="#fnref120">↩</a></p></li>
<li id="fn121"><p>Alte Implementierung: <a href="https://github.com/disorganizer/brig/tree/253208a0651b8649d54b159024b2756319458b94/im" class="uri">https://github.com/disorganizer/brig/tree/253208a0651b8649d54b159024b2756319458b94/im</a><a href="#fnref121">↩</a></p></li>
<li id="fn122"><p><a href="https://de.wikipedia.org/wiki/MQ_Telemetry_Transport" class="uri">https://de.wikipedia.org/wiki/MQ_Telemetry_Transport</a><a href="#fnref122">↩</a></p></li>
<li id="fn123"><p><a href="http://www.usabilitynet.org/trump/methods/recommended/requirements.htm" class="uri">http://www.usabilitynet.org/trump/methods/recommended/requirements.htm</a><a href="#fnref123">↩</a></p></li>
<li id="fn124"><p><a href="https://syncthing.net" class="uri">https://syncthing.net</a><a href="#fnref124">↩</a></p></li>
<li id="fn125"><p>Siehe auch: <a href="http://gitless.com" class="uri">http://gitless.com</a><a href="#fnref125">↩</a></p></li>
<li id="fn126"><p>Eine freie Desktopumgebung für Linux (<a href="https://www.gnome.org" class="uri">https://www.gnome.org</a>)<a href="#fnref126">↩</a></p></li>
<li id="fn127"><p>Eine freie GUI–Bibliothek (<a href="http://www.gtk.org" class="uri">http://www.gtk.org</a>)<a href="#fnref127">↩</a></p></li>
<li id="fn128"><p>Siehe auch: <a href="https://developer.gnome.org/hig/stable" class="uri">https://developer.gnome.org/hig/stable</a><a href="#fnref128">↩</a></p></li>
<li id="fn129"><p>Siehe auch: <a href="https://github.com/alexflint/gallium" class="uri">https://github.com/alexflint/gallium</a><a href="#fnref129">↩</a></p></li>
<li id="fn130"><p>Siehe auch: <a href="https://en.wikipedia.org/wiki/YubiKey" class="uri">https://en.wikipedia.org/wiki/YubiKey</a><a href="#fnref130">↩</a></p></li>
<li id="fn131"><p>Dies entspricht Anforderung 2).<a href="#fnref131">↩</a></p></li>
<li id="fn132"><p>Quelle: <a href="https://commons.wikimedia.org/wiki/File:QRCodeWikipedia.svg" class="uri">https://commons.wikimedia.org/wiki/File:QRCodeWikipedia.svg</a><a href="#fnref132">↩</a></p></li>
<li id="fn133"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/Nautilus_(Dateimanager)" class="uri">https://de.wikipedia.org/wiki/Nautilus_(Dateimanager)</a><a href="#fnref133">↩</a></p></li>
<li id="fn134"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/Eierlegende_Wollmilchsau" class="uri">https://de.wikipedia.org/wiki/Eierlegende_Wollmilchsau</a><a href="#fnref134">↩</a></p></li>
<li id="fn135"><p>Webpräsenz: <a href="http://ceph.com" class="uri">http://ceph.com</a><a href="#fnref135">↩</a></p></li>
<li id="fn136"><p>Webpräsenz: <a href="https://www.gluster.org" class="uri">https://www.gluster.org</a><a href="#fnref136">↩</a></p></li>
<li id="fn137"><p>In der momentanen Implementierung bei jedem <code>fsync()</code> und beim Schließen einer Datei.<a href="#fnref137">↩</a></p></li>
<li id="fn138"><p><a href="https://www.cockroachlabs.com" class="uri">https://www.cockroachlabs.com</a><a href="#fnref138">↩</a></p></li>
<li id="fn139"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/VeraCrypt" class="uri">https://de.wikipedia.org/wiki/VeraCrypt</a><a href="#fnref139">↩</a></p></li>
<li id="fn140"><p>Mehr Informationen unter: <a href="https://de.wikipedia.org/wiki/Amazon_Web_Services\#Speicher" class="uri">https://de.wikipedia.org/wiki/Amazon_Web_Services\#Speicher</a><a href="#fnref140">↩</a></p></li>
<li id="fn141"><p>Möglich mittels Werkzeugen wie <code>sshfs</code> (<a href="https://de.wikipedia.org/wiki/SSHFS" class="uri">https://de.wikipedia.org/wiki/SSHFS</a>) und <code>s3fs</code> (<a href="https://github.com/s3fs-fuse/s3fs-fuse" class="uri">https://github.com/s3fs-fuse/s3fs-fuse</a>)<a href="#fnref141">↩</a></p></li>
<li id="fn142"><p>Eine Enkodierung, welche die Wiederherstellung der Inhalte bis zu einem gewissen, konfigurierbaren <em>Beschädigungsgrad</em> erlaubt. Siehe auch <span class="citation">[15]</span>.<a href="#fnref142">↩</a></p></li>
<li id="fn143"><p><a href="https://github.com/dokan-dev/dokany" class="uri">https://github.com/dokan-dev/dokany</a>, eine Go–Bibliothek ist bereits verfügbar: <a href="https://godoc.org/github.com/keybase/kbfs/dokan" class="uri">https://godoc.org/github.com/keybase/kbfs/dokan</a><a href="#fnref143">↩</a></p></li>
<li id="fn144"><p><a href="https://de.wikipedia.org/wiki/WebDAV" class="uri">https://de.wikipedia.org/wiki/WebDAV</a><a href="#fnref144">↩</a></p></li>
<li id="fn145"><p>Siehe dazu: <a href="https://golang.org/wiki/Mobile" class="uri">https://golang.org/wiki/Mobile</a><a href="#fnref145">↩</a></p></li>
<li id="fn146"><p>Beispielsweise SSE4.x: <a href="https://de.wikipedia.org/wiki/Streaming_SIMD_Extensions_4" class="uri">https://de.wikipedia.org/wiki/Streaming_SIMD_Extensions_4</a><a href="#fnref146">↩</a></p></li>
<li id="fn147"><p><a href="https://de.wikipedia.org/wiki/Ramfs" class="uri">https://de.wikipedia.org/wiki/Ramfs</a><a href="#fnref147">↩</a></p></li>
<li id="fn148"><p>In diesem Fall ein <em>AMD Phenom(tm) II X4 955</em>.<a href="#fnref148">↩</a></p></li>
<li id="fn149"><p>Die 1080p Version von <em>Big Buck Bunny</em> von <a href="http://bbb3d.renderfarming.net/download.html" class="uri">http://bbb3d.renderfarming.net/download.html</a><a href="#fnref149">↩</a></p></li>
<li id="fn150"><p><a href="http://corpora2.informatik.uni-leipzig.de/downloads/deu_news_2015_3M.tar.gz" class="uri">http://corpora2.informatik.uni-leipzig.de/downloads/deu_news_2015_3M.tar.gz</a><a href="#fnref150">↩</a></p></li>
<li id="fn151"><p><a href="http://pygal.org/en/stable" class="uri">http://pygal.org/en/stable</a><a href="#fnref151">↩</a></p></li>
<li id="fn152"><p><a href="https://github.com/disorganizer/brig/blob/master/store/mime-util/main.go" class="uri">https://github.com/disorganizer/brig/blob/master/store/mime-util/main.go</a><a href="#fnref152">↩</a></p></li>
<li id="fn153"><p><a href="https://letsencrypt.org" class="uri">https://letsencrypt.org</a><a href="#fnref153">↩</a></p></li>
<li id="fn154"><p><a href="https://caddyserver.com" class="uri">https://caddyserver.com</a><a href="#fnref154">↩</a></p></li>
<li id="fn155"><p>Siehe auch: <a href="https://github.com/google/snappy/blob/master/framing_format.txt#L91" class="uri">https://github.com/google/snappy/blob/master/framing_format.txt#L91</a><a href="#fnref155">↩</a></p></li>
<li id="fn156"><p>Siehe auch: <a href="https://de.wikipedia.org/wiki/Journaling-Dateisystem" class="uri">https://de.wikipedia.org/wiki/Journaling-Dateisystem</a><a href="#fnref156">↩</a></p></li>
<li id="fn157"><p><a href="https://en.wikipedia.org/wiki/Tagsistant" class="uri">https://en.wikipedia.org/wiki/Tagsistant</a><a href="#fnref157">↩</a></p></li>
<li id="fn158"><p><a href="https://de.wikipedia.org/wiki/Zeroconf" class="uri">https://de.wikipedia.org/wiki/Zeroconf</a><a href="#fnref158">↩</a></p></li>
<li id="fn159"><p>Siehe auch: <a href="https://www.torproject.org" class="uri">https://www.torproject.org</a><a href="#fnref159">↩</a></p></li>
<li id="fn160"><p>Siehe auch: <a href="https://github.com/ipfs/notes/issues/37" class="uri">https://github.com/ipfs/notes/issues/37</a><a href="#fnref160">↩</a></p></li>
<li id="fn161"><p>Bildquelle: xkcd (<a href="https://xkcd.com/927" class="uri">https://xkcd.com/927</a>)<a href="#fnref161">↩</a></p></li>
<li id="fn162"><p>Quelle: <a href="https://github.com/ipfs/ipfs/issues/120" class="uri">https://github.com/ipfs/ipfs/issues/120</a><a href="#fnref162">↩</a></p></li>
<li id="fn163"><p><code>ipfs</code> implementiert momentan nur ein rein lesbares FUSE–Dateisystem.<a href="#fnref163">↩</a></p></li>
<li id="fn164"><p>Siehe auch: <a href="http://www.luga.de/Aktionen/LIT-2016" class="uri">http://www.luga.de/Aktionen/LIT-2016</a><a href="#fnref164">↩</a></p></li>
<li id="fn165"><p>Im Falle der Autoren ist das: Arch Linux mit Kernel 4.4 und Go in Version 1.5 bis 1.6.<a href="#fnref165">↩</a></p></li>
<li id="fn166"><p><a href="https://golang.org/dl/" class="uri">https://golang.org/dl/</a><a href="#fnref166">↩</a></p></li>
<li id="fn167"><p>Mehr Informationen hier: <a href="https://github.com/dropbox/zxcvbn" class="uri">https://github.com/dropbox/zxcvbn</a><a href="#fnref167">↩</a></p></li>
<li id="fn168"><p>Benannt nach dem traditionellen Unix–Kommando <code>cat</code> zum Ausgeben und Konkatenieren von Dateien.<a href="#fnref168">↩</a></p></li>
<li id="fn169"><p>Mehr Informationen unter <a href="http://semver.org" class="uri">http://semver.org</a><a href="#fnref169">↩</a></p></li>
<li id="fn170"><p><a href="https://neovim.io" class="uri">https://neovim.io</a><a href="#fnref170">↩</a></p></li>
</ol>
</div>
</body>
</html>
